Discussion II: Designing and Pursuing Better Human Data Relations {#chapter-7}
========================

> _"Civilizations advance not by the technology they know about, but by the technology they don't have to know about."_ — Anonymous proverb

Introduction & Background{#7.1}
----------------

### Objectives and Approach for this Chapter

[Chapter 6](#chapter-6) concluded the academic inquiry part of this thesis. We now know, backed up by the insights from the participants of the Case Studies, what people want from direct [[RQ1](#RQ1)] and indirect [[RQ2](#RQ2)] data relations. That is, however, not the end of the story. Bringing to bear my experience as a designer and software developer, I can advance the exploration of Human Data Relations further, turning from theory to practice, from what is needed to what is possible. It has been my good fortune to have been involved throughout the duration of this PhD with peripheral activities that also can be seen, in the context of this thesis' findings, to relate very much to the pursuit of better HDR. For Chapter 7, therefore, I expand the original research question, going beyond [the initial RQ](#RQ)'s inquiry into what relationship people need with their personal data, and explore how those needs could be met in practice:

> <a name="exRQ"></a>**"Having understood what relationship people need with their personal data, how might these better Human Data Relations be achieved?"**

Methodologically, this chapter falls outside of the core academic inquiry. The Case Studies prioritised a participatory and investigatory approach. But, there is a for specialist design innovation that cannot always arise from working with everyday users. Chapter 7, therefore, is more UCD than PD [[3.2.1](#3.2.1)]. Thesis findings are now considered as material to inform myself as an adversarial designer, proposing technical and societal changes that can bring about better HDR. [7.1.2](#7.1.2) the describes the peripheral R&D activities I undertook. These form the primary point of reference for this chapter.

The wide-reaching objective of better HDR in practice has many facets: technical, design, commercial, legal, moral, social and political. This chapter does not cover them all. This chapter presents an understanding of the multi-faceted realities of the PDE landscape _sufficient to inform the design_ of PDE processes and systems. This understanding is synthesised from my real world practical designs and insights as well as from the work of other innovators and activists, and is contextualised relative to existing literature and the thesis's earlier contributions.

Considering the [expanded research question](#exRQ) above generates further questions. Like SI's _barriers cascade_ [@li2010], what barriers exist that inhibit the building or adoption of human-centric technologies? What opportunities might overcome these barriers? How can we catalyse progress toward MyData's human-centric agenda [@mydata2017declaration]? What challenges are faced when attempting to build human-centric technologies for today's world? Building on an understanding of human experience of the data-centric world, can we more provide an outlook for PDE design & development and define a _research agenda_ for the next step of tackling the PDE challenge?

In [7.2](#7.2), I position the topic of this thesis, Human Data Relations, as a field of study in its own right. Additional insights into how people relate to data are identified, as well an important dichotomy of people's needs for better relations with their data. The six HDR wants [[Chapter 6](#chapter-6)] are repurposed as four core objectives for a landscape of better HDR. I conceptualise those who pursue better HDR as _HDR reformers_ and reflect on the researcher-turned-activist stance that drives this chapter, recognising a nascent _recursive public_.

This chapter is deliberately broad and open-ended. It does not pretend to be complete or definitive in its interpretation of the outlook for HDR. It is not a roadmap, but rather a snapshot of ongoing work, identified challenges and known opportunities. It serves as an anthology of reference material, based on my research and design experience from six years work to understand and advance HDR. A good high-level understanding of the landscape combined with some specific ideas to work with should be valuable for anyone working in the HDR space. The goal is to empower HDR reformers through the insights so that they might 'hit the ground running'. [7.3](#7.3) identifies the main obstacles that one must face in pursuit of the HDR objectives. [7.4](#7.4) is solution-focused, considering the nuts and bolts of _how_ we might begin to tackle the obstacles of [7.3](#7.3) in pursuit of the HDR objectives, and offers four specific approaches or trajectories for change, framed using _Theories of Change (ToC)_ [[7.4.1](#7.4.1)]. Within each of these four trajectories, specific opportunities are described or referenced in varying detail [^11]. Key designerly insights are highlighted in inset boxes throughout these two sections.

In [7.5](#7.5), the contribution of this chapter is summarised, again with reference to ToC thinking, in answer to the [expanded research question](#exRQ).

[^11]: Some of the challenges and opportunities are described in greater detail than others. This corresponds only to my proximity and depth of engagement with those ideas, rather than their relative merit, complexity or impact potential. Given the broad aim to chart a new field, I consider it is more useful to introduce a range of applicable ideas even if some are only lightly detailed than to document just a few.

### Peripheral Research & Design Settings

As established [[3.2.2](#3.2.2); [3.6](#3.6); [7.1.1](#7.1.1)], this chapter describes the wider action research [[3.2.2](#3.2.2)] cycle that has contributed to my evolving learning about HDR, looking beyond direct academic investigation and also drawing upon both self-experimentation and my embedded work in in the personal data space as both developer and researcher. Through field experience, I have understood constraints and opportunities that affect data interaction system and process design. Concurrently I have fed research learnings back into those projects, creating practical impact. Instead of conducting formal studies, I have undergone a process of acculturation to the world of practical system building and project operation in the PDE. Through design, technical prototyping and pushing boundaries of existing systems, I have developed knowledge and gained expertise which allows me to draw conclusions with confidence about how discipline HDR should proceed in its future R&D to best serve individual and societal interests.

Concurrent to this PhD, I took a major role in two industrial research projects (1 & 2), and two academic research projects (3 & 4):

  1. **BBC R&D's Cornmarket Project** [@sharp2021], which explored through user experience design, technical prototyping and participatory research, how individuals might interact with data through a Personal Data Store interface [see [ARI7.1](#additional-bbc)];
  2. **SITRA/Hestia.ai's digipower Project** [@härkönen2022project], a successor to Case Study Two, in which European politicians examined companies' data practices through exercising data rights and conducting technical audits [see [ARI7.2](#additional-digipower)];
  3. **Connected Health Cities (CHC)'s SILVER Project** [@ConnectedHealthCities2017silver], where I, along with a backend developer and a team of researchers, developed a prototype health data viewing interface for Early Help support worker [see [3.4.1](#3.4.1.1)]; and
  4. **Digital Economy Research Centre (DERC)'s Healthy Eating Web Augmentation Project**, which explored the use of web augmentation techniques to modify the user interface of takeaway service Just Eat to insert health information, in support of healthy eating [see [ARI7.3](#additional-derc)].

For additional details about these projects and my involvement in them, see the linked sections. See also [ARI7.4](#ari-attribution) for a note about the attribution and origin of the ideas presented within this chapter.

Defining and Refining 'Human Data Relations' (HDR){#7.2}
--------------------------------------------------

Chapter 6 established six 'wants' that people have in their relationships with data: **visible**, **understandable** and **useable data**; **process transparency**, **individual oversight** and **decision-making involvement**.

The major contribution of this thesis, beyond evidencing these wants in chapters 4 to 6, is to transform these desires into a clearly defined field for future research and innovation. Repurposing concepts of 'human-technology relations' and later 'human-data relations' which have been the subject of some study in the contexts of philosophy, embodied interaction and the performing arts [@ihde1990; @hogan2012; @windeyer2021], I have chosen to name this field **Human Data Relations**, or **HDR** for short. I propose this field as a successor to Mortier _et al._'s Human Data Interaction (HDI) [@mortier2014]. HDR builds upon HDI but takes a broader sociotechnical stance. HDR encompasses all the ways people and organisations can and should relate to data, not just direct data interaction. Through its greater focus on relationships and ecosystems, and approaches that address today's data-centric power-imbalanced reality, it offers a more actionable research agenda for the world of the 2020s. HDR's definition draws upon three distinct connotations or readings of its name:

| Human Data Relations - A Definition |{#HDR}
| :---------------------------------- |
| The field of HDR encompasses all the ways in which humans and human organisations relate to, and with, data, specifically: |
|   1. _Human-Data Relations_: users' direct interaction with data to understand and use it, similar to HDI, in service of the direct data wants [[6.1](#6.1)] of visible, understandable and useable data. |
|   2. _Human "Data Relations"_: individuals' relationships with organisations that hold data about them, in service of the indirect data wants [[6.2](#6.2)] of transparency, individual oversight and involvement. |
|   3. _Human/Data Relations_: how organisations manage their customers with respect to personal data. Similar to _public relations_ or _customer relations_, organisations choose how present their data practices (so as to build trust), and whether they will involve users with data, and provide support to understand data to their users. Organisations can empower individuals and build more effective customer relationships through HDR [[4.4.1](#4.4.1); [5.5.2](#5.5.2); [6.1.2](#6.1.2)]. |

Having scoped HDR, we see that 'better' HDR can be achieved by working to improve upon the identified six HDR wants. However, as this section will explain, HDR is motivated in two distinct ways, to which those wants apply differently. As background understanding, it is first necessary to examine more closely what role data plays in people's lives.

### The Role of Personal Data{#7.2.1}

Today, almost anything can be encoded as data. Many previously analogue objects and activities now have digital equivalents, so the concept of data has become broad and hard to pin down. Underlying HDR is a need to recognise what roles data can play in people's lives—what it **is** to people. I have so far identified eight distinct lenses to explain how people might relate to data—including as property, as memory and as creative work. These are modelled in [Table ARI5.2](#table-ari5.2).

People may think of their personal data through any or all of these _lenses_ [@karger2005; [2.2.2](#2.2.2.5)] at any given time. Any data interaction process or interface design should take these into account. Different informational representations might be needed at different times [@lindley2018], bringing different aspects of the data to the forefront. Looking across these lenses, I identify four specific _roles_ that data can serve:

1. Data has a role as an **artifact of value** to your life;
2. Data has a role in **informing** you about yourself, the world, and the prior or recent actions of others that may affect you;
3. Data has a role as **a useable<sup>[10](#fn10)</sup> material with which to effect change** in your life;
4. Data has a role as **a means to monitor changes** in data holders' behaviours, in digital influences upon you, or within your life.

### Human Data Interaction or Human Information Interaction?{#7.2.2}

To unpack HDR further, we must differentiate between humans relating to data, and humans relating to information. HDI concerns the way people interact with data. Mortier _et al._  [@mortier2013; @mortier2014] defined the field of HDI without making the important distinction between data (the digital artifact stored on computer) and information (the facts or assertions available from that data). This is an important distinction. _Human Information Interaction (HII)_ originated in library sciences to consider how humans relate to information without regard to the technologies involved [@marchionini2008]. Jones _et al._ called for a new sub-field of HII in an HCI context[^12], highlighting the need to focus on information interaction:

> _"_[HCI can] _unduly focus attention on the computer when, for most people, the computer is a means to an end—the effective use of information."_—[@jones2006]

DIKW theory [[2.1.1](#2.1.1)] highlights that interpretation of data to obtain information is a discrete activity. This was borne out in the findings of Case Study Two, where it became clear that participants have distinct needs from data, and from information [[5.4.3](#5.4.3.2)]. Access to data _and_ information is critical to both understanding and useability [[6.1.2](#6.1.2); [6.1.3](#6.1.3)].

[^12]: The HCI panelists involved (excepting Fidel) were seemingly unaware of the existing HII field in library sciences, as they positioned the publication as a call for a 'new field'.

Drawing on DIKW theory, allows the identification of three distinct artefacts people can have relations with:

  1. **data** - the stored digital artefacts held by organisations for algorithmic processing and human reference, copies of some of which can be obtained using data rights;
  2. **information about individuals** (a.k.a. _life information_) - facts and assertions about the individual and their life, obtained through human or algorithmic interpretation of stored data or analytical inference; and
  3. **information about data**_ (a.k.a. _metadata_ [[Table 5.2](#table-5.2); [5.3.1](#5.3.1)] or _ecosystem information_) - stored facts about data, such as storage location, access history, means of collection, contextual meaning, or sharing records.

### The Two Distinct Motivations for HDR{#7.2.3}

Considering these two types of information in the context of the six HDR wants [[Chapter 6](#chapter-6)] reveals two very different reasons why people might want better HDR:

(i) to acquire _information about your data_, so that you might exert control over where the data is held and how it is used, in order to be treated fairly and make informed choices about personal data. This is **Personal Data Ecosystem Control (PDEC)**.

(ii) to acquire _information about yourself_, so that you might gain insights into your own behaviour, and gain personal benefits from those insights or make changes in your life. This is **Life Information Utilisation (LIU)**.

[Figure 7.1](#figure-7.1) shows processes individuals might go through in pursuit of these motives. PDEC is a process of holding organisations to account and managing _what happens_ to personal data, often regardless of what it means. LIU is more concerned with _what the data means_ and its inherent personal value, regardless of where it is stored and how it is used[^13]. This novel motivational model was first proposed in [@bowyer2021twopurposes].

![Figure 7.1: The Two Motivations for HDR: Controlling Your Personal Data Ecosystem and Utilising Your Information About Your Life<br/>(with 'idealised'[^14] processes illustrated)](./src/figs/fig7.1-the-two-motivations-for-hdr.jpg){#figure-7.1}

[^13]: There is some overlap. Organisations hold data to enable interpretation (usually algorithmic) to inform decision making. In this way, organisations are doing LIU for _their_ benefit. This grey area is situated as part of PDEC, because from the individual's perspective, how organisations understand you through information informs decisions that affect your life. As such, it is more likely to enable you to exert control over use of your data than to pursue personal LIU goals.

[^14]: The illustrated processes incorporate existing data access processes such as GDPR, where the only access is through provision of a copy of one's data. This is _not_ ideal, as it creates divergent versions and will quickly become out-of-sync, however for the sake of simplicity that inefficiency is ignored [see [5.5.1](#5.5.1) for improvements to copy-based access].

<a name="7.2.3.1">**Life Information Utilisation (LIU)**</a>

_Life Information Utilisation_ is a superset of _Self Informatics (SI)_ [[2.2.3](#2.2.3)], including all purposes relating to self-monitoring and self-improvement through personal data, but also other uses including creative expression, evidence gathering, nostalgia, keeping, and sharing. Many such desires were expressed in Case Study Two [[Table 5.4](#table-5.4)], and also hinted at in the Early Help context [[4.4.1](#4.4.1)]. While the existence of digitally-encoded information clearly unlocks new possibilities, LIU has existed in some form throughout human civilisation, as seen through analogue processes such as storytelling, journaling and scrapbooking.

The most relevant HDR wants to LIU are _data understandability_ [[6.1.2](#6.1.2)] and _data useability<sup>[10](#fn10)</sup>_ [[6.1.3](#6.1.3)], which relate closely to the HDI concepts of _legibility_ and _agency_ respectively.

<a name="7.2.3.2">**Personal Data Ecosystem Control (PDEC)**</a>

Unlike LIU, _Personal Data Ecosystem Control_ is a _new_ individual need, arising as a result of the emergence of the data-centric world [[2.1](#2.1); [2.2.4](#2.2.4)]. Only when organisations began to collect and store facts about people as a substitute for direct communication and involvement did it become necessary. The more data is collected about individuals, and the more parties doing so, the greater the need for individuals to understand these acts so that they might influence them (or risk their lives being affected in unexpected or unfair ways). PDEC is a direct response to the power imbalance between data holders and individuals [@wef2014lens; [2.1.2](#2.1.2)].

Multiple HDR wants are important to PDEC: visible data and transparent processes (referred to collectively as _data ecosystem transparency_), and individual oversight and involvement (referred to collectively as _data ecosystem negotiability_, drawing on the HDI concept of _negotiability_). These grouped terms are used below.

### Four Objectives for Human Data Relations{#7.2.4}

![Figure 7.2: Mapping the Six Wants into Objectives for the HDR Opportunity Landscape](./src/figs/fig7.2-landscape-objectives.jpg){#figure-7.2}

To offer future value to future researchers, activists and innovators, this chapter contributes a map of the HDR opportunity landscape. This map is expressed in two parts across this section and [7.4](#7.4). First, the six HDR wants [[Chapter 6](#chapter-6)] are transformed into four simple _landscape objectives_ which shape our ultimate goals for effective HDR in this landscape of opportunity:

  1. Data Awareness & Understanding;
  2. Data Useability<sup>[10](#fn10)</sup>;
  3. Data Ecosystem Awareness & Understanding[^15] and
  4. Data Ecosystem Negotiability<sup>[15](#fn15]</sup>.

[^15]: To avoid overly cumbersome wording, subsequent sections will drop the 'Data' prefix from 'Data Ecosystem Awareness & Understanding' and 'Data Ecosystem Negotiability'.

As [Figure 7.2](#figure-7.2) shows, the need for data to be understandable, visible and useable applies to all types of data, whether that data is interpretable as _life information_ (information within the data, that says something about the individual) or _ecosystem information_ (information _about_ the data, where it is held and how it is used). These two types of information will collectively be referred to as **human information**. These terms are used in subsequent sections.

### Better Human Data Relations as a Recursive Public{#7.2.5}

Let us revisit the stance from which we approach this change. This PhD has been grounded in participatory action research and experience-centred design [[3.2](#3.2)]. Using a _Digital Civics_ [@vlachokyriakos2016] approach to understand people's unmet needs, we can model how the world should change. Such research is political [[3.2.1](#3.2.1)], seeking to correct an imbalance in the world through _adversarial design_ [@disalvo2012]. This chapter steps forward in the role of activist researcher, not only understanding what needs to change, but exploring how individuals and groups can actually change their world.

In this, we can consider ourselves (those who pursue better HDR, or _HDR reformers_ as a shorthand) as a nascent _recursive public_ [@p2pwikiRecursivePublic]. This term originates in the free software movement to describe:

> _'a collective, independent of other forms of constituted power, capable of speaking to existing forms of power through the production of actually existing alternatives'_-[@kelty2008]

Being a recursive public means using various means at our disposal to seek to modify the systems and practices we live within in pursuit of our goals. These methods might include participatory research, experience-centred design, software prototyping, rights exertion and campaigning.

This idea of reconfiguring society in this way has been conceived as _civic hacking_ [@crabtree2007; @levitas2013; @tauberer2014]. The collective around HDR reform does not yet exist as a named and identifiable _public_ [@ledantec2016] but its members congregate around interconnected and overlapping movements such as:

- the MyData community [@mydata2017declaration; [2.3.4](#2.3.4)];
- personal data lockers [@digime2021; @citizenme2021; @sharp2021];
- digital rights [@openRightsGroup];
- gig economy worker rights [@kirven2018; @wie2022];
- privacy by design [@cavoukian2010];
- privacy activism [@davies1990; @bits2000];
- data justice [@taylor2017; @crivellaro2019];
- critical algorithm studies [@gillespie2016];
- adversarial interoperability [@doctorow2019];
- 'makers' [@altsitsiadis2021];
- humane technology [@harris2013]; and
- explainable AI [@explainableAI].

The commonality to so many groups suggests HDR reform is an emergent cultural phenomenon, whether or not a single identifiable public coalesces. Time will tell whether _Human Data Relations_ as laid out in this thesis is sufficient to give form to that phenomenon. At the least, HDR offers as descriptive umbrella term. The breadth of research, innovation and activism validates the need _and_ the desire for such a recursive public around HDR reform to exist. In fact, it already does, whether named or not. Therefore, this chapter takes an unashamedly critical view of the status quo, favouring disruptive societal change that would further HDR reform and provide actionable approaches for members of this public. This chapter asks,

> _"How can we change the world into the one we want?"_

The landscape of opportunity: Obstacles to better Human Data Relations, and how we might overcome them{#7.3}
------------------------------------------------------------------------------------------------------

Considering how the four objectives [7.2.4](#7.2.4) might be tackled, specific _obstacles_ have been identified. Analogous to Li's _barriers cascade_ [[2.2.3](#2.2.3); @li2010], these are the challenges that individuals or system designers must be empowered to overcome. These obstacles, documented below, are accompanied by _insights_ that might help. [Figure 7.3](#figure-7.3) shows an HDR-specific barriers cascade: a route of overcoming obstacles through which individuals might be empowered and by which organisations might become more HDR-friendly.

![Figure 7.3: Obstacles and Resulting Insights in the HDR Opportunity Landscape](./src/figs/fig7.3-obstacles-insights-hdr-landscape.jpg){#figure-7.3}

The obstacles and insights in the figure are explained in the following subsections. The last of these (corresponding to the 'solution space' box) covers some of more pervasive obstacles that apply to all four HDR objectives.

### Obstacles to the HDR Objective of Data Awareness & Understanding{#objective-1}

In pursuit of visible, understandable data [[6.1.1](#6.1.1); [6.1.2](#6.1.2)], the first obstacle encountered is that most personal data is **invisible**, **inaccessible** or **unrelatable**. It is trapped in service providers' databases, or on different devices or hard drives, or by software limitations and proprietary file formats [@abiteboul2015; @bowyer2018freedata]. My research participants spoke of 'not knowing' what data exists and of being 'in the dark'. Case Study Two showed that even where data is accessible, it is not **relatable** (_legible_ [@mortier2014]; [2.3.2](#2.3.2)). The objective here, addressed in [Insight 1](#insight-1), is to ensure that people not only have awareness of their data, but can understand ('make sense' [@gurstein2011; [2.1.4](#2.1.4)]) of what it means.

| **INSIGHT 1: Life Information makes Data Relatable** |{#insight-1}
|:---------------------------------------|
| In the pilot study and Case Study One, data cards' were used to represent civic data [[Figure 3.6](#figure-3.6)]. In Case Study Two [[Figure 3.7](#figure-3.7)] and in Hestia.ai's digipower investigation [[ARI7.2](#ari-digipower)], a categorisation of provider-held data was displayed. In my BBC research report [@bowyer2020bbcreport], the use of **relatable examples** was identified as an important way to help people understand what a piece of data represents.<br/><br/>Recalling that to make data meaningful, we must be able to interpret it as information [[2.1.1](#2.1.1)], this can be refined further: |

> **To make data meaningful, it needs to be expressed as information about your life**.

|(continues…)|
|:--|
| Spreadsheets and 'big data' sound dry and (to many) dauntingly technical, but once those same datapoints are expressed as 'facts about your life', the hurdle of relatability is overcome [[4.2.1](#4.2.1)]. The effectiveness of applying this principle is evident in successful online services like Netflix, Spotify and Strava, and in social media platforms like Facebook: these interfaces show understandable everyday concepts like Friends, Events, Movies, Playlists, not files, records, folders or database rows. They have successfully _'pushed the technology into the background'_, in line with Weiser's vision [@weiser1991], Rogers' calm computing, and the quote that opens this chapter. While exploring this idea of representing **life concepts** further at BBC R&D, I produced [Figure 7.4](#figure-7.4), which shows a near-exhaustive overview of the many different informational concepts in an individual's life that providers might hold as data:|

![Figure 7.4: Life Concept Modelling](./src/figs/fig7.4-life-concepts.png){#figure-7.4}

|(continues…)|
|:--|
| This diagram shows how most common personal data types handled today can be mapped to more relatable life information concepts. These life concepts (exemplified where possible) make data meaningful to individuals, and can help people find value in their data [[5.4.3](#5.4.3.1)].|

Another important obstacle to consider here is what I call the **Personal Data Diaspora**[^16]. As illustrated by Imogen Heap's quote opening [Chapter 1](#chapter-1), an individual's personal data is typically very widely dispersed, and there is no central, holistic view of one's data. For example, if I consider just my movement tracking data, I have over time accumulated activity logs from walking, running, cycling, and driving which are stored by Nike+, MyFitnessPal, Strava, Google Fit, Fitbit, Apple Health and Google Maps, not to mention the records remaining on my different smart watches, smartphones and hard drives. This is the SI problem of _Integration_ [@li2010] [[2.2.3](#2.2.3)]. EAs well as the challenge of managing one's data ecosystem [[2.2.4](#2.2.4)], this makes impossible to view physical activity history in one place, to spot patterns over time or make comparisons. To overcome this, we need interfaces that recognise the scattered reality of each individual's personal data, and begin to make that ecosystem visible and understandable [see [7.3.3](#7.3.3) and [7.3.4](#7.3.4) below].

Data awareness and understanding is a problem of representation. Invisible data should be visibly represented. All data should be represented as contextually relatable life information.

[^16]: The word _'diaspora'_ is typically used with reference to populations, but is an apt term, derived from the Greek 'diaspeirein' meaning 'scattered about' or 'dispersed'.

### Obstacles to the HDR Objective of Data Useability<sup>[10](#fn10)</sup>{#objective-2}

To improve the useability of data, let us consider what properties of data make it hard to use. Most personal data is immobile, inacessible, unmalleable and not interrogable.

It is **immobile** in that is very difficult to move a dataset out of its environment. Most data exists in organisations' internal databases, where it is tightly coupled to technology stacks, interfaces and business processes. Separating one's data from the service that holds it is difficult and often impossible. It is **inaccessible** to individuals (in the sense of _effective access_ [@gurstein2011]). Data access requests such as GDPR are typically satisfied by creating a copy of the data, creating problems of delay, divergence and understanding. Even then, returned data is incomplete [[5.4.2](#5.4.2.2)]. Its accessibility is also hindered by the technical nature of data. Data is often be stored in complex proprietary structures which are designed for the algorithmic efficiency of the specific business operations rather than for general-purpose re-use.

People need to be able to ask questions of their data [[Table 5.4](#table-5.4); [4.3.2](#4.3.2.4)]. But data is **not interrogable**. It must stand for itself, yet there is no obvious way to ask a question about the meaning of the data or its ability to answer a particular question. To ask questions of data requires either the co-operation of the data holder or advanced technical skills in data querying and analysis. Data needs to be **malleable**—capable of being broken down, looked at from different perspectives, and reconstituted in different ways. This goes beyond visually representing the data, and implies an ability to interact with the data to produce new interpretations and insights to investigate specific questions.

To overcome these obstacles, data must be freed from its current constraints and moved into environments where it can be freely examined and reconstituted without restriction. This leads to Insight 2:

| **INSIGHT 2: Data Needs to be United and Unified** |{#insight-2}
|:-------------------------------------------------|
| It is clear that better HDR involves recognising this splintered reality [@lemley2021] and moving beyond it. To make data useable for individuals, the diaspora must be united. This means that data from different sources must first be **united**—brought together—and then **unified**, which means making it into a collection of data about the individual and their life, rather than scattered slices of company data that may have secondary value to the individual. This is a multi-faceted sociotechnical problem of access, interpretation and _integration_ [@li2010; [[2.2.3](#2.2.3)]]. Negotiability remains important; we can only unite data that we can access, and only data holders can fully explain it [see [7.3.3](#7.3.3) and [7.3.4](#7.3.4)]. Setting that aspect aside, the pragmatic way forward begins with creating a space where data can be held, combined, controlled and **owned** by the individual - _'a place for your personal data'_ [@jones2011pim,[[2.2.4](#2.2.4)]]. This can form the seed of their new human-centric personal data ecosystem. This follows Bergman's _subjective classification principle_: |

> _'All related items should be classified together regardless of technological format'_—[@bergman2003]

| (continues…)|
|:--|
| We could add: _'regardless of where they are held'_. This vision is embodied in the **Personal Data Stores** (PDS) concept [[2.3.4](#2.3.4)]. The BBC R&D Cornmarket project [[ARI7.1](#ari-bbc)] examines how to build PDSs. In [7.4](#7.4) I explore possible design approaches. At this stage, only the _concept_ is important. Once data is united and unified, PDSs enable the creation of new views of data that were not previously possible, because code can execute across data that was previously dispersed. For example, today each separate TV app, device or streaming service maintains separate records of what you have watched. Once unified in a PDS, it would be possible to present you with a unified view of all the past content you had viewed, across all channels, as this mock-up I made during my BBC internship shows:|

![Figure 7.5: Mock-up of a Unified TV Viewing History Interface](./src/figs/fig7.5-unified-watch-history.png){#figure-7.5}

| **INSIGHT 3: Data Must Be Transformed into a Versatile Material** |{#insight-3}
|:-------------------------------------------------|
| In Case Study Two [see [Table 5.4](#table-5.4) and the additional detail in the Supplemental Materials of @bowyer2022gdpr], participants expressed diverse goals for personal data, including reflection, pattern-finding, goal-tracking, and creative use. In the PIM space [[2.2.2](#2.2.2)] relevant innovations include associative exploration, spatial arrangement, and embodied interaction for different contexts) Drawing on all of these, allows me to infer that unified data must be transformed into a **versatile material**. Individuals need to be able to use data—represented as facts or assertions about one's life by performing manipulations such as: |

  - creating,
  - deleting,
  - moving,
  - grouping,
  - annotating,
  - copying,
  - sharing,
  - modifying,
  - labelling,
  - organising, and
  - separating.

| (continues…)|
|:--|
| Data as material will be new to most except data scientists. This is novel not just for end users but for designers too. Eva Deckers, in her work on _data-enabled design_, an approach to design which also calls for data to become a material, notes (and we could expand this to laypeople too): |

> _"Designers are in general not trained and prepared to work with data. They're not equipped with the right tools. Data manipulation is not part of the schools' curriculum and designers are rarely interested in understanding data."_—[@deckers2018].

| (continues…)|
|:--|
| Her work with colleagues on the 'connected baby bottle' illustrates how treating data as a design material creates a novel iterative user-centred development of new capabilities [@bogers2016]. In HDR terms, I theorise that what this material should _be_ is _human information_ - life information and ecosystem information [[7.2](#7.2)]. Data useability therefore calls for the creation of systems that enable **human information to be treated as a material**.|

As [Insight 3](#insight-3) show, data will only become useable once we change its nature. Since the 1970s, drawing on the then-common metaphor of a filing cabinet, computers have considered _files_ as the basic material that users will interact with. Where we do interact with data as information instead of files, that information is typically presented in limited contexts within certain products or apps [[Insight 1](#insight-1)]. To move up the DIKW pyramid [[2.1](#2.1)], we need smarter computer systems, that move beyond files [@bowyer2011filesdie]. We need systems whose basic material is not files, but pieces of human information.

**We need a human information operating system**.

### Obstacles to the HDR Objective of Ecosystem Awareness & Understanding{#objective-3}

As established [[2.2.5](#2.2.5); [2.3](#2.3); [6.2](#6.2); [7.2](#7.2)], HDR cannot be made effective without a sea change in the way that individuals are able to interact with the complex ecosystem of personal data they each inhabit. Our personal data ecosystems are **incredibly complex** and **largely invisible**. For example, it is easy to allow a handful of messaging and social media apps to access your contact list. Before you know it, you have created a complex and unmanageable network of connections that silently sync and propagate your addresses and phone numbers across the Internet. And there are deeper layers which are not even slightly visible to users: networks of data brokers, advertisers and digital cookie companies exchange user identifiers, activity data and personal information about you while you browse or use apps [@pidoux2022]. The ability to build up a meaningful picture of your personal data ecosystem is completely absent [[4.3.4](#4.3.4.1)] or severely limited. People remain 'in the dark', leading to fear [@bowyer2018family], overload [[2.2.4](#2.2.4)] and resignation [[5.4.4](#5.4.4.1)]. Managing one's personal data ecosystem is an **overwhelming, unmanageable task** that even personal data experts are not fully able to get a handle on. We do not feel 'in control' [@teevan2001; [2.2.2](#2.2.2.6)]. The ability to provide a user with ecosystem transparency is hindered by the complexity and multiplicity of data relationships they have been encouraged to set up. People lack tools to provide a meaningful, or indeed any, view of those relationships. In both Case Study contexts, we saw that no one individual or organisation has the ability to see the whole of a user's data ecosystem [[4.3.4](#4.3.4.3); @cornford2013]. There is little commercial motive to try and solve this problem, as each provider focuses on their own apps, websites and services. Making one's ecosystem visible, transparent and understandable is therefore an essential objective for better HDR, as [Insight 4](#insight-4) shows.

| **INSIGHT 4: Ecosystem Information is an Antidote to Digital Life Complexity** |{#insight-4}
| :------------------------------------------------------------------------- |
| Acquiring ecosystem information and understanding is a key motivator for many people—encompassing 74% of participant goals in Case Study Two [[Table 5.4](#table-5.4)]—and is essential for better HDR. This suggests two distinct goals for system builders: **ecosystem detection** and **ecosystem information display** as ingredients to help overcome the obstacle. As a representative example let us examine a recent app called SubsCrab [[Figure 7.6](#figure-7.6)]: |

![Figure 7.6: SubsCrab: An Example Application for Ecosystem Detection and Visualisation](./src/figs/fig7.6-subscrab.png){#figure-7.6}

| (continues…)|
|:--|
| This app connects to the user's e-mail account, and searches it and monitors it for e-mails from service providers such as Netflix, Spotify, Dropbox, or Google with which the user has monthly or annual subscriptions. In doing so, it is detecting part of the user's ecosystem. It is identifying which companies they have a payment relationship with. It parses found e-mails to identify billing dates and payment amounts. It then provides additional representations of that ecosystem information to the user, so that they might get on top of their subscriptions, see what they need to pay (or cancel), and feel more 'in control' [@teevan2001; [2.2.2](#2.2.2.6)] of this aspect of their digital life. From this example, it is easy to imagine other types of ecosystem detectors, which could detecting relationships with free services and websites, identify account numbers and e-mail addresses, password resets, address book syncs, OAuth logins, family identities and more. Alistair Croll and I explored possibilities for _e-mail mining_ in 2009 [@acroll2009], and while there has been some innovation in this space, it has largely been for commercial reasons [@braun2018]. New ecosystem detectors could power new interfaces, contributing to the simplification of the user's digital life. This would give people more visibility and control over their previously unmanageable data ecosystem. |
| A secondary consideration in achieving the required 'sea change' in approaches HDR, is that current PDS and SI approaches are very life-information-centric. It is implicitly assumed that the only way to unite data is to collect it. The difficulty in such an approach is that you can only collect that which you can extract. To address this, I draw inspiration from a computer programming concept known as _pass by reference_ (as opposed to _pass by value_) [@ananya2020] where data is 'pointed to' rather than moved. Productivity guru David Allen recommends the use of _'placeholders'_ [@allen2015] to keep track of tasks you cannot otherwise bring into your planning. To build a complete map of a user's ecosystem we must be able to keep track of accounts and data that are remote, much like a search engine points to information on different pages around the web. We can create **proxy representations** of service-provider-held or otherwise immobile data (e.g. data which is offline or restricted). These representations become part of the manipulable material in the user interface, and could be augmented with links to visit the remote source. |

As we start to consider _what the data is about_, new possibilities are unlocked. A PDS-type system could built that is not only a repository of personal data, but (using proxy representations), a collection of ecosystem information and _contextually-situated_ life information too. This could include information about relationships with data holders or other entities. Builders of such a system would face a further challenge—**a lack of metadata** [[2.2.2](#2.2.2.2)]. Typically, most data on our hard drives lacks context about its origin, and how it relates to the individual in a holistic life/ecosystem sense. Where data access rights are executed (or data is personally shared [[4.3.2](#4.3.2.2)]), the attention is on the data itself: what it says. But as Case Study Two showed, some of the most desired information was not the data itself, but handling information and inferences—information that can only come from metadata, which was rarely forthcoming [[Table 5.3](#table-5.3)]. Metadata could include many facets that could be quantified and recorded, as illustrated in [Figure 7.7](#figure-7.7), which I created at BBC R&D:

![Figure 7.7: Some of the Many Aspects of Metadata that Might Exist About a Datapoint or Dataset](./src/figs/fig7.7-metadata.png){#figure-7.7}

These facets can be mapped back to the 5 W's that collectively make up the user's _context_ [@abowd2000; #2.2.2.5]. Many of these facets are not explicitly recorded today, or would take significant work to capture. Nonetheless, this exploration shows how data can be better contextualised, supporting contextual and associative approaches [[2.2.2](#2.2.2.5)]. This leads to [Insight 5](#insight-5):

| **INSIGHT 5: We Must Know Data's Provenance** |{#insight-5}
|:-------------------------------------------------------------------------|
| Metadata is what gives information _context_. Context is critical to _sensemaking_ [[2.2.3](#2.2.3)] and enables good experience-centred design [[2.3.2](#2.3.2); [2.3.3](#2.3.3)]. Without context, data loses meaning [[5.4.3](#5.4.3.1)]. Collecting historical data about the individual is important for reflection [[2.2.3](#2.2.3)] and considered valuable [[4.3.3](#4.3.3.3)], but knowing the **history of a piece of data** allows its context to be understood. Data is not neutral, and is inherently biased, since it was created for a specific purpose with a specific agenda in mind [@gitelman2013; @neff2013]. To combat this bias, more context is needed. Significant research in this space has been undertaken by Professors Mike Martin and Rob Wilson at Northumbria University, formerly Newcastle University, who promote the idea of **data with provenance**; in other words: |

**Data must carry with it the details of why it exists, how it came to be, and what has happened to it since its inception.**

| (continues…)|
|:--|
| Provenance should be communicated alongside any visualisation of the data, in order for it to be fairly assessed in context. Provenance is essential for data to be trusted, argues Martin, and should be quite granular: a piece of data should be attributed not just to an individual or organisation, but to the relationship between role-holding individuals in a specific context. Greater insights can be gained when considering all actions upon data as motivated communications from one party to another; only by capturing this information in-situ can the data's meaning be fully appreciated [@martinWP]. This framing essentially advances the concept of history tracking [[2.2.3](#2.2.3)] into the sociotechnical, ecosystem-aware problem space. While everyday system designs have not approached this level of granularity, the importance of data provenance has been recognised in the PIM space. Temporal PIM systems [[2.2.2](#2.2.2.4)] from Lifestreams [@freeman1996] to _activity streams_ [@hartdavidson2012] rely upon data provenance in some form. A study by Jensen _et al._ concluded that provenance tracking can be valuable for identifying related documents, a critical part of knowledge work today [@jensen2010]. Odom, Lindley and colleagues proposed the idea of _file biographies_, which view the lifetime of a file as something that should remain connected, so it could be traversed in order to understand the context of the file different moments of interaction [@lindley2018]. This comes close to Martin's vision but does not capture the motivation for each interaction. While provenance capture is not a solution in its own right to the understanding of data and of ecosystems, it is clear that data with provenance is very likely to be a valuable part of any design that aims to provide understanding of complex and invisible personal data ecosystems.|

Paying attention to ecosystem information, metadata and provenance, facilitates a new space that, at the time of writing in 2022, almost no-one is building for. For people to manage their digital world, they need a map. This is the first step on the road to giving individuals oversight of their personal data ecosystem.

### Obstacles to the HDR Objective of Ecosystem Negotiability{#objective-4}

There are three distinct obstacles to ecosystem negotiability:

  - the intrinsic structures that give data holders power,
  - the trend of actively diminishing user agency, and
  - the intractable data self.

<a name="7.3.4.1">**Hegemony through Data Holding**</a>

It is in the pursuit of oversight [[6.2.2](#6.2.2)] and involvement [[6.2.3](#6.2.3)] that the impact of the power imbalance [[2.1.2](#2.1.2)] becomes most clear; unlike the other HDR objectives, individuals cannot act to claim ecosystem negotiability for themselves. Negotiability means having the power to act, and in the context of systems and interfaces owned and designed by service providers, **that power can only be given**. The hegemony of data holders is therefore is the greatest obstacle to this objective, so it is vital to examine the nature of that power. Where does it come from?

![Figure 7.8: The Panopticon Structure of the Illinois State Penitentiary](./src/figs/fig7.8-panopticon.png){#figure-7.8}

A helpful analogy for the relationship between provider and user can be seen in the design of Jeremy Bentham's _panopticon_ [@bentham1791], a real-world version of which is pictured in [Figure 7.8](#figure-7.8). The panopticon is an 18th century prison architecture that elevates the power of the (hidden) prison guards to observe all the prisoners easily at any time while removing prisoners' privacy and providing them no ability to observe those in power. As in Orwell's _Nineteen Eighty-Four_, individuals are unable to know when they are being watched (in this case, because the guards are hidden from view by one-way screens). This enforces compliance. Structuralist philosopher Foucault interpreted the panopticon as a political design, recognising that human environments can be configured to influence or regulate behaviour, in order to defend the power of the ruling class [@foucault1975]. Such designs embody his four principles:

  - **Pervasive Power**: the guards see everything all the prisoners do, all the time
  - **Obscure Power**: the guards can see into any cell at any time, but the prisoners can't know when, how or why they are being observed
  - **Direct Violence Made Structural**: the structure motivates the prisoners to self-regulate their behaviour without being coerced (through beating or punishment)
  - **Structural Violence Made Profitable**: having been made compliant by the structure, the prisoners can be put to work for the benefit of those in power, as it is the only option available to them.

We can see at least three of these traits in modern Internet platforms such as Facebook today. These platforms monitor users' behaviour (pervasive power) without their knowledge and without accountability (obscure power). Interfaces are designed to offer only those actions that benefit the platforms (for example, clicking ads, sharing content or spending more time on site (structural violence made profitable). This has happened through the processes of _platformisation_ and _infrastructurisation_ [@helmond2015; @plantin2018], which have supplanted the Web 2.0-era promise of a free, open Internet that could have been more empowering to individuals.

Through the control of data and of interface design—the only channels through which they can be observed—**service providers and platforms assert a structural power over the digital landscape**. Just as the design of the panopticon regulates the behaviour of the prisoners, so the configuration of platforms, apps and service interfaces we use regulate and limit our behaviour as users. As Lessig wrote, **_'Code is law.'_** [@lessig2000]. This infrastructural power is explained further in [[Insight 6](#insight-6)] below.

Structural power is not the only form of power which modern-day data-centric service providers hold. Jasperson _et al._'s extensive review of types of power in the context of technology organisations [@jasperson2002] identifies 23 different power paradigms, of which at least 13 can be, and are, asserted by data-centric organisations today:

- _**authority**_: ownership of technology or infrastructure (for example of websites, servers and code)
- _**resource control**_: controlling the flow of resources (in this case of information/data)
- _**systems/structural power**_ structural manipulation of others (as detailed above)
- _**rational power**_: controlling decision-making processes
- _**disciplinary power**_: using an influential position to affect others' mental models (for example, positioning location tracking as theft resilience
- _**zero sum power**_: winning a battle for ownership/resource control at the other party's expense (e.g. losing control of your sacrificed data)
- _**behavioural influence**_: persuading others to carry out the desired behaviour (e.g. restricting features to motivate subscription payments, or promoting certain content or actions)
- _**interpretative influence**_: determining how reality is externally represented (e.g. Facebook determining the way in which your social network is represented to you)
- _**network centrality**_: becoming an indispensable hub of a wider ecosystem (for example, Facebook/Google dominance in online ad-brokering)
- _**processual power**_: changing processes for competitive advantage (for example, platforms offering preferential APIs or rates to compliant partners)
- _**socially shaped power**_: influencing a wide audience to settle upon a preferred interpretation (e.g. using dominant market position to dominate debates e.g. about privacy norms)
- _**interpretive power**_: creating the internal representations of reality within an organisation (for example, presenting unpopular attitudes to data privacy to staff as normal/acceptable/beneficial for business)

| **INSIGHT 6: Data Holders use Four Levers of Infrastructural Power** |{#insight-6}
| :------------------------------------------------ |
| Hestia.ai [[ARI7.2](#ari-7.2-digipower)] have produced a model to explain the mechanisms by which technology companies gain power and use it to shape today's digital landscape. In this model, _infrastructural power_ comes from three things: |

_**technical ability**_,
_**organisational ability**_, and
_**the acquisition of data about individuals and populations**_.

| (continues…)|
|:--|
| As organisations (especially platforms) collect more data, and grow in market influence or technical capability, they gain power over individuals and over other organisations. They exert this power using four 'levers'. Simplified and expressed in the terms of this thesis, these are:

  1. **Collect & Interpret Data to Acquire Knowledge**: Data and signals are collected from individuals and interpreted in order to infer their intents and interests. For example, Google collects raw GPS and wi-fi hotspot data from mobile phones, which it then statistically analyses to infer which shops or venues you visited and what forms of transport you used, increasing Google's knowledge about individuals and populations.
  2. **Present Content and Configure Structures to Influence Individual Behaviour**: Knowledge of individual intents and interests is exploited within user interfaces to influence desired individual actions. For example, Facebook or presents a user with a product relevant to their interests, which they are motivated to click upon, generating ad revenue. Another example would be Twitter manipulating the content of the user's feed to show more tweets from conversation topics where they can show promoted tweets, increasing ad revenue.
  3. **Configure Structures to Improve Knowledge Acquisition**: A provider uses its dominant position to force other organisations to improve the provider's ability to acquire knowledge. For example, Google provides free analytics tools to web developers, but requires the end users of those client websites to supply visitor data back to Google, increasing their ability to acquire knowledge about individuals and populations.
  4. **Configure Structures to Disadvantage Others**: Certain providers (typically of operating systems or popular devices) can configure the structural relationships between other parties. For example, a smartphone manufacturer could limit data exchange between other apps, while still extensively collecting data signals themselves, such as when Google was found to be collecting call history from Android's dialer app.

| (continues…)|
|:--|
| The precise mechanisms and techniques employed when exerting infrastructural power, as well as the social and market consequences of these practices, are explored in detail in Hestia.ai's digipower technical reports, of which I was a co-author [@bowyer2022hestia; @pidoux2022]. |
| The research highlights that providers' power is far greater than many realise. Unlike in the physical realm, providers of popular online platforms can **reconfigure the landscape to change the way that individuals perceive reality**, in line with the powers of interpretative influence, behavioural influence and socially shaped power described above [@bowyer2022hestia]. Providers control the extent to which (if at all) data stored behind the scenes, and internal processes that use that data, are visible, and how data and processes are represented.|
| The model shows that the accumulation of data (and hence, information) is implicitly and objectively a form of power, consistent with participants' observations in [5.4.4](#5.4.4.1). As long as current service providers are free to collect so much personal information, the information landscape is likely to remain imbalanced and individuals will not be able to acquire ecosystem negotiability. |
| This insights shows that the most powerful data holders exert huge influence over the digital landscape, in terms of what is _knowable_ and what is _doable_. HDR reformers' abilities to balance the landscape are hindered by the fact that they are operating in a landscape that the incumbent platform and service providers effectively control. |

<a name="7.3.4.2">**The Active Diminishing of User Agency**</a>

The second major obstacle to ecosystem negotiability is that platformisation and power exertion are not a one-off transition, but rather an ongoing process. Today's platforms exhibit **a continuing trend of actively diminishing individuals' agency**, especially in the last decade. When software was sold in a box, manufacturers competed based upon which product would let the user take home the greatest range of features and capabilities. New releases with new features drove new product sales. But in the cloud computing era, a smaller set of core features done well is sufficient to guarantee an ongoing subscription revenue from a user. Cost savings in development and support costs can be made by reducing feature sets. Constrained, compliant users are easier to manage. The relentless pursuit of increased profits and further cost saving sees products lose, not gain, features. Interfaces are reshaped to serve businesses' interests first and foremost. Providers' focus on making user behaviours constrained, predictable and profitable, more than meeting their needs or providing maximal value [[2.3.5](#2.3.5)]. Plantin _et al._ describe the particular harmful influence on the ecosystem of Facebook's power exertions:

> _"Facebook is a formidable force in a profit-motivated platformisation which is beginning to eat away at the Open Web.  This entails moving away from published URIs and open HTTP transactions in favour of closed apps that undertake hidden transactions with Facebook through a Facebook-controlled API."_—[@plantin2018]

Here are just a few examples of the ways in which users' agency has been, and continues to be, diminished:

- Facebook closed their RSS feeds, and later parts of their APIs, meaning that users could no longer consume their friends' posts in any other environment than the ad-filled and manipulated Facebook main feed. Later, they eliminated feeds of friends' posts and favourite pages, removing users' ability to compartmentalise their content viewing to certain friends groups. The 'Friends' page on Facebook currently shows a list of recommended new friends. To access your current friend list requires an extra click. Encouraging users to grow their networks is prioritised over user convenience.
- Twitter closed the parts of its APIs that allowed real-time notifications and access to one's home feed, killing off primary functionality for a healthy ecosystem of third-party Twitter clients that increased user choice [@newton2018]. TweetDeck, a major third-party Twitter client was acquired, and later shut down, as was Twitter's own desktop client. Eventually, the only option left to users was to use the web interface. [@gayomali2015; @hatmaker2018; @siegal2022]
- Apple has been diminishing users' agency for a long time. Users cannot open up iPhones even to change the battery without invalidating their warranty. Apple have removed disk drives, headphone ports, SD card slots and other ports. Certain parts of the hard drive on macOS devices are now read-only and non-writeable by users.
- Facebook recently announced they will no longer store users' historical location data (though they will still use location information) [@pegoraro2022]. This means users will lose the capability to access historical location records. But this makes it harder for users to see how their location data will be used in future, as there will be no historical log to examine. Data-centric companies can change their practices to limit agency and reduce accountability.
- Online news and discussion site Reddit has removed content access for non-logged in users, and uses deceptive techniques to present advertisements that look like posts from users, and to discourage users from appearing offline. These patterns have been described as _disrespectful design_ [@regoje2021].
- In an example from the public sector, through my work on the SILVER project [[3.4.1](#3.4.1.1)] just prior to the introduction of the GDPR in 2018, I heard whispers in at least one local authority of plans to 'shift from getting data collection consent from supported families towards simply informing them of our practices' (in other words, removing their choice). The instinct to further organisational interests over those of the individual appears not to be limited to commercial data holders.
- In a similar vein, TikTok recently announced that it would rely on _legitimate interest_ rather than consent when it comes to using users' activity data to personalise the app experience. This removing users' ability to withdraw consent to such use. This plan has subsequently been paused after warnings that this might breach GDPR [@lomas2022].

Unchecked, trends to reduce users' agency and further providers' interests at the expense of human autonomy are likely to continue. Today's data-centric systems suffer from a lack of consideration to individual welfare. Data centricity encourages neglect of the human end user perspective, creating potential for harm:

> _"There are certain things you do not in good conscience do to humans. To data, you can do whatever you like."_—[@sonnad2022]

The trend to diminish users' agency is needs explicit targeting if data interfaces are to become more free-flowing [@bowyer2018freedata], and if ecosystem negotiability is to be realised. Somehow, the trend needs to be halted, before it can be reversed. The TikTok example suggests this can only be achieved through regulatory changes.

<a name="7.3.4.3">**The Intractable Data Self**</a>

The third obstacle Ito ecosystem negotiability is _the intractable data self_. Data about individuals serves as their proxy [[@bowyer2018family; [5.4.4](#5.4.4.1)]. This is their _data self_ [[4.4.1](#4.4.1.3)]. If it is incomplete, inaccurate or unfair—highly likely given the difficulties of representing people in data [@cornford2013; @martin2007]—which can cause harm [@bowyer2018family; @crossley2022]. Yet currently, although some legal rights to data correction exist [@ico2018], people cannot modify or assert control over this most important version of themselves—the version of them that exists in data. Even when data can be seen, people lack the ability to **exert influence over their data self** [[5.5.2](#5.5.2); @cornford2013]. To address this obstacle, HDR reformers should explore giving people a role in the curation of their data self [[4.4.3](#4.4.3); [5.5.2](#5.5.2)] and [6.3](#6.3)].

To date, research and innovation on ecosystem negotiability has been very limited. It is easier to find business models and research funding for narrow and well-defined contexts. Without a business motive, only non-profit socially-focussed research organisations such as BBC R&D and Sitra have found themselves well-equipped to explore this problem space. Nonetheless, there is an urgent societal need. People need to reclaim their data selves, and be given control over their digital lives at the broadest level.

### Obstacles to the HDR Objective of Effective, Commercially Viable and Desirable Systems{#objective-5}

In the previous four subsections, the obstacles to the four identified HDR objectives [[7.2.4](#7.2.4)] were considered. However, during attempts to tackle these objectives, and through observation of how the public and businesses were engaging with the growing Personal Data Economy, it became clear that there are certain obstacles that are specifically faced in this sector that affect _all_ efforts to make progress towards improving HDR. The main challenge is around building such disruptive systems that are so different from the status quo: **businesses and individuals will not readily invest time and money in HDR, because it is unfamiliar**. Customers are not demanding HDR capabilities in their lives, and, all but the most socially responsible businesses do not immediately see the value in something that runs so contrary to their current business models which are based on the accumulation of data and the control of customer experiences.

Today, data is overwhelming, complex, and 'sounds boring'. Currently, engaging with one's personal data economy to any degree more than that of passive consumer is hard work. People routinely accept data sacrifice, click through T&Cs and cookie banners and are unwilling (or in some cases lack sufficient technical literacy, comprehension or skill) to do the work of asserting control over their digital lives. There is not a clear demand for holistic and novel ways of managing your digital life and exerting agency and negotiability over it. Across both Case Studies and the PDS work at BBC R&D, it was clear that even if new **human-centric information systems** and more inclusive service interaction practices could be created, we cannot assume that people will be inclined to use them in great numbers, especially not if it seems like hard work or not worthwhile. This can be seen as an obstacle that affects all HDR improvement approaches we see, and indeed is why many companies in the emergent PDE economy [[2.3.4](#2.3.4)] struggle to find a business model - while there are clear benefits, better HDR does not appear to something that a mainstream audience would be directly be willing to pay for. But this should not deter disruptive innovation nor does it indicate that such offerings would not be useful. As automobile pioneer Henry Ford famously said, _"If I had asked people what they wanted, they would have said faster horses."_ Nonetheless, it is a clear overarching obstacle to overcome.

| **INSIGHT 7: Human-centred Information Systems must serve Human Values, Relieve Pain and Deliver New Life Capabilities** | {#insight-7}
| :------------------------------------------------------------ |
| Through work at BBC R&D exploring how to better connect people with their data, it became clear that there is a way to combat such indifference and apathy of users. It emerges from the realisation that the way people find value in data is to connect it their lives. The more that people see relatable life information and can imagine ways to harness that information in their everyday life, the more motivated they will be. BBC R&D conducted some research [@forrester2021] that identified fourteen specific Human Values that people seek to satisfy in their lives, which are shown in in [Figure 7.9](#figure-7.9). These are, at the most abstract, goals that people care about in their daily existence. |

![Figure 7.9: Human Values, as Identified in BBC R&D Research Funded by Nesta](./src/figs/fig7.9-bbc-human-values.png){#figure-7.9}

|(continues…)|
|:--|
| Given these and the earlier observation that life information is what makes data relatable, the insight I offer here is that **the way to make people care about their data is to use it to help them in their life**. By starting with a focus on a user's world, one can then focus in on their life, and then the data that represents elements of that life. Then, the individual has a vested interest. Systems and features should be designed from this life-centric perspective. This is known as **_value-centred design_** [@reber2005] and it has been argued that this should become the guiding design philosophy in HCI [@cockton2004]. And to offer true individual value, all human-centric system designs must also consider _context_ [[2.3.2](#2.3.2)], _environment_ [@abowd2012] and _experience_ [[3.2.1](#3.2.1). In business modelling, there is a tool called the _value proposition canvas_, which identifies three ways of conceptualising value: _**gain creators**_, _**pain relievers**_ and _**jobs-to-be-done**_. If we can use those concepts to inform our designs, we can produce better human-centric functionality - relieve an individual's pain points, help them complete their tasks, or offer them some gain over the status quo. In the HDR space, given the lack of existing tools for digital life management, we have the opportunity to create quite a unique type of gain: **new capabilities over your digital life** that you have never had before. This ability to do new things has been identified as key ingredient of user empowerment [@meschtscherjakov2014; @schneider2018]. |
| Here is an example of what this value-centric approach might look like in the HDR space: Myself and BBC R&D colleague Jasmine Cox imagined focusing on address books and contact lists as a strong relatable starting point to generate demand for a human-centric interface. This could provide people with new life capabilities while also relieving pains. Many people have address and contact information scattered far and wide, and face a complexity they cannot easily manage when it comes to the automated syncing and sharing of potentially sensitive contact information between devices, apps and providers. Developing human-centric personal information management capabilities to bring that messy situation under control would offer a clear and tangible benefit to users. In [Figure 7.10](#figure-7.10), we show how there could be a strategic path, beginning with detecting ecosystem and life information from the individual's calendar and e-mail inbox, through to building up to more holistic life-level PDS capabilities. |

![Figure 7.10: A Contact-and-Calendar-centric PDS Approach](./src/figs/fig7.10-calendar-contact-centric-PDS-strategy.png){#figure-7.10}

|(continues…)|
|:--|
| A helpful example is that of a vacation from my 2011 article [@bowyer2011filesdie] and shown in [Figure 7.11](#figure-7.11)]. Today, all the information around such a holiday is scattered into multiple systems - emails, online provider bookings, chat logs, cloud synced photos, web browser bookmarks, smartphone location logs, etc. It is not hard to imagine that a system that was able to bring all related information about that vacation together in one central interface (mock-up in [Figure 7.12](#figure-7.12)) could deliver huge value to users and be very compelling.  Such context-targeted human-centric offerings can have a much greater chance of generating interest and impact than offerings that merely allow you to 'organise your data' or some other abstract phrasing.|

![Figure 7.11: The Scattered Data Relating to a Vacation](./src/figs/fig7.11-vacation.png){#figure-7.11}

![Figure 7.12: Mock-up of a Unified Interface for a Vacation](./src/figs/fig7.12-holiday-interface.jpg){#figure-7.12}

The kind of life-spanning, unifying interfaces described in the insight above are nothing like the interfaces that are built today, as they span across different providers' data and services. This highlights the secondary obstacle that all HDR system builders will face, whichever objective they wish to target: **closed, self-interested organisations with a lack of interoperability**. Building an HDR system will necessarily involve connecting to systems of different providers that have different touchpoints into an individual's life and world. Yet most companies act in closed, introspective and non-cooperative ways to further their own interest. Companies like Apple, Amazon, Microsoft, Facebook and Google (the so-called _'big five'_) build **proprietary, incompatible silos** or _'walled gardens'_—sub-Internets that pretend that the alternatives do not even exist, in order to encourage a flow of money and attention to their own products and services. Commercial motives encourage them to get users to spend time in their own proprietary spaces (so that resultant ad revenue can be captured) and in order to maintain subscription revenues it is in providers' interests to make it hard for individuals to leave or switch providers. In effect, providers build for a world that does not exist, where **every individual is imagined to only interact with that single company's interfaces**. I would argue, for example, that Google's venture into social networking with Google+ did not succeed because it failed to build for a reality where most people and their friends were already on Facebook. But one can understand their motives; there is little incentive to open up the ecosystem when the free flow of information and of users might result in loss of income for the company in question. Users with negotiability would be more able to leave. And this also encourages keeping users in the dark [[5.4.2](#5.4.2)]. The less agency and negotiability that users have, the more freedom the provider has to do exactly what they want with their data. In this context, users are _'pathetic dots'_ [@lessig2000] or _'docile bodies'_ [@foucault1975].

The tendency of organisations to work in closed, introspective practices and to be resistant to opening up data or services is not solely motivated by commercial reasons: the public sector has a vastly complex, closed and fragmented ecosystem [@pollock2011; @copeland2015; [4.1.2](#4.1.2)]. Efforts to build a system to share health data with support workers for the SILVER project [[3.4.1](#3.4.1.1)] proved hugely challenging. Sometimes the challenge was a more technical one - incompatible data formats that are hard to reconcile, or data being stored in legacy systems with no public API that would allow programmatic access to that data, or issues around licensing. Data sharing agreements must be established, especially in the public sector which is by its nature more liable to scrutiny and accountability. But more than these technical or procedural issues there was resistance to change in data processes and an unwillingness to share data between agencies, often motivated by a fear of legal repercussions. **Data-centrism encourages insular thinking**: it encourages organisations to codify the world into their own systems, processes and formats for their own use.

And yet, for effective HDR, **data needs to be separable from services**. The more users data is tightly coupled to specific services, the less agency users have and **the harder it is to build life-centric systems**. On BBC R&D's Cornmarket project, attempts to build an interface for users to import data from multiple popular Internet services proved to be a hugely complicated endeavour, requiring access to many different APIs or manual exports and imports of data by users. There needs to be greater interoperability and **greater establishment and adoption of standard formats for exchanging human information** (as distinct from establishing standards for data or service-specific APIs). As mentioned above, platformisation breaks the Open Web [@plantin2018]. To overcome this, companies must be persuaded that human-centric thinking, interoperability and transparency has not just social benefits, but business benefits too.

But at an abstract level the technical obstacle, the problem is one that has always faced the tech industry, which is that there often is no universally agreed way to represent important concepts - in this case human-centric information concepts such as events, social media posts, website visits, location history information, app activity, etc. And any entity that does create a standard then faces the challenge of trying to persuade others that their standard is the best one to use. In general, standards work best when established by non-commercial industrial standards bodies (for example the World Wide Web Consortium (W3C) or International Organisation for Standardization (ISO) and then mandated through policy such as European Union law. Such standards much be established with input from industry experts.

| **INSIGHT 8: We Need to Teach Computers To Understand Human Information** |{#insight-8}
|:----------------------------------------------------------------------|
| In order to move towards standardised ways to store and unify personal data from multiple sources, computer systems must be taught to understand the information within the data, and how it relates to an individual and the world. This moves beyond just capturing data provenance: put simply, **computers need to understand human information**. They need to move beyond files [@bowyer2011filesdie] and databases, and begin to perform operations on human informational concepts, and to associate those concepts according to what they mean - i.e. **_semantically_**. This is a preliminary step that will enable the building of systems and interfaces that are able to deal in human concepts and represent the elements of everyday life.|
| We need to store **semantic context and semantic associations**, i.e. the meaning of things, not just raw bundles of data. This is advocated by the Web's inventor Tim Berners-Lee in his vision of a Semantic Web [@bernersLee2001] and by proponents of _networked_ and _semantic_ PIM systems, as detailed in [2.2.2](#2.2.2). There is a need to develop standard ways to digitally model facts and assertions about users' lives, so that those disparate pieces of data can be unified, connected, correlated and compared. Some standards are already developing, such as _data shapes_ [@shapeRepo]. And the extraction of meaning from data is a problem domain all of its own. Sizable industries have built up around Content Analytics and Enterprise Content Management. But to consider the problem at its simplest level, I offer this insight: Through **the capture of metadata** at the point of data recording, and through **subsequent programmatic analysis** of stored data, as illustrated in [Figure 7.13](#figure-7.13), we can begin to teach computers what the data we store represent.|

![Figure 7.13: Annotating Data with Semantic Context](./src/figs/fig7.13-semantic-annotation.png){#figure-7.13}

Machine learning technologies and Artificial Intelligence have pushed machine understanding of human words, images and content to impressive levels in recent years and such technologies can certainly be helpful, but in fact at the core what we are talking about here is something much simpler than AI; It is simply about labelling datapoints in as many different ways as possible so that those datapoints can be associatively retrieved from many different angles, and providing humans with ways to amend incorrect labels and to reclassify data or apply new semantic associations. Issues of interoperability for PDS systems are being actively explored and developed in the _'Solid'_ community [@bernersLee2022inruptSolid; @bansal2018] in pursuit of a decentralised web [@verborgh2017].

Such approaches are in their infancy, and have not yet been adopted extensively in commercial settings. Even after addressing the obstacles of end-user buy-in and the technical complexities of building human-centric systems, data-driven corporations, motivated as they are by profit and business success (and smaller online organisations too) need to be persuaded of the business value of transparency, interoperability and human-centricity. This is explored further in [7.4.5](#7.4.5).

In summary, whichever of the above four HDR objectives are targeted, all HDR reformers involved in building HDR systems must:

  1. create, adopt and co-ordinate around **new standards** for human information storage and management
  2. invest in systems that elevate computers from data-processing machines to **human-information-processing machines**, and
  3. make a persuasive case to both businesses and individuals that the new approach offers **tangible, previously unavailable value**.

The landscape of opportunity: Four approaches to improving Human Data Relations {#7.4}
------------------------------------------------------------------

In this section, I will present four different 'flavours' of activity, that we can pursue as HDR reformers. These are represented diagrammatically as trajectories of change using a model known as _Theories of Change (ToC)_ which is explained in [[7.4.1](#7.4.1)].

These trajectories for change could be supported or pursued in many different ways, which may appeal to different readers:

  - prototyping and creating proofs of concepts;
  - fundraising or investment; design activities;
  - market research, participatory research or usability research;
  - 'early adopter' testing and quality assurance of PDE / PDS offerings;
  - promotion, advocacy and journalism of HDR issues;
  - critical audits of provider practices;
  - policy design;
  - political pressure on governments and regulators;
  - participation in open data, PDE, civic hacking or MyData communities; or even
  - individual self-experimentation with HDR tools, rights and capabilities.

### A Primer on Theories of Change (ToC){#7.4.1}

To provide a structure for cataloguing the insights conveyed by this section, I use a _Theory of Change (ToC)_ framing. ToC is a set of methodologies is commonly used by philanthropists, educators and those trying to improve the lives of disadvantaged populations [@brest2010]; the theories can be used in different ways including planning, participatory design and field evaluation of the effectiveness of new initiatives. There are many different implementations, but common to most of them is a focus on explicitly mapping out desired outcomes [@taplin2012] with a clear focus on who is acting and whether the change being brought about is a change in action, or a change in thinking [@vanEs2015]. In this section, ToC theory will be used in a very limited way, not as a methodology but simply to provide a structural frame for proposed changes, as described below. Using ToC to perform evaluation of the effectiveness of proposed change approaches in action in society would be well beyond the scope of this thesis. Nonetheless, this frame is a useful way to map out the different approaches to changing the world in pursuit of the ideal of better HDR.

![Figure 7.14: Theory of Change [ToC]\: The Four Dimensions of Change[^17]](./src/figs/fig7.14-dimensions-of-change.png){#figure-7.14}

[^17]: Diagram used here unchanged from _Hivos ToC Guidelines_ [@vanEs2015, 90] under a CC-BY-NC-SA 3.0 license, whose authors state that this diagram was adapted from earlier work by Wilber (1996), Keystone (2008) and Retolaza (2010, 2012).

[Figure 7.14](#figure-7.14) illustrates the aspects of ToC thinking that are important when using this frame. Specifically, desired changes can be broken down into:

- _**Internal changes**_: changes in thinking, feeling, reasoning, understanding, attitudes or identity.
- _**External changes**_: changes in actions, behaviour, interactions, structure, policy, technological capability, processes and the external environment.

At the same time, desired changes can be broken down into:

- _**Individual changes**_: changes to individual thought or actions
- _**Collective changes**_: changes to the thoughts or actions of groups of people together, or to the systems, practices and norms of society at large.

These two splits produce four dimensions of change, and form four quadrants representing different types of change, which are shown in [Figure 7.14](#figure-7.14) and described here:

- _**Individual/Internal (II)**_: This top-left quadrant represents changes to what individuals know and understand, and to how they think, feel and plan to act.
- _**Individual/External (IE)**_: This top-right quadrant represents changes to how individuals' relationships with others; acting (or being enabled to act) differently in their daily lives and when interacting within society.
- _**Collective/Internal (CI)**_: This bottom-left quadrant represents changes in the shared knowledge of groups of people or to the collective identity or values of social groups.
- _**Collective/External (CE)**_: This bottom-right quadrant represents changes to the structures and procedures within which people operate, including technology, law, societal norms and communications.

Key to ToC thinking is the idea that making changes in one quadrant can stimulate change in others; for example, collective learning about data attitudes and practices, such as the research conducted in this PhD, (lower left quadrant) could inform the design of new technologies, interfaces or processes (lower right quadrant), which if built could make new structures available to have an impact on improving individual-provider relationships (upper-right quadrant). The changes to those relationships could then in turn lead to individuals thinking and feeling differently (upper left quadrant), for example feeling more empowered or having greater awareness of data practices. The diagram at the start of each of the following four subsections illustrate that approach's trajectory of change through the ToC quadrants.

### Approach 1 to Improving HDR: Discovery-Driven Activism{#approach-1}

![Figure 7.15: HDR Approach 1: Discovery-Driven Activism](./src/figs/fig7.15-hdr-approach-1.jpg){#figure-7.15}

The approach to HDR reform presented in this section, and illustrated in [Figure 7.15](#figure-7.15) above, embraces the _activist_ aspect of being a recursive public [[7.2.5](#7.2.5)], as well as the idea of reconfiguring one's world. This approach focuses on the realities of the current data-centric provider ecosystem, and is focused upon deeply understanding it so that it can be challenged from a grounded position of strength. The approach, which would be applied typically to a single service provider, app or platform (which could also be a public sector service) is fourfold:

  1. **Gather Evidence**: Using all available means, gather personal data and information from the target organisation.
  2. **Determine Current Practice**: Analyse the gathered data and information, using targeted approaches to dig deeper where needed, to establish facts about how the target organisation stores and handles personal data.
  3. **Identify Desired Change**: By consideration of the specific practices observed from the analysis, specific problematic practices, gaps or areas where improvement or change is needed are identified.
  4. **Appeal for, or Compel, Others to Act**: Using all available means, directly or indirectly persuade or force the target organisation to execute the desired change.

I describe this approach as **Discovery-Driven Activism**. The discovery phase, which aims simply to establish facts about the past or current data practices of the target organisation, can be broad (_'let's see what we find'_, as in the [digipower investigation](#ari-digipower)), or highly targeted, such as when _The Citizens_ (a non-profit pressure group in the UK who _'use impact journalism to hold government and big tech to account'_ [@citizens2020]) used Subject Access Requests to investigate a breach of personal data by the Labour Party in the UK [@colbert2022].

**_Subject Access Requests_** and **_Data Portability Requests_** [@ico2018] are two of the most powerful tools for this kind of investigation. Similarly to Freedom of Information Requests which have used to obtain otherwise hidden data and information from governments and public sector organisations [@bbc2014foi], so these new data access rights are beginning to be used to force commercial organisations to release personal data or information about data processing. There are challenges in non-compliance, as discussed in [5.4.2](#5.4.2.2) and [5.5.1](#5.5.1), but the ability for the individual to ask very broad or very precisely targeted questions and to be able to threaten a complaint to a Data Protection Authority if that question is not answered, is a significant new power that HDR reformers can exploit.

| **INSIGHT 9: Individual GDPR requests can compel companies to change data practices.** |{#insight-9}
| :--------------------------------------------------------------------- |
| In this inset box, I will show, using a mini case-study from my own direct personal experience, how one person can apply the discovery-driven activist approach to compel a multi-billion-dollar international data-centric organisation to improve their HDR. |
| As an avid user for several years of the music streaming service Spotify who has built up a large library of playlists, I have made a number of GDPR requests to get copies of my personal data. When I was first given a copy of my personal data, I was returned a basic ZIP file including 12 JSON files containing playlists, search queries, account information, my last 12 months of track play history, and inferences about my musical tastes. Spotify also make an extended data download available, including technical log data, and extended play history (which covers the lifetime of my account). I requested this extended download and received a much larger dataset with 175 JSON files, including granular details of when I had used different interface features and the precise details of every song I had ever played. Thinking that I would like to use this data to build a view of my listening history that was not tied to the Spotify platform (in line with the idea of increasing agency by separating one's data from the service that holds it [[7.3](#7.3)]), I examined the streaming history and playlist data with this purpose in mind. What I found was that individual songs were identified only by textual strings of the title, artist and album name. This information is insufficient for a programmer's use - there is no unique identifier or Uniform Resource Indicator (URI) to uniquely identify the specific version and release of a track played. Also without such an identifier, it would not be possible to generate a thumbnail image of the track, or build functionality such as a clickable link to 'play this track in Spotify'. |
| This highlights a common issue that occurs with data access requests, as highlighted in [5.4.3](#5.4.3.2) - there is ambiguity over whether providers should identify data in a machine-readable way (useful for programming), or in a human-readable way (to optimise understanding). In my case, I needed both. I e-mailed Spotify back and was provided with an alternative file set which contained only Spotify Track URIs, such as `spotify:track:5CKqyYTZqp6Nb4b3kJjUL5`. These met the programmer need to uniquely identify the track, but not the human need - I had no idea which artist or track each of these URIs corresponded to, as there was no human-readable text accompanying each entry. So, I e-mailed Spotify back, making the case that my GDPR rights had not been fully satisfied, because I needed _for each play history entry_, both machine-readable ID and human-readable track title and artist name. I sent Spotify over 30 e-mails on this matter between October 2020 and May 2021. There is little continuity of conversation between support agents, and hard to be escalated to the correct staff with the technical or legal expertise to assist with such nuanced questions. However, by persistently and politely repeating my questions and not accepting No for an answer, I was able to achieve a notable outcome, Spotify **changed the format of their data returns**, not just for me but  **for all future customers**. Now, each item in the playback history data you get back from Spotify, every item includes textual track and artist details AND a Spotify track URI. The data can now be understood by both human and machine. The likely interpretation here is that I successfully able to persuade their Data Protection Officers (who handle GDPR requests) the importance of returning data that is both machine-readable and human-understandable. Perhaps they also recognised the amount of work they had invested in supporting my query, and wanted to **avoid having to do such work ever again** should I or any other customer make the same request in future. This was a tiny impact, but a lasting one, and it shows that the discovery-driven activism / civic hacking approach can have an effect in improving HDR with a target organisation. |
| A larger scale example of individuals forcing giant corporations to change is seen in the case of Facebook. In the early 2010s, Austrian lawyer Max Schrems began to pressure Facebook to disclose more personal data to their users. He created a tool to enable people to make their own data access requests, which over 40,000 people used. Faced with an overwhelming volume of work and massive liability of future data access requests, Facebook was forced to launch the self-service 'Download Your Information' (DYI) download tool, increasing transparency for all Facebook users worldwide [@solon2012]. Facebook was forced to increase its transparency further when Paul-Olivier Dehaye (now CEO of Hestia.ai) made a GDPR request (later backed by legal action) to force Facebook to disclose more information about which advertisers Facebook had enabled to target him using the Facebook Custom Audiences feature. Apparently in order to avoid being embarrassed in court, Facebook updated DYI so that your downloaded information includes a list of advertisers who have added you to a Custom Audience [@dehaye2017]. Dehaye and Schrems both continue to act as HDR reformers and civic hackers following the discovery-driven activism approach, through their organisations Hestia.ai and privacy rights organisation noyb.eu ('none of your business') [@schrems2017] respectively. |

Facebook's DYI tool, mentioned in the insight above, represents a useful class of tool in the arsenal of the activist HDR reformer. Along with Google Takeout, it is one of number of **_'data download portals'_** that allow users to download their own data. Since GDPR's introduction in 2018, an increasing number of large online platforms including Facebook, Google, Apple, Netflix, Twitter, Spotify, Uber, Instagram and Strava, faced with the need to reduce the cost impact of GDPR request handling for their large userbases, have developed and augmented online self-service portals available where users can download a copy of their personal data. This has some advantages over Subject Access Requests in that data can usually be obtained within minutes or hours rather than taking up to 30 days, but has some disadvantages in that the data returned is a voluntary offering by the company, that may not cover the data that the individual is seeking and does not provide any ability to ask follow-up questions. This technique was sometimes used as a fallback means to obtain data in Case Study Two, and was used more strategically in the [digipower project](#ari-digipower), where its merits and limitations are discussed [@bowyer2022hestia]

Both access requests and download portals rely on the organisation in question to be transparent, accurate and thorough in their provision of information, but an alternative technique of **_data flow auditing_** allows individuals to investigate and collect data on the _actual_ behaviour of a target organisation. This was used effectively in the [digipower project](#ari-digipower). Using an Android app called TrackerControl [@kollnig2021tc], a service provider's app can be monitored while the user is using it normally, to see which servers or domains that app is contacting (and one can imply, exchanging data with). Apple has recently introduced an equivalent function on iOS known as App Activity Reports [@apple2022appPrivacy], providing iPhone users with the same ability as part of the phone's operating system. This has limitations in that the content of the data exchanges is not known, but can serve as a valuable tool to verify claims made in privacy policies or GDPR responses, and also as a means to _generate questions_ for further investigation, for example by identifying third parties such as data brokers which the target organisation may be sharing personal data with. This technique is described further in [@bowyer2022hestia], along with a comparison of the different techniques of data flow auditing, data download portals and data access requests.

In general, what the discovery-driven activism approach highlights is that there is a role for pro-active citizens to play in challenging the power of data-holding organisations by treating those organisations as a subject of investigation, both in research [@walby2012] and in the pursuit of improving civic society [@schrock2016].

Once information has been obtained, the HDR reformer activist can use a variety of means to try to bring about the desired change. If a target organisation fails to comply with a data access request, or a demand to erase or correct data, they can be _**reported to the Data Protection Authority**_. In some cases even the threat of this (which can carry a large fine) can be enough to compel the organisation to change. If a breach of law is found, the target organisation could be _**taken to court**_, as seen in the Schrems case above, which resulted in new legislation that Facebook had to comply with [@kuchler2018]. As well as individual cases, this also often happens in the form of class action lawsuits, as with Facebook and Cambridge Analytica [@bowcott2018]. Increasingly, unethical or illegal data practices are being challenged. In some cases, such extreme measures are not needed. Simply _**making data available to the public**_ can be empowering to society at large. This approach has been demonstrated by the UK website TheyWorkForYou, which increases democratic accountability of MPs by making MP's votes and public statements more readily accessible [@mySociety2004]. As well as structured _'impact journalism'_ such as that conducted by The Citizens as mentioned above, another technique available to individual activists is _**public shaming of misbehaving organisations**_, especially on Twitter. While the ethics of this are complex and it does not always succeed, the technique has been used effectively to force organisations to change, in order that they might avoid further bad publicity [@silver2014; @braw2022].

| **INSIGHT 10: Collectives can compare and unify their data and use their pooled knowledge to demand change.** |{#insight-10}
| :--------------------------------------------------------------------- |
| Increasingly, the Internet experience that individuals experience is not the same as anyone else's. Thanks to recommendations, targeted ads and social media feeds personalised to your interests, no two people will see the same digital reality. This means it is very difficult for regulators or individuals to hold digital service providers to account. In recent years, many activists have embraced **the power of collectives**, and realised that together, they can discover far more than they can alone. |
| An example of this is the WhoTargetsMe project, launched in 2017 [@jeffers2017]. The objective of this project was to monitor political advertising in the UK. Recognising (as larger studies have shown [@bakshy2015]) that everyone was seeing different advertisements, the goal was to have each individual report what adverts they see on Facebook, so that these can be pooled and compared with others. Over 50,000 people participated, building up an otherwise unavailable clear picture of the ways in which different political demographics were being targeted. This is a powerful mechanism available to collectives in this space: the ability to **have individuals obtain their own datapoints and then compare them**.
| Another example is seen in the Worker Info Exchange [@wie2022], a collective that helps gig economy workers such as Uber drivers and Deliveroo riders to make data requests. Using the pooled data, they conduct investigations to understand algorithmic inequalities and identify unfair treatment of worker by employers. They then help those workers to fight for better working conditions, much **like a traditional trade union, but powered by collectively-sourced data**. This resulted in Uber being taken to court, and some gains being made for drivers [@lomas2021; @dumas2021]. |
| As the aforementioned case with Max Schrems showed [Insight 9](#insight-9), collectives can be particularly powerful when **exerting their data access rights _en masse_**, and this can improve HDR and force greater transparency. René Mahieu and Jef Ausloos have published an exhaustive list of collective actions taken using GDPR rights, addressing issues such as discrimination by US colleges, corporate surveillance of climate activists, identifying gaps in data disclosures, and manipulation of users on dating apps [@mahieu2020a]. The authors identify that the GDPR provides an **'architecture of empowerment'** and have called for better enforcement and for European authorities to provide better support for the ability for collectives to make data access requests together [@mahieu2020b]. Hestia.ai's digipower investigation concluded that data-discovery driven collectives are a vital step on the road to a more digitally empowered society [@pidoux2022, 70]. It is clear that organised collectives exploiting data access rights represents a powerful vector for impactful discovery-driven activism. |

Having identified that there is a clear trajectory where individuals and collectives can obtain data to empower them, it is clear that this complex work can be supported. We see the emergence of **_'data access & understanding services'_**, with entrepreneurs and activist enthusiasts:

- creating **tools to help people get their data back** from organisations, such as Tap My Data [@tapmydata2022], AccessMyInfo [@accessMyInfo2022] and My Data Done Right [@mydatadoneright2022];
- creating **tools to help people understand their personal data**, such as Ethi [@jelly2021] and digipower.academy [@digipowerAcademy2022]; and
- helping collectives and journalists with **training, workshops and skills development** to take advantage of their data rights and **understand data ecosystems**, like Hestia.ai [@dehaye2019].

If such emergent endeavours can be supported and enabled to flourish, that could make HDR reformers using the discovery-driven activism approach more successful by ensuring that a lack of legal, technical or investigative skill does not become a barrier to any HDR reformer wanting to use this approach.

This approach shows that there is a role for independent actors and organisations to carry out discovery-driven activism - access requests, complaints, legal challenges, public campaigns and more. Discovery-driven activism can empower individuals and collectives to incrementally work towards building the world of better HDR that this thesis outlines.

### Approach 2 to Improving HDR: Building the Human-centric Future{#approach-2}

![Figure 7.16: HDR Approach 2: Building the Human-centric Future](./src/figs/fig7.16-hdr-approach-2.jpg){#figure-7.16}

The approach to HDR reform presented in this section, illustrated in [Figure 7.16](#figure-7.16) above, focuses on the gaps in individual data interaction capability that exist today. The objective here is to design and build proofs of concept for **novel human-centric information systems that can deliver people new capabilities over their data**. In this approach, the focus is more introspective than Approach 1: it is about how the individual can improve their relationship with data in the context of their own digital life. The bulk of this section describes **specific design ideas** developed by myself and colleagues at BBC R&D during my 2020-2021 research internship on the Cornmarket project. As established in [Insight 2](#insight-2), one of the most promising models for giving people a new and improved relationship with their data is to create a place where one's scattered [@abiteboul2015] personal data can be stored and aggregated in one place [@jones2011pim], and based on [Insight 3](#insight-3), that place should offer individuals the means to use their life and ecosystem information as a material they can explore, examine or repurpose as they see fit. This leads to the vision of a Personal Data Store [[2.3.4](#2.3.4)] or into which one can unify the data from the different parts of your digital life (as depicted in the AllOfMe vision video [@yt2008allofme]), and meet public demand for 'control over your data' [@teevan2001; @hartman2020]. The Cornmarket R&D project therefore sought to develop a human-centred (i.e. non-commercial) PDS proof of concept, as shown in the conceptual model I developed for the BBC Cornmarket project depicted in [Figure 7.17](#figure-7.17).

![Figure 7.17: Conceptual Model for a Personal Data Store System](./src/figs/fig7.17-conceptual-PDS.png){#figure-7.17}

<a name="7.4.3.1">**Designing a Life Interface: Transforming Data into Life Information**</a>

The first challenge in designing such as a system is to consider what data will be stored, and how it might be represented. At a high level, I identified a number of different types of data that a user might wish to store in a PDS:

![Figure 7.18: High Level Data Types](./src/figs/fig7.18-data-types.jpg){#figure-7.18}

Then, considering the earlier observation by myself [@bowyer2011filesdie] and proponents of temporal PIM systems [[2.2.2](#2.2.2.4)] that time can be used as a unifying concept for personal information, I considered how we might represent occurrences within personal data as _happenings_, anchored against a particular point in time. In effect, this would focus on different properties of the data, much like Karger's _lenses_ [@karger2005; [2.2.2](#2.2.2.5)].

![Figure 7.19: Life Information Modelled as Happenings](./src/figs/fig7.19-happenings.jpg){#figure-7.19}

In modelling data as life information using the concepts shown in [Figure 7.4](#figure-7.4) and [Figure 7.19](#figure-7.19), it is important to come up with as simple a model as possible, so that the _life interface_ is not overwhelmingly complex and unmanageable. Over several iterations, I was able to reduce the modelling of life information in a PDS down to the following four types - _activities_, _interactions_, _transactions_ and _datapoints_, which could correspond to four views or lenses within the user interface:

![Figure 7.20: A Simple PDS Life Information Presentation Model](./src/figs/fig7.20-simple-data-model.jpg){#figure-7.20}

Having decided upon models for the information within a PDS, it becomes much easier to design visual presentations of that information. [Figure 7.21](#figure-7.21) shows a design mock-up designed by Alex Ballantyne of BBC R&D of some of the views of life information that one could offer within a PDS:

![Figure 7.21: Mock-up of Life Information Presented in a PDS Interface](./src/figs/fig7.21-dashboard-concept.png){#figure-7.21}

<a name="7.4.3.2">**Life Partitioning**</a>

What has been shown in [Figure 7.21](#figure-7.21) is the beginnings of imagining what a _life interface_ might look like, a single holistic interface covering all aspects of one's digital life.

Previous HCI design work [[2.3.1](#2.3.1)] has focused on, in the first wave, the functionality of the machine; in the second wave, on the common tasks of a work environment; and in the third wave, on classes of users and the commonalities of experiences in everyday life. But the challenge designers of life interfaces face is even more difficult. As Lindley noted, no single arrangement of information will suffice because in the same context two people may have different needs [@lindley2018; [2.2.2](#2.2.2.5)]. Because of the _subjectivity principles_ [@bergman2003; [2.2.2](#2.2.2.6)], we are now faced with the need to build an interface that is suited to the individual, even though **every individual has different needs**. The design requirements for the interface are likely unique to the individual. Therefore, any life interface design must be able **support different mental models** - and as the life sketching exercise [[Figure 5.2](#figure-5.2)] in Case Study Two showed, people have many different ways of compartmentalising their life.

During a life interface design hack week at BBC R&D, colleague Jasmine Cox and I explored this problem. We considered that a key element of the interface design would need to be the versatility to _partition one's life in different ways_, and then to be able to assign different collections of life information to the different partitions. As a visual illustration of one possible mental model for life partitioning, consider [Figure 7.22](#figure-7.22), where, based on an idea I had had years earlier, I modified a Cluedo™ board to represent the 'rooms of your digital life':

![Figure 7.22: Life Partitioning Analogy using a Cluedo™ board[^18].](./src/figs/fig7.22-rooms-of-life.jpg){#figure-7.22}

[^18]: Cluedo board design is a copyright of Hasbro, Inc., fair use applies.

We also imagined other mental models, such as partitioning your life according to parts of the body (heart for relationships, body for fitness, brain for current projects, etc.) or a landscape with forest, lake and buildings representing different things.

Whatever the visual metaphor engaged, the important thing is the functionality - being able to use these partitions to _filter_ [[2.1.4](#2.1.4)] your life information and focus on a particular _perspective_ [@lansdale1992; @krishnan2005; [2.2.2](#2.2.2.5)]. Deciding to focus on a particular aspect of one's life is analogous to fixing a _conceptual anchor_ [@teevan2001; [2.2.2](#2.2.2.6)].

We then produced a mock app workflow for assigning different elements of your life (such as people, places or topics) to different partitions of your life, and viewing a visualisation of those different partitions in some subjectively meaningful form before filtering on a particular life partition and then being presented with a _timeline_ [[2.2.2](#2.2.2.4)] of life information pieces associated with that part of life. This is illustrated in [Figure 7.23](#figure-7.23), with artwork by Jasmine Cox:

![Figure 7.23: Mock-up: Browsing by Areas of Life](./src/figs/fig7.23-browse-by-areas-of-life.png){#figure-7.23}

<a name="7.4.3.3">**Entity Extraction from Pooled Life Data**</a>

| **INSIGHT 11: Automating the Identification of Entities can enhance Machine Understanding and Unburden Life Interface Users.** |{#insight-11}
| :------------------------------------------------------------------ |
| Having identified the need to assign every piece of a user's life information to a particular partition (or multiple partitions) of their life, it quickly becomes apparent that this would be **too much work for the user** to do alone. Systems that use manual categorisation and tagging to classify information work best with a large userbase to contribute effort to the classification operation [@golder2006]. As part of the explorations of PDS approaches at BBC R&D I therefore also examined how this challenge might be addressed (considering also that having a lot of effort could be a deterrent to adoption [[Objective 5](#objective 5)]). I identified an approach that could help with this problem: If the _entities_ (for example, a person, a place, an event or a topic) associated with a piece of data can be identified, then a lot of the **assignment of data to life partitions can be handled automatically**. For example, association with your office location would indicate that any data associated to that location is likely to relate to the 'work' part of your life, and this could be done automatically, reducing the effort for the PDS user. The process of **identifying entities within data**, known as _entity extraction_ or _named entity recognition (NER)_ is a well-established technique, which relies on the trained recognition of proper nouns and keywords combined with the statistical analysis of sentence grammar [@marshall2019]. This technique is used extensively in text-mining products within the Content Analytics industry such as those produced by my former employer, OpenText [@opentext2022]. However, in the context of a PDS, I propose that new techniques can be applied, making use of the data touchpoints into different parts of an individual's life to identify entities relevant to them personally (including, for example, names of friends or private projects that a standard NER solution would not detect). Data is full of references to entities that have personal relevance in your life. Finding these allows meaningful metadata to be attached to each datapoint. [Figure 7.24](#figure-7.24) shows how a large number of entities could be detected from different parts of an individual's data once it has been imported into a PDS environment: |

![Figure 7.24: Identifying Entity Associations in Data](./src/figs/fig7.24-finding-entities-in-data.jpg){#figure-7.24}

|(continues…)|
|:--|
| This sort of approach could be quite powerful in reducing the effort for life interface users. By scanning the data, the most prevalent entities could be identified, and the user need only assign the entities to different parts of their life, as illustrated in the first two frames of [Figure 7.23](#figure-7.23). This would then allow hundreds of associated data points which had been programmatically associated to that entity, to be assigned to the correct 'bucket' or life partition. While such an approach would not be perfect, and there would need to be some corrections made by the user, this is far preferable to them having to provide all the classifications and is likely to motivate greater engagement. I have observed in user experience design and consideration of productivity systems that users are more motivated to correct errors, than to fill in a blank page. Philosophically, we are moving here towards a _learning system_, a system that can be told when it is right and when it is wrong, and get better at classifying things correctly, analogous to the way an executive might train an assistant to anticipate his/her needs better, a sort of _digital life assistant_ [@bowyer2018grandvision]. Bayesian classification techniques could also be used to help with the learning here [@geeks2022]. . This approach is also useful for _ecosystem detection_, as outlined in [Insight 4](#insight-4) - as identification of relationships with external entities is a key first step to mapping a user's ecosystem. |

Insight 11 offers a practical, theory-informed approach as to how we might start to build systems that are more able to understand the meaning of human information [[Insight 8](#insight-8)]. This is a technique that is already being used by corporations. For example, Facebook has developed an internal system called _world2vec_, shown in [Figure 7.25](#figure-7.25), through which it mines information about the world from the data that people generate through social media posts, messages and interactions. This information is exploited for commercial benefit. It is about time similar techniques were used for individual benefit and personal data empowerment.

![Figure 7.25: Facebook's World2vec Model, Semantically Modelling Human Information from Social Media Posts on Facebook [@peyshakhovic2020]](./src/figs/fig7.25-facebook-world2vec.png){#figure-7.25}

Automatic 'best guess' attempts to arrange personal data in a PDS can go further than just association of related entities. In many cases, it is possible to programmatically determine the nature of a piece of data. [Figure 7.26](#figure-7.26) shows a detailed approach for identifying and classifying data automatically in a PDS, drawing on the previously identified data types in [Figure 7.18](#figure-7.18), the data attributes in [Figure 7.28](#figure-7.28), and the entities identified in [Figure 7.24](#figure-7.24). In [Figure 7.27](#figure-7.27), a more abstracted approach is shown looking at how data could be classified according to the four different life information concepts in [Figure 7.20](#figure-7.20).

![Figure 7.26: Identifying the Attributes of Data](./src/figs/fig7.26-interpreting-data-as-information.jpg){#figure-7.26}

![Figure 7.27: Determining the Nature of a Piece of Data](./src/figs/fig7.27-determining-nature-of-data.jpg){#figure-7.27}

<a name="7.4.3.4">**Designing Capabilities for the Manipulation of Life Information**</a>

Moving beyond the initial challenge of classifying and arranging human information within a _life interface_, a core consideration in designing such an interface is to consider what capabilities the user might be given over the pieces of life information represented in the interface. It is through the provision of a wide range of useful operations upon information items that the information will start to feel like _a material_ as described in [Insight 3](#insight-3) and deliver the _new capabilities_ needed for success [Insight 7](#insight-7).

There are two ways to consider this problem - one starting with the data, and another starting with the user.

Starting with the data, and considering the different types of data that a user might be able to gather from a across their digital life, I identified that each datapoint or dataset is likely to have properties which determine _what can be done with it_. A number of possibilities are shown in [Figure 7.28](#figure-7.28):

![Figure 7.28: Attributes of Data](./src/figs/fig7.28-data-attributes.jpg){#figure-7.28}

These attributes could then be used to determine which datapoints would be eligible for inclusion in different views (or _lenses_ [@karger2005]) of the data, such as tables, graphs, maps, lists, media thumbnail views, etc.

If we consider capabilities from the user's perspective, it is useful to recognise that visualisations alone (such as those in [Figure 7.21](#figure-7.21) are not sufficient to meet the need for either interrogability or malleability [[7.3.2](#7.3.2)]. To address the need for malleability, we need to determine what actions an individual might want to perform on a piece of life information. To explore this design question, we can draw on multiple sources of inspiration:

  - actions identified in prior PIM research & design work [[2.2.2](#2.2.2)] such as arranging, browsing, keeping, and associating;
  - actions needed for SI [[2.2.3](#2.2.3)] such as combining, history viewing, interpreting patterns;
  - actions needed for effective access [[2.1.4](#2.1.4)] such as filtering, zooming, getting detail on demand; and
  - actions inspired by the eight lenses of how people think of data [[Table 7.1](#table-7.1)] such as summarising, deriving or remixing.

Having developed a large set of initial design ideas for possible actions, I worked with my BBC colleague Chris Gameson to distil this information design thinking into a 12 _data card_ designs that could encapsulate some of the most common _actions a user might want to perform_ upon personal data in a PDS. These are shown in [Figure 7.29](#figure-7.29). These had a similar purpose to the cards in my pilot study [[1.3.1](#1.3.1)] and Case Study One [[4.2.1](#4.2.1)], acting as _'things to think with'_ [@bowyer2018family].

![Figure 7.29: Actions One Might Perform on Life Information](./src/figs/fig7.29-data-actions.jpg){#figure-7.29}

As identified in chapter 5 [[5.3.3](#5.3.3); [5.4.2](#5.4.2.3)] and explored further in [6.1.3](#6.1.3), being able to ask questions of data is important to individuals. Addressing this need for interrogability in a similar approach, we produced 10 data card designs to encapsulate some of the different common questions that users might want to ask of their data, as shown in [Figure 7.30](#figure-7.30).

![Figure 7.30: Questions One Might Ask of Life Information](./src/figs/fig7.30-data-questions.jpg){#figure-7.30}

These actions and questions act as a design building blocks, a precursor that can inform the design of features for a life interface that could provide the user with new capabilities to interrogate and manipulate the data in a much more interactive way.

Once information has been correctly identified semantically (using approaches such as those in [Figure 7.26](#figure-7.26) and [Figure 7.27](#figure-7.27)), and associated to entities, it then becomes possible to enrich users' search and browse capabilities by enabling the use of _**facets**_ {@televiciute2020} to allow users to precisely target a set of data points or a particular data item. An example of how this could be done is shown in [Figure 7.31](#figure-7.31), another design artefact from my work at BBC R&D. This is not a user interface mock-up but rather a three-stage strategy, with examples, for the different types of facets that one could offer a user to help them explore their data in powerful ways:

![Figure 7.31: Example Taxonomies for Life Information Navigation](./src/figs/fig7.31-taxonomies-for-navigation.png){#figure-7.31}

<a name="7.4.3.5">**Digital Self Curation & Inclusive Data Flows**</a>

A final element of Approach 2, which, unlike the previous subsections, has a broader focus than just the creation of an effective life interface because it has sociotechnical/business process design implications too, aims to address the problem identified in [7.3.4](#7.3.4-digitalself) - the intractable data self. Drawing upon the philosophy behind VRM [[2.3.4](#2.3.4)], we can imagine (as implied by both Case Studies [[4.3.3](#4.3.3.4); [5.5.2](#5.5.2)]) that were individuals able to **create or contribute to the digital representation of themselves in data**, that this would be more accurate. Furthermore, this would provide an opportunity to address the identified HDR want of _involvement_ [[6.2.3](#6.2.3)]. In the BBC Cornmarket project, this was explored through the concept of profile-based recommendations. Functional interfaces were built which allowed users to construct and edit a representation of their own musical/media tastes known as a _'media profile'_, using personal data such as viewing/listening history imported from multiple sources as inputs. This profile would then be used to recommend new content, which would be likely to be better suited to the individual's tastes since it would be based on a more accurate representation of self. This aspect of the Cornmarket project [@orphanides2021] is not only a practical manifestation of the ideas of pull-centric/VRM approaches, but is also illustrative of a new way of thinking about personal data, where it can be **directly generated (or edited/fixed) by the individual**, rather than just asserted on inferred by the service provider without verification.

Such thinking could be expanded further to accommodate the idea that data is not static. Once we make the mindset shift from data as a static bundle of facts to **data as an ever-changing flow or _stream_** [[2.2.5](#2.2.5); [4.3.3](#4.3.3.3); [6.2.2](#6.2.2)], it becomes much easier to think about how processes and interfaces might be updated to give users a direct role in the evolution and shaping of that data. This also makes it easier to maintain knowledge of data's provenance [[Insight 5](#insight-5)]. Such _**'inclusive data flows'**_ and processes could yield benefits for users in terms of increased ecosystem negotiability [Objective 4](#objective-4), but also for businesses, as will be explored in [Approach 4](#approach-4).

The future-centric designs and insights[^19] I have presented as part of Approach 2 show that while developing interfaces and processes for a better HDR future is a challenging design problem (due to the variety in individuals' mental models and the breadth of data across an individual's digital life), it is certainly possible to tackle these challenges. It is likely that the reasons that few have ventured into this space are largely due to the lack of an obvious business model or incentive rather than any question of the merits of these approaches. It is possible to **empower individuals with new capabilities** over the life and ecosystem information encoded within their data, and even to design **new data interaction approaches** that give users an ongoing role in the curation of that data, and HDR reformers can help make a world of better HDR a reality by **building, or investing, in the building of these more life-centric technologies and processes**.

[^19]: The research and design work and insights from my time with BBC R&D's Cornmarket project are documented in more detail in the external publications detailed in [1.3.4](#1.3.4)).

### Approach 3 to Improving HDR: Defending User Autonomy and Hacking the Information Landscape{#approach-3}

![Figure 7.32: HDR Approach 3: Defending User Autonomy and Hacking the Information Landscape](./src/figs/fig7.32-hdr-approach-3.jpg){#figure-7.32}

While [Approach 2](#approach-2) focuses on designing a better future, and [Approach 1](#approach-1) focuses on identifying and campaigning for positive changes in provider practices, there is a need for a more direct approach to tackle an urgent and evident problem head on: the active diminishing of users' agency [[7.3.4](#7.3.4.2)]. In pursuit of mass market appeal and cost reduction, there is a trend towards the _dumbing down_ of technology, which invariably leads to fewer features and less agency. Increasingly, companies encourage users to think of technology as a black box, which you cannot and should not look inside, as depicted in [Figure 7.33](#figure-7.33), and discourage users from varying their usage, digging deeper or challenging the normal way of using a product:

![Figure 7.33: The Modern 'Black Box' View of Technology](./src/figs/fig7.33-black-box.png){#figure-7.33}

This disempowering trend is seen across hardware, software and service industries, where providers attempt to **restrict the ways in which technology can be used** even after it has been purchased - cars that can only be serviced by official dealers, printers that can only use officially branded ink cartridges, smartphones that cannot be repaired without special tools and warranty invalidation, media files that cannot be copied or shared, online content that cannot be accessed in certain geographies, operating systems that block or discourage certain software from running, and banking applications that forbid screenshots. Apple, for example, encourages users to consider technology as 'magical', rather than as tools to be harnessed and understood. This approach is highly problematic for user agency:

> _"Magical design prioritises pleasing and surprising a passive user who can only use the solution as authorised."_—Cristiano Storni [@storni2014]

In order to challenge this trend towards disempowered, compliant users and **protect individual autonomy** and our ability to make sound judgements and hold organisations to account, direct activism and grassroots civic action is called for. This forms the core objective of this approach, which is represented in [Figure 7.32](#figure-7.32) above: to **identify ways in which agency is being diminished**, and to find ways to **circumvent the new barriers** in order to maintain existing levels of capability.

It is bad enough when a particular technology blocks you from doing what you want to do, but the trend is even worse when viewed at a broader level: As the digipower investigation highlighted [[Insight 6](#insight-6)], the information landscape that we inhabit as digital citizens is being manipulated to **change what we see, what we understand of the world, and what we can do, in order to manipulate our behaviour**, which can have harmful effects on democracy, agency and individual autonomy. Therefore a further goal here is to protect our ability to **experience unbiased and unmanipulated information landscapes**. A recent US Congress investigation shows how the big five use their dominant positions as device manufacturers, search engines or major Internet platforms to promote their own interests [@sisco2022]. In a paper looking at the growing manipulation of search results, Shah and Bender consider how this landscape could be protected and accountability preserved. They describe their approach as establishing _**'guardrails for the status quo'**_, and I find this phrase to be an excellent summary of what Approach 3 is trying to do [@shah2022]. We can also take this idea further through the idea of _**adversarial design**_ [@disalvo2012] which advocated **using design processes to challenge the status quo**. To understand how to gain traction here and carry out _**'design after design'**_ [@storni2014], it is important to understand the concept of _**seams**_, how they can be exploited, and the risks of losing them. This concept is explained in Insight 12.

| **INSIGHT 12: The 'Seams' of Digital Services need to be Identified, Exploited and Protected.** |{#insight-12}
| :------------------------------------------------------------------------ |
| As we have already identified [[7.3.4](#7.3.4.1)] product design (be it hardware or software) is political. Designers pass some power to the user through their design, but also, users should be able to take some power on their own terms. This is the case made by Cristiano Storni in his 2014 paper on _'the politics of seams'_, Cristiano Storni identified the idea of _**'empowerment-in-use'**_ which advocates the idea that people need to appropriate their technologies to different users that the designers may not have foreseen [@storni2014], something that current black box, limit-what-the-user-can-do thinking blocks. Central to this capability is the concept of _**seams**_ - those **exposed areas which the user is free to change** . This concept was proposed by Mark Weiser and developed by Chalmers and others [@weiser1994; @weiser1997; @chalmers2003]. The changes such as closures of APIs or removal of ports as described in [7.3.4](#7.3.4.2) can be seem as the removal of seams. As Storni highlights, the availability of design seams is a **critical determiner of user power**, and companies gain power and reduce agency when they remove those seams. It follows therefore that by identifying, exploiting and protecting the seams of digital services and devices, user autonomy and the viability of data-unification efforts can be protected.|
| **An unseen battle is for the free flow of information is underway** at the seams of today's digital products. Hackers, civic activists and makers seek to repurpose and exploit the edges of products for their own means, while digital service providers and platforms try to block such activity. For example: |
|  - A successful tool called Findings allowed people to clip and share their favourite quotes from Kindle books. Amazon blocked and banned this tool, and the company shut down [@hazardOwen2012; @maldre2012].
|  - Louis Barclay created a tool called Unfollow Everything, which allowed Facebook users to automatically unfollow all friends and pages, in order to give them greater control of their News Feed reading experience and avoid being manipulated into reading more than they want to. He was banned for life from Facebook and threatened with legal action should he ever build any tools that manipulated the Facebook experience [@barclay2021]. |
| - Various activist groups have for several years been fighting to give individuals the legal _**right to repair**_ their own products [@miller2021], which has often been blocked through planned obsolence, inaccessible seams or restricting access to parts. The problem has been described as _**device tenancy**_, the idea that our relationship with our technology products is more like a tenant, where a landlord retains overall control and permits us to perform certain activities [@tufecki2019]. New laws have been introduced in the EU [@tett2022], forcing companies to support individuals to repair their devices. Apple has subsequently released self-service repair kits, though these themselves force parts to be paired with particular phones, limiting the utility of self-repair [@mooreColyer2022]. |
| - As detailed in my co-authored paper with Louis Goffe and colleagues [@goffe2021; @goffe2022], _**web extensions**_ and _**web augmentation**_ offer a powerful technique for modifying web experiences and repurposing user interfaces. This is because once a website is loaded into your browser, it is no longer under the control of the remote site, and by creating a _web extension_ to run code within your local web browser that loaded website can be edited, _scraped_ [@p2021], or otherwise repurposed. This has been successfully used to stop clickbait, dispute fake news, combat addiction, filter explicit words and more. However, in order to re-assert control over these customisations, Google has announced changes to the way Chrome extensions will work, which will _'stifle innovation'_ and limit what developers can do within the web extension [@miagkov2019]. |
| - An example from 2016 shows how seams can be exploited to obtain information and increase transparency. By brute force querying of a Facebook API, researchers were able to identify a complete list of 282,000 interests on Facebook and identify the relative popularity of each interest. [@havlak2016]. |
| - A number of HDR reformers, myself included, had identified a new seam for subverting some of Facebook's control over how its content is consumed [[7.3.4](#7.3.4.2)]: _accessibility tags_ or _ARIA tags_ [@aria2022]. These are specially marked-up tags which are used by screenreaders to display or read content in a more accessible way for partially-sighted or blind people. Because these show page content in a standard format (whereas the HTML of most web pages varies widely and often changes), they present a reliable way to more easily scrape content from the loaded web page within a web extension. In experiments at Open Lab we successfully scraped posts from friends' feeds (which Facebook do not make available anywhere except the News Feed) so that they could be consumed separately in a more human-focused user experience. This technique has been used successfully to monitor Facebook ads by NYU's Ad Observatory [@watzman2021]. In 2021, Facebook was found to have deliberately obfuscated content within ARIA tags to prevent such investigations, resulting in **visually impaired users being unable to differentiate ads from posts and hearing junk characters read aloud**. This can be taken as an adversarial stance against researchers, activists and HDR reformers, and shows that companies like Facebook will go to extraordinary lengths to assert their dominance and reduce user agency [@faife2021].
| - One reason why many companies and services have produced apps is because these are much more locked down and controllable than the web browser environment; there are fewer seams. However, adopting the same philosophy as using web extensions to modify web-based experiences, and drawing on data flow auditing technologies like TrackerControl [[7.4.3](#7.4.3)] researchers at Oxford University have now developed techniques by which mobile apps can be reverse engineered and modified to change user experiences to better meet users' needs, offering the promise of a _**'right to fair programs'**_ [@kollnig2021appThatWay].
| These examples make it quite clear that Storni was right: product seams are the place where control can be asserted or regained. They are the setting for the battle for the freedom and integrity of today's information landscape, and it is important for HDR reform that this space is specifically targeted. The role of the HDR reformer here is twofold: |
|   1) To **surface information injustices** and especially the closures of seams. |
|   2) To **push the seams to gain transparency and re-assert control**, using both and campaigns for policy change. |
| In this context, the work of whistleblowers such as Frances Haugen [@horwitz2021] and Edward Snowden [@macaskill2013] is particularly validated and important. Whistleblowers can expose internal procedure changes that affect the information landscape's integrity that are not otherwise visible. In order to hold online platforms to account, the public must be **aware** and **able to attribute** any restriction in freedom or information access to the correct source, in other words to know that the information or functionality is being modified or restricted. These ideas are explored further in [@bowyer2017]. Seams should be much more in the public consciousness than they are. |

The reason that seams are so important, is that because they a point of friction, a point of resistance to the idea that **_data should be separable from services_** [[Objective 5](#objective-5)]. One of the goals of HDR, and particularly this approach, is to wrest control of data away from service providers, so that it can be truly free-flowing, as I envision in [@bowyer2018freedata]. In this approach, I have identified some of the key avenues for progressing this goal - through web extensions, accessibility tags, API exploitation and reverse engineering. But in the face of such extreme power, it is clear that such grassroots advocacy will not be enough. For example, web extensions are a powerful approach but are limited in that only those 'power users' who install the extension will gain the benefits. They do not directly help the layperson with their diminishing agency. Therefore, as outlined in [[5.5.1](#5.5.1)], HDR reformers must also work to educate and persuade policymakers of the need for change. As an example of this, in my Case Study Two paper [@bowyer2022gdpr] I called for better guidelines from the EU towards data holders. The European Data Protection Board launched a public consultation on a new set of guidelines they had constructed around GDPR [@edpb2022guidelines] and I contributed a detailed set of recommendations to that consultation, emphasising some of the important insights I have identified in this thesis, including a focus on human information, delivering ongoing understanding, establishing standards, and viewing data as an ongoing flow over time [@bowyer2022guidelines]. This sort of engagement by HDR reformers is critical to help shape future policies and guidance, contributing expertise to help the civil servants making those rules. As HDR reformers we must continue to push for better regulation - as it really is the only force that can significantly change data-holding organisations' practices. Better regulation is needed not only to help individual user autonomy, but to combat online extremism [@arthur2017]. In this context it is important to note that the European Union is, at the time of writing in July 2022, developing a wide range of new laws that could help to improve the agency of individuals and the integrity of the information landscape:

- The Data Act [@edpb2022dataact]
- The Data Governance Act [@ec2022dga]
- The Digital Markets Act [@ec2022dma]
- The Digital Services Act [@ec2022dsa]
- The Artificial Intelligence Act [@brakel2022]

It is too early to evaluate exactly what these laws will change or what their impact will be, but HDR reformers should observe carefully: they will almost certainly play as pivotal a role in protecting the information landscape as the GDPR has in opening up data access to individuals.

In this approach, I have highlighted how important it is for HDR reformers to **seize and harness the powers we are given, and fight to hold onto them**. Groups of HDR reformers can combine development skills, innovation and disruptive design approaches to find and publicise new ways to circumvent providers' efforts to control and limit users' agency, and policymakers can prevent further erosion of individual agency through legislation and enforcement over the information landscape. As the popularised adage based on the words of John Philpot Curran and Thomas Jefferson goes, _"The price of freedom is eternal vigilance"_.

### Approach 4 to Improving HDR: Winning Hearts and Minds: Teaching, Championing and Selling the Vision{#approach-4}

![Figure 7.34: HDR Approach 4: Winning Hearts and Minds: Teaching, Championing and Selling the Vision](./src/figs/fig7.34-hdr-approach-4.jpg){#figure-7.34}

Approach 1, the investigative activist approach [[7.4.2](#7.4.2)], and approach 3, the digital freedom fighter approach [[7.4.4](#7.4.4)], can help with users' ecosystem understanding [[Objective 3](#7.3.3)] and ecosystem negotiability [[Objective 4](#.7.3.4)]. Meanwhile, Approach 2, the disruptive interaction designer approach, can help with user's direct understanding [[Objective 1](#7.3.1)] and capabilities [[Objective 2](#7.3.2)] over their data. But as outlined in [[Objective 5](#7.3.5)], these approaches will not have sufficient impact until and unless the goals of HDR reform become widely accepted among business leaders, citizens, journalists and politicians. And for that to be truly accepted, **better HDR must be proven to work**.

The call for better Human Data Relations is a call for a radical reconfiguration of today's data world. As [[Objective 5](#7.3.5)] outlines, where new systems are needed, system builders must invest in and **see the value of HDR ideals** (not just to individuals but to their organisations). Where new policies are needed, politicians must be persuaded that HDR's ideals are **worthwhile and have public support**. And most importantly for any change to occur, there must be a **demand for change, and an engagement and appreciation** of new HDR approaches once they become available. These are the goals of Approach 4, as illustrated in [Figure 7.34](#figure-7.34) above.

Therefore, there is a complementary parallel trajectory of HDR reformer effort that is needed if the disruptive potential of HDR is to be realised. Across society, we must find ways to **demonstrate, persuade and prove the value of better HDR**. Collectively we could call this _'motivational work'_ in support of HDR reform. I have identified three aspects to this motivational work, which will be explored below:

  1. Education & Data Literacy
  2. Demonstrating Business Value
  3. Proving the Viability

<a name="7.4.5.1">**1. HDR Education & Data Literacy**</a>

My interactions with participants in the pilot study [[1.3.1]](#1.3.1)], Case Study One and Two have all shown me that people do not feel comfortable and confident when it comes to matters of accessing and using their own data. This impression is empirically sound: A research study which surveyed over 1,500 members of the public about attitudes to personal data conducted at BBC R&D in early 2021 highlighted a lack of understanding and confidence around personal data as one of four key findings. Other key takeaways from this research included feelings of helplessness and needing to know the basics [@sharp2021]. A major part of any effort to overcome the lack of demand for HDR described in [7.3.5](#7.3.5) therefore must begin with **educating people about data** - and more specifically, to educate people about data, human information [[7.2.3](#7.2.3.1)], and personal data ecosystems [[2.3.4](#2.3.4); [7.2.3](#7.2.3.2)] from a human-centric, forward-looking HDR reform perspective.

_**Data literacy**_ is already a strong education and skills focus area across public and private sector, for both children and adults. However, I identify some inadequacy in this concept when viewed through an HDR lens. Given the broad and varying perspectives of data [[2.1.1](#2.1.1)], there are also varying ideas about what data literacy is. To some, data literacy is about the technical skills of number crunching, spreadsheets and data analysis [@precisely2022]. To others, it is a more high-level ability to read, understand and argue with data, and to exercise critical thinking or identify bias [@knight2016]. A third perspective is that of technical prowess, as outlined by Gurstein as one of the needs for effective data access - the literal ability to interpret and visualise the information within your data [@gurstein2011]. While all of these are clearly important aspects, something broader is needed to encompass _**HDR literacy**_. This would encompass such as aspects as:

  - being able to **appreciate the value** of your personal data as containing stored facts and records about your life [[5.5.3](#5.5.3)];
  - being able to understand the implications of **how your personal data is used and shared** by organisations you interact with [[7.3.3](#7.3.3)];
  - having an appreciation of the importance of establishing **portable data and separation** between data and services [[7.4.2](#7.4.2)];
  - knowing how to **exercise your rights** to obtain your own data, being able to recognise incomplete data returns and knowing how to demand corrections or better responses [[5.1](#5.1)]; and
  - understanding the need for a **free and fair information landscape** and being able to identify when individual agency is being diminished [[7.3.4](#7.4.3.2); [7.4.3](#7.4.3)].

These skills should become part of school curricula, but also need to be taught to adults both in the private and public sector - both in their roles as citizens as well as in their roles within the organisations they work for.

As examples of the sort of educational work that can be beneficial, we need to look at organisations whose remit includes the delivery of education and training. For example:

- The BBC's primary duties are to entertain, _inform_ and _educate_. In line with these latter two objectives, the efforts begun in the Cornmarket project continue into public engagement - the Cornmarket team have produced explanatory videos and blogs to convey important parts of the HDR reform messaging to the public [@sharp2021; @bbc2022vids]. At the time of writing in the summer of 2022, a new project is about to be released which will include a generally available public offering which will combine PDS technology with the 'BBC Together' watch party concept. This will allow groups of friends to have fun watching or reading BBC content together, while also gaining an understanding of what data is generated while they do and how that information might be utilised to better understand themselves and for the basis of a personal data ecosystem under their own control.
- In Switzerland, Hestia.ai is pioneering a new approach in offering interactive data-exploration workshops to businesses, researchers, educational establishments and activist collectives around Europe. This takes the approach used with EU politicians in the digipower investigation [@härkönen2022project] and broadens it into general training provision known as 'digipower academy' [@digipowerAcademy2022] which will enable the creation of workshops where participants can upload their data, explore data flows and aggregate information insights, and learn about the important issues of the personal data economy.

To support this approach and reach wider audiences, efforts such as those of BBC R&D and Hestia.ai need to be invested in, replicated, scaled up and offered to all age groups and all levels of society. This shows that there is a second important reason to support the growth of _**data access & understanding services**_ in addition to the investigative angle in [Approach 1](#7.4.2), namely to **raise HDR literacy across society**.

<a name="7.4.5.2">**2. Demonstrating the Business Value of Better HDR**</a>

There are two aspects to the motivational problem of generating demand. One is motivating the end users - for which I have shown an approach running through [Insight 7](#insight-7) and Approach 2 [[7.4.3](#7.4.3)]. The other, perhaps more challenging, is to demonstrate that the radical new approaches of HDR reform, while they will entail significant changes and new work, will be worthwhile for businesses and organisations. Some of the challenges of shifting to more inclusive and more human-centric ways of operating are explored in Case Study One [[4.4.3](#4.4.3)]. In the following insight, we consider the ways in which HDR reform such as shared data stewardship [[4.2.4](#4.2.4)], inclusive data flows and individually-sourced data [[7.4.3](#7.4.3.5)] might be beneficial to businesses.

| **INSIGHT 13: It is Possible (and Necessary) to Demonstrate Business Benefits of Transparency and Human-centricity** |{#insight-13}
|  :------------------------------------------------------------------------ |
| As outlined in [7.3.5](#7.3.5) and in this section, it is essential that work is done to persuade data-holding organisations of the benefits of moving towards the new paradigms outlined in this thesis. The following avenues for possible future research and advocacy toward data holding organisations have been identified:|
| - **Trust & Reputation**: In line with the third 'public relations'-like aspect of HDR [[7.2](#7.2)]  as well as the recommendations in [4.3.4](#4.3.4), [4.4.1](#4.4.1), [5.5.2](#5.5.2) and [6.2.1](#6.2.1), displaying a more inclusive, open and supportive attitude to data handling could strengthen the service relationship and increase customer loyalty and trust. Organisations that are seen to have good human data relations are preferred. |
| - **Consent**: In the wake of the GDPR, ensuring consent is becoming an increasing concern to organisations, and the risks of legal consequences for mistakes are high. It makes sense that a more dynamic [@bowyer2018family; [4.4.1](#4.4.1); [5.5.2](#5.5.2); [6.2.2](#6.2.2)] consent approach that involves individuals [[6.2.3](#6.2.3)] and keeps them in the loop, will enable individuals to speak up much earlier and express consent wishes that might otherwise go undetected. |
| - **Accuracy**: The best-placed person to spot errors in data's accuracy or fairness is the individual about whom the data is concerned. Therefore, increasing their involvement is likely to improve the quality of the data, especially if additional data is contributed or curated by the service user [[4.3.3](#4.3.3.4), [6.2.3](#6.2.3)] |
| - **Liability**: In an increasingly litigious society, storage of personal data, especially health or financial data, is a significant liability for businesses, especially if something goes wrong. Investment in human-centred personal ecosystems would outsource the storage of sensitive data to data trusts or PDS providers, reducing liability for the service business. By ensuring that data is accessed only in ways that are centralised outside of the business and remaining in the user's control—such as PDS company digi.me's Private Sharing model [@digimePrivateSharing; @bowyer2020bbcreport]—organisations can ensure that have negligible risk of mishandling customer data. |
| - **Better Customer Targeting** The most radical, but perhaps the most persuasive, business model relating to better HDR, is the Vendor Relationship Management approach [[2.3.4](#2.3.4)], where individuals express their own service or product desires explicitly, which vendors then respond to. This turns traditional models inside out, and would empower users more, but due to the inherently improved accuracy of a self-declared interest, might also give businesses a greater confidence that their investment in converting those customers to a sale would be worthwhile. It is important to remember that the current drive towards collecting more data that drives the platformisation trend is in order to improve ad targeting, so that businesses can get a better return on their investment. A VRM approach, or any other approach where the individual contributes improved data to their data self, is in line with that current business objective. |

This section has identified the areas which need to be evaluated and explored through research or entrepreneurial investment, in order to produce data that could persuade businesses to adopt reformed HDR approaches to data handling and service user interaction.

<a name="7.4.5.3">**3. Proving the Viability of Human-centric Approaches**</a>

The third aspect of the motivational work in Approach 4 is that work must be done not just to create new systems and technologies that meet the HDR objectives [[7.2.4](#7.2.4)], but to **prove that human-centric HDR approaches work**. This involves both developing functional technical **proofs of concept** to test HDR design concepts such as those in Approach 2 [[7.4.3](#7.4.3)] in practice, as well as starting businesses which can explore new business models to discover which forms of value in the PDE / HDR space can be sufficient to drive the space and its players - which after all will be the engines of change in pursuing HDR - forward.

As an example, development work I undertook with Stuart Wheater as part of my role in the SILVER project [@ConnectedHealthCities2017silver] was successful in building a working system to extract citizens' health data from EMIS, the medical system used by NHS GPs, and make it available as understandable and explorable timeline-based information that could be understood by support workers. A screenshot of the interface I developed is shown in [Figure 7.35](#figure-7.35), and example videos have been published online [@bowyer2019silvervideo].

![Figure 7.35: SILVER Health Data Viewing Interface](./src/figs/fig7.35-silver-data-interface.png){#figure-7.35}

Across the MyData and PDE / HDR space, many small businesses have been established which have demonstrated successes in different elements of pursuing the visions of MyData and HDR. For example:

- Digi.me, along with their partners UBDI [@digime2021; @ubdi2019], have demonstrated the technical and business viability of **human-centric solutions which allow users to securely share data**, through a personal data store-like library, with paying third parties, while maintaining individual oversight and information-viewing functionality. CitizenMe [@citizenme2021] has also demonstrated success in this field, focusing on individual data generation and personal rewards.
- Tim Berners-Lee's company, Inrupt, has successfully produced an effective open source **PDS platform technology called _Solid_**, which is in use in several organisations across the world [@olivo2020]. The Solid community has also resulted in the first practical standard for unifying human information from the personal data diaspora [[7.3.1](#7.3.1)], as called for in [[7.3.5](#7.3.5)], _data shapes_ [@shapeRepo], which is gaining adoption.
- BBC R&D's Cornmarket project has come up with a viable set of designs and mock-ups and a working R&D prototype. Built upon Solid technology, it connects to real data sources including Netflix, BBC and Spotify. If supplemented by some of the features and strategies described in [7.4.3](#7.4.3), it could deliver a **real-world PDS-based life interface**. While not yet tested in the marketplace, the designs have received positive feedback in a 1,500-participant study, including specific appreciation for many of the ideas raised in this chapter and this thesis, including life insights and goal setting, personal data unification, individual oversight, data exploration, the twin goals of LIU and PDEC [[7.2.3](#7.2.3)], and self-contributed data [@sharp2021; ADD REF YS].
- With several customers including non-profit research organisations, universities, researchers, consumer organisations, local authorities and transport providers, Hestia.ai has proven that there is a **paying market for _data access and understanding services_** [@hestia2022realization], which are needed for the reasons outlined in Approach 1 [[7.4.2](#7.4.2)] and Approach 3 [[7.4.4](#7.4.4)].

Looking at Approach 4 as a whole, this section has shown that pursuing HDR is not purely a data interaction design problem, nor solely a political problem, nor solely a technical problem. It is all of these, but also, it is a business problem. In our capitalist society it is essential to find a path to better HDR that companies can get behind. And this approach too has shown that motivation and education go hand in hand with all of the above. It is not just a case of building new things, it's about beginning and catalysing a cycle of constant feedback, of data-enabled design and action research or iterative software and business model development - finding what works, championing it, communicating it and selling it.

Summation: Addressing the Expanded Research Question{#7.5}
----------------------------------------------------

![Figure 7.36: Summary of Generalised Change Strategies for Pursuing Better HDR, Using the ToC Model](./src/figs/fig7.36-summary-change-trajectories.jpg){#figure-7.36}

This chapter examined the expanded research question [[7.1.1](#exRQ)] of how better Human Data Relations might be achieved in practice. Through detailed practical examples drawn from the peripheral research settings [[7.1.1](#7.1.2)] and elsewhere, I have identified key obstacles [[7.3](#7.3); [Figure 7.3](#7.3)] to better HDR including invisible, inaccessible, scattered, immobile, unmalleable, or unrelatable data; the complexity of current personal data ecosystems; a lack of metadata and machine understanding;  the ongoing exertion of power by introspective data holders to diminish user agency; and a lack of demand and investment in HDR.

Building upon the 13 insights introduced throughout [7.3](#7.3) and [7.4](#7.4), I have, as illustrated in Figures [7.15](#figure-7.15), [7.16](#figure-7.16), [7.32](#figure-7.32), and [7.34](#figure-7.34), described four distinct trajectories for improving HDR, which provide not a complete answer, but provide steps to begin to address that [expanded research question](#exRQ):

  1. **Discovery-Driven Activism** [[7.4.2](#7.4.2)]
  2. **Building the Human-Centric Future**  [[7.4.3](#7.4.3)]
  3. **Defending User Autonomy and Hacking the Information Landscape** [[7.4.4](#7.4.4)]
  4. **Teaching, Championing and Selling the HDR Vision** [[7.4.5](#7.4.5)]

The common elements of these four approaches are summarised in abstract in [Figure 7.36](#figure-7.36) above, and can be considered in terms of the four ToC quadrants:

- _**Learn & Discover**_ (CI): In this quadrant, individuals, researchers, activists and other stakeholders work in groups to understand data attitudes and user needs, and to gain collective knowledge of data collection and usage practices which are sometimes hidden.
- _**Defend & Create**_ (CE): In this quadrant, activists work to ensure current HDR capabilities are not eroded, while researchers, designers, technologists and social innovators design and create new technologies, operating models, organisations and interface designs, the structures enabling a world with better HDR.
- _**Influence & Motivate**_ (IE): In this quadrant, individuals' relationships with data and with data holders, as well as data holders and policymakers' relationships, can be improved. For us, as external actors seeking change, the task is to influence the many parties by showcasing and facilitating newly created structures and capabilities, and to harness our new collective knowledge to advocate the benefits of changing data-related behaviours.
- _**Educate & Empower**_ (II): In this quadrant, individuals' ways of thinking about data and data holders grow and evolve towards a state we could call _'feeling empowered'_ [[6.3](#6.3)], which would show true progress in delivering the better HDR that participants of this thesis's research called for. This change is driven through education, improving Human Data Relations literacy, and through the experience of new capabilities and changed relationships with data and with data holders that can empower individuals to hold a more aware and equitable position in those relationships and in their digital life.

Taken together, these various efforts show how better HDR might be achievable in practice, even despite the identified obstacles. The [glossary](#hdr-glossary) included at the back of this thesis provides a convenient way for future researchers, innovators, activities and HDR reformers to quickly locate insights and designs of value within this chapter and the wider thesis, so that others can build on this research to pursue improved Human Data Relations. In the [next and final chapter](#chapter-8), the legacy and contributions of the thesis are discussed in more detail.

---
