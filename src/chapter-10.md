<h1 class="title">Section V: Conclusions & Outlook</h1>

<h2>Introduction to Section V</h2>

<span class="editnote">ADD NEW SUBSECTION INTRODUCING chapter 10 inc new parts here</span>

Thesis Conclusion {#chapter-10}
=================

> _"Our research should transform, not just inform, society."_
>—Kingsley ofosu-Ampong (researcher & lecturer in digital transformation)

<span class="editnote">update C10 intro to account for the new sections and no longer part A and part B</span>

Section [6.3](#6.3) concluded Part One's academic enquiry with a clear answer to the question [[2.4](#RQ)] of what relationship people want with their personal data in order to be empowered. They want:

  - visible, understandable and useable data, as well as
  - process transparency, individual oversight and involvement in decision making.

Section [9.6](#9.6) concluded Part Two's exploratory design work by summarising the outlook for improving Human Data Relations, through four strategic trajectories for producing change in the HDR landscape:

  - discovery-driven activism,
  - building human-centric life interfaces,
  - defending and exploiting the seams of the information landscape, and
  - championing and teaching the HDR vision.

In this brief concluding chapter, I will bring the two parts of the thesis together, reflecting on my journey as a researcher, activist and innovator through this work, and contextualising the contributions of the thesis in terms of their legacy and future value.

Design Insights and Recommendations{#10.1}
------------------------------------------

<span class="editnote">WRITE INTRO AND ENDING TO THIS SECTION ON DESIGN INSIGHTS. Notes: New conclusion chapter for the entire PhD which consolidates and draws out takeaways from the work to link together the HDR framework, insights from studies 1 and 2 and the interventions developed in Part B. This includes reorganising existing content, as opposed to substantial rewriting e.g. moving content from ‘Insights’/’Contributions’ and seeking to formulate recommendations for design using the HDR framework.</span>
<span class="editnote">include the idea that we are not talking just about interface design or interaction design, but also the design of sociotechnical actions, interactions and relationships.</span>
<span class="editnote">DE TABLIFY ALL THESE INSIGHTS</span>
<span class="editnote">Notes on having insights here: Need to pull out lessons from the insights in Ch 9 – which will be presented in Ch 10. This PhD has been very well signposted and documented throughout – however, the conclusion felt very short by comparison to levels of detail in chapter summaries. There are so many fascinating takeaways from this work. Need to move some of that detail into the conclusion, to really help guide the reader on the key takeaways. The intro already did this to an extent but good to reiterate at the end of the journey too.This is reorganisation by pulling from ‘Insights’, ‘Contributions’, other domains of PhD – it is a reordering of existing material you have. </span>

### Design Insight 1: Life Information makes Data Relatable

| **<a name="insight-1">INSIGHT 1</a>: Life Information makes Data Relatable** |
|:---------------------------------------|
| In the pilot study and Case Study One, data cards were used to represent civic data [[Figure 3.6](#figure-3.6)]. In Case Study Two [[Figure 3.7](#figure-3.7)] and in Hestia.ai's _digipower_ investigation [[ARI7.2OLD](#ari-digipower-OLD)], a categorisation of provider-held data was displayed. In my BBC research report [@bowyer2020bbcreport], the use of **relatable examples** was identified as an important way to help people understand what a piece of data represents. Recalling that to make data meaningful, we must be able to interpret it as information [[2.1.1](#2.1.1)], this can be refined further: |

> **To make data meaningful, it needs to be expressed as information about your life**.

|(continues…)|
|:--|
| Spreadsheets and 'big data' sound dry and (to many) dauntingly technical, but once those same datapoints are expressed as 'facts about your life', the hurdle of relatability is overcome [[4.2.1](#4.2.1)]. The effectiveness of applying this principle is evident in successful online services like Netflix, Spotify and Strava, and in social media platforms like Facebook: these interfaces show understandable everyday concepts like Friends, Events, Movies and Playlists, not files, records, folders or database rows. They have successfully _'pushed the technology into the background'_, in line with Weiser's vision [@weiser1991] and Rogers' _calm computing_. While exploring this idea of representing **life concepts** further at BBC R&D, I produced [Figure 8.2](#figure-8.2), which shows a near-exhaustive overview of the many different informational concepts in an individual's life that providers might hold as data:|

<span class="editnote">RENUMBER FIgure 8.2</span>

![Figure 8.2: Life Concept Modelling](./src/figs/fig8.2-life-concepts.png){#figure-8.2}

|(continues…)|
|:--|
| This diagram shows how most common personal data types handled today can be mapped to more relatable _life information_ concepts. These life concepts (exemplified where possible) can make data meaningful to individuals, and can help them find value in their data [[5.4.3](#5.4.3.1)].|

### Design Insight 2: Personal Data Needs to be United and Unified

| **<a name="insight-2">INSIGHT 2</a>: Data Needs to be United and Unified** |
|:-------------------------------------------------|
| It is clear that better HDR involves recognising this splintered reality [@lemley2021] and moving beyond it. To make data useable for individuals, the diaspora must be united. This means that data from different sources must first be **united**—brought together—and then **unified**, which means making it into a collection of data about the individual and their life, rather than scattered slices of company data that may have secondary value to the individual. This is a multi-faceted sociotechnical problem of access, interpretation and _integration_ [@li2010; [2.2.3](#2.2.3)]]. Negotiability remains important; we can only unite data that we can access, and only data holders can fully explain it [see [8.3](#8.3) and [8.4](#8.4)]. Setting that aspect aside, the pragmatic way forward begins with creating a space where data can be held, combined, controlled and **owned** by the individual - _'a place for your personal data'_ [@jones2011pim,[[2.2.4](#2.2.4)]]. This can form the seed of their new human-centric personal data ecosystem. This follows Bergman's _subjective classification principle_: |

> _'All related items should be classified together regardless of technological format'_—@bergman2003

| (continues…)|
|:--|
| We could add: _'regardless of where they are held'_. This vision is embodied in the **Personal Data Stores** (PDS) concept [[2.3.4](#2.3.4)]. A PDS can brings together personal data from multiple sources that has never co-existed before. This enables the provision of new capabilities over one's digital life.  The BBC R&D Cornmarket project [[ARI7.1OLD](#ari-bbc-OLD)] examines how to build PDSs. In [Chapter 9.2](#9.2) I explore possible design approaches. At this stage, only the _concept_ is important. Once data is united and unified, PDSs enable the creation of new views of data that were not previously possible, because code can execute across data that was previously dispersed. For example, today each separate TV app, device or streaming service maintains separate records of what you have watched. Once unified in a PDS, it would be possible to present you with a unified view of all the past content you had viewed, across all channels, as this mock-up I made during my BBC internship shows:|

<span class="editnote">RENUMBER FIgure 8.3</span>

![Figure 8.3: Mock-up of a Unified TV Viewing History Interface](./src/figs/fig8.3-unified-watch-history.png){#figure-8.3}

### Design Insight 3: Data must be Transformed into a Versatile Material

| **<a name="insight-3">INSIGHT 3</a>: Data Must Be Transformed into a Versatile Material** |
|:-------------------------------------------------|
| In Case Study Two [[Table 5.4](#table-5.4); @bowyer2022gdpr, supplemental materials], participants expressed diverse goals for personal data, including reflection, pattern-finding, goal-tracking, and creative use. In the PIM space [[2.2.2](#2.2.2)] relevant innovations include associative exploration, spatial arrangement, and embodied interaction for different contexts) Drawing on all of these, allows me to infer that unified data must be transformed into a **versatile material**. Individuals need to be able to use data—represented as facts or assertions about one's life by performing manipulations such as: |

  - creating,
  - deleting,
  - moving,
  - grouping,
  - annotating,
  - copying,
  - sharing,
  - modifying,
  - labelling,
  - organising, and
  - separating.

| (continues…)|
|:--|
| _Data as material_ will be new to most except data scientists. This is novel not just for end users but for designers too. Eva Deckers, in her work on _data-enabled design_, an approach to design which also calls for data to become a material, notes (and we could expand this to laypeople too): |

> _"Designers are in general not trained and prepared to work with data. They're not equipped with the right tools. Data manipulation is not part of the schools' curriculum and designers are rarely interested in understanding data."_—[@deckers2018].

| (continues…)|
|:--|
| Her work with colleagues on the 'connected baby bottle' illustrates how treating data as a design material creates a novel iterative user-centred development of new capabilities [@bogers2016]. In HDR terms, I theorise that what this material should _be_ is _human information_ - life information and ecosystem information [[7.2](#7.2)]. Data useability therefore calls for the creation of systems that enable **human information to be treated as a material**.|

### Design Insight 4: Ecosystem Information is an Antidote to Digital Life Complexity

| **<a name="insight-4">INSIGHT 4</a>: Ecosystem Information is an Antidote to Digital Life Complexity** |{#insight-4}
| :------------------------------------------------------------------------- |
| Acquiring ecosystem information and understanding is a key motivator for many people—encompassing 74% of participant goals in Case Study Two [[Table 5.4](#table-5.4)]—and is essential for better HDR. This suggests two distinct goals for system builders: **ecosystem detection** and **ecosystem information display** as ingredients to help overcome the obstacle. As a representative example let us examine a recent app called SubsCrab [[Figure 8.4](#figure-8.4)]: |

<span class="editnote">RENUMBER FIgure 8.4</span>

![Figure 8.4: SubsCrab: An Example Application for Ecosystem Detection and Visualisation](./src/figs/fig8.4-subscrab.png){#figure-8.4}

| (continues…)|
|:--|
| This app connects to the user's e-mail account, and searches it and monitors it for e-mails from service providers such as Netflix, Spotify, Dropbox, or Google with which the user has monthly or annual subscriptions. In doing so, it is detecting part of the user's ecosystem. It is identifying which companies they have a payment relationship with. It parses found e-mails to identify billing dates and payment amounts. It then provides additional representations of that ecosystem information to the user, so that they might get on top of their subscriptions, see what they need to pay (or cancel), and feel more 'in control' [@teevan2001; [2.2.2](#2.2.2.6)] of this aspect of their digital life. From this example, it is easy to imagine other types of ecosystem detectors, which could detecting relationships with free services and websites, identify account numbers and e-mail addresses, password resets, address book syncs, OAuth logins, family identities and more. Alistair Croll and I explored possibilities for _inbox scanning_ in 2009 [@acroll2009], and while there has been some innovation in this space, it has largely been for commercial reasons [@braun2018]. New ecosystem detectors could power new interfaces, contributing to the simplification of the user's digital life. This would give people more visibility and control over their previously unmanageable data ecosystem. |
| A secondary consideration in achieving the required 'sea change' in approaches HDR, is that current PDS and SI approaches are very life-information-centric. It is implicitly assumed that the only way to unite data is to collect it. The difficulty in such an approach is that you can only collect that which you can extract. To address this, I draw inspiration from a computer programming concept known as _pass by reference_ (as opposed to _pass by value_) [@ananya2020] where data is 'pointed to' rather than moved. Productivity guru David Allen recommends the use of _'placeholders'_ [@allen2015] to keep track of tasks you cannot otherwise bring into your planning. To build a complete map of a user's ecosystem we must be able to keep track of accounts and data that are remote, much like a search engine points to information on different pages around the web. We can create **proxy representations** of service-provider-held or otherwise immobile data (e.g. data which is offline or restricted). These representations become part of the manipulable material in the user interface, and could be augmented with links to visit the remote source. |

### Design Insight 5: We Must Know Data's Provenance

| **<a name="insight-5">INSIGHT 5</a>: We Must Know Data's Provenance** |
|:-------------------------------------------------------------------------|
| Metadata is what gives information _context_. Context is critical to _sensemaking_ [[2.2.3](#2.2.3)] and enables good experience-centred design [[2.3.2](#2.3.2); [2.3.3](#2.3.3)]. Without context, data loses meaning [[5.4.3](#5.4.3.1)]. Collecting historical data about the individual is important for reflection [[2.2.3](#2.2.3)] and considered valuable [[4.3.3](#4.3.3.3)], but knowing the **history of a piece of data** allows its context to be understood. Data is not neutral, and is inherently biased, since it was created for a specific purpose with a specific agenda in mind [@gitelman2013; @neff2013]. To combat this bias, more context is needed. Significant research in this space has been undertaken by Professors Mike Martin and Rob Wilson at Northumbria University, formerly Newcastle University, who promote the idea of **data with provenance**; in other words: |

**Data must carry with it the details of why it exists, how it came to be, and what has happened to it since its inception.**

| (continues…)|
|:--|
| Provenance should be communicated alongside any visualisation of the data, in order for it to be fairly assessed in context. Provenance is essential for data to be trusted, argues Martin, and should be quite granular: a piece of data should be attributed not just to an individual or organisation, but to the relationship between role-holding individuals in a specific context. Greater insights can be gained when considering all actions upon data as motivated communications from one party to another; only by capturing this information in-situ can the data's meaning be fully appreciated [@martinWP]. This framing essentially advances the concept of history tracking [[2.2.3](#2.2.3)] into the sociotechnical, ecosystem-aware problem space. While everyday system designs have not approached this level of granularity, the importance of data provenance has been recognised in the PIM space. Temporal PIM systems [[2.2.2](#2.2.2.4)] from Lifestreams [@freeman1996] to _activity streams_ [@hartdavidson2012] rely upon data provenance in some form. A study by Jensen _et al._ concluded that provenance tracking can be valuable for identifying related documents, a critical part of knowledge work today [@jensen2010]. Lindley _et al._ proposed the idea of _file biographies_, which view the lifetime of a file as something that should remain connected, so it could be traversed in order to understand the context of the file different moments of interaction [@lindley2018]. This comes close to Martin's vision but does not capture the motivation for each interaction. While provenance capture is not a solution in its own right to the understanding of data and of ecosystems, it is clear that data with provenance is very likely to be a valuable part of any design that aims to provide understanding of complex and invisible personal data ecosystems.|

### Design Insight 6: Data Holders use Four Levers of Infrastructural Power


| **<a name="insight-6">INSIGHT 6</a>: Data Holders use Four Levers of Infrastructural Power** |
| :------------------------------------------------ |
| Hestia.ai [[ARI7.2OLD](#ari-digipower-OLD)] have produced a model to explain the mechanisms by which technology companies gain power and use it to shape today's digital landscape. In this model, _infrastructural power_ comes from three things: |

  - _technical ability_,
  - _organisational ability_, and
  - _the acquisition of data about individuals and populations_.

| (continues…)|
|:--|
| As organisations (especially platforms) collect more data, and grow in market influence or technical capability, they gain power over individuals and over other organisations. They exert this power using four 'levers'. Simplified and expressed in the terms of this thesis, these are:

  1. **Collect & Interpret Data to Acquire Knowledge**: Data and _signals_ are collected from individuals and interpreted in order to infer their intents and interests. For example, Google collects raw GPS and wi-fi hotspot data from mobile phones, which it then statistically analyses to infer which shops or venues you visited and what forms of transport you used, increasing Google's knowledge about individuals and populations.
  2. **Present Content and Configure Structures to Influence Individual Behaviour**: Knowledge of individual intents and interests is exploited within user interfaces to influence desired individual actions. For example, Facebook or presents a user with a product relevant to their interests, which they are motivated to click upon, generating ad revenue. Another example would be Twitter manipulating the content of the user's feed to show more tweets from conversation topics where they can show promoted tweets, increasing ad revenue.
  3. **Configure Structures to Improve Knowledge Acquisition**: A provider uses its dominant position to force other organisations to improve the provider's ability to acquire knowledge. For example, Google provides free analytics tools to web developers, but requires the end users of those client websites to supply visitors' data back to Google, increasing their ability to acquire knowledge about individuals and populations.
  4. **Configure Structures to Disadvantage Others**: Certain providers (typically of operating systems or popular devices) can configure the structural relationships between other parties. For example, a smartphone manufacturer could limit data exchange between other apps, while still extensively collecting data signals themselves, such as when Google was found to be collecting call history from Android's dialer app.

| (continues…)|
|:--|
| The precise mechanisms and techniques employed when exerting infrastructural power, as well as the social and market consequences of these practices, are explored in detail in Hestia.ai's digipower technical reports, of which I was a co-author [@bowyer2022hestia; @pidoux2022]. |
| The research highlights that providers' power is far greater than many realise. Unlike in the physical realm, providers of popular online platforms can **reconfigure the landscape to change the way that individuals perceive reality**, in line with the powers of interpretative influence, behavioural influence and socially shaped power described above [@bowyer2022hestia]. Providers control the extent to which (if at all) data stored behind the scenes, and internal processes that use that data, are visible, and how data and processes are represented.|
| The model shows that the accumulation of data (and hence, information) is implicitly and objectively a form of power, consistent with participants' observations in [5.4.4](#5.4.4.1). As long as current service providers are free to collect so much personal information, the information landscape is likely to remain imbalanced and individuals will not be able to acquire ecosystem negotiability. |
| This insights shows that the most powerful data holders exert huge influence over the digital landscape, in terms of what is _knowable_ and what is _doable_. HDR reformers' abilities to balance the landscape are hindered by the fact that they are operating in a landscape that the incumbent platform and service providers effectively control. |

### Design Insight 7: Human-centred Information Systems must serve Human Values, Relieve Pain and Deliver New Life Capabilities

| **<a name="insight-7">INSIGHT 7</a>: Human-centred Information Systems must serve Human Values, Relieve Pain and Deliver New Life Capabilities** | {#insight-7}
| :------------------------------------------------------------ |
| Through work at BBC R&D exploring how to better connect people with their data, it became clear that there is a way to combat such indifference and apathy of users. It emerges from the realisation that the way people find value in data is to connect it their lives. The more that people see relatable life information and can imagine ways to harness that information in their everyday life, the more motivated they will be. BBC R&D conducted research [@forrester2021] that identified fourteen specific Human Values that people seek to satisfy in their lives, which are shown in in [Figure 8.7](#figure-8.7). These are, at the most abstract, goals that people care about in their daily existence. |

<span class="editnote">RENUMBER FIgure</span>

![Figure 8.7: Human Values, as Identified in BBC R&D Research Funded by Nesta](./src/figs/fig8.7-bbc-human-values.png){#figure-8.7}

|(continues…)|
|:--|
| Given these and the earlier observation that life information is what makes data relatable, the insight I offer here is that the way to make people care about their data is to **use it to help them in their life**. By starting with a focus on a user's world, one can then focus in on their life, and then the data that represents elements of that life. Then, the individual has a vested interest. Systems and features should be designed from this life-centric perspective. This is known as _value-centred design_ [@reber2005] and it has been argued that this should become the guiding design philosophy in HCI [@cockton2004]. And to offer true individual value, all human-centric system designs must also consider _context_ [[2.3.2](#2.3.2)], _environment_ [@abowd2012] and _experience_ [[3.2.1](#3.2.1)]. In business modelling, there is a tool called the _value proposition canvas_, which identifies three ways of conceptualising value: _gain creators_, _pain relievers_ and _jobs-to-be-done_. Informed by these concepts, we can design better human-centric functionality that relieves an individual's pain points, helps them complete their tasks, or offers them some gain over the status quo. In the HDR space, given the lack of existing tools for digital life management, we have the opportunity to create quite a unique type of gain: **new capabilities over your digital life** that you have never had before. This ability to do new things has been identified as key ingredient of user empowerment [@meschtscherjakov2014; @schneider2018]. As [2.1.4](#2.1.4) and [2.2.2](#2.2.2) showed, a range of novel capabilities are needed for effective PIM. |
| Here is an example of what this value-centric approach might look like in the HDR space: Myself and BBC R&D colleague Jasmine Cox imagined focusing on address books and contact lists as a strong relatable starting point to generate demand for a human-centric interface. This could provide people with new life capabilities while also relieving pains. Many people have address and contact information scattered far and wide, and face a complexity they cannot easily manage when it comes to the automated syncing and sharing of potentially sensitive contact information between devices, apps and providers. Developing human-centric personal information management capabilities to bring that messy situation under control would offer a clear and tangible benefit to users. In [Figure 8.8](#figure-8.8), we show how there could be a strategic path, beginning with detecting ecosystem and life information from the individual's calendar and e-mail inbox, through to building up to more holistic life-level PDS capabilities. |

<span class="editnote">RENUMBER FIgure</span>

![Figure 8.8: A Contact-and-Calendar-centric PDS Approach](./src/figs/fig8.8-calendar-contact-centric-PDS-strategy.png){#figure-8.8}

|(continues…)|
|:--|
| A helpful example is that of a vacation from my 2011 article [@bowyer2011filesdie] and shown in [Figure 8.9](#figure-8.9). Today, all the information around such a holiday is scattered into multiple systems - emails, online provider bookings, chat logs, cloud synced photos, web browser bookmarks, smartphone location logs, etc. It is not hard to imagine that a system that was able to bring all related information about that vacation together in one central interface (mock-up in [Figure 8.10](#figure-8.10)) could deliver huge value to users and be very compelling.  Such context-targeted human-centric offerings can have a much greater chance of generating interest and impact than offerings that merely allow you to 'organise your data' or some other abstract phrasing not rooted in everyday life.|

<span class="editnote">RENUMBER FIgure</span>

![Figure 8.9: The Scattered Data Relating to a Vacation](./src/figs/fig8.9-vacation.png){#figure-8.9}

<span class="editnote">RENUMBER FIgure</span>

![Figure 8.10: Mock-up of a Unified Interface for a Vacation](./src/figs/fig8.10-holiday-interface.jpg){#figure-8.10}

### Design Insight 8: We Need to Teach Computers To Understand Human Information

| **<a name="insight-8">INSIGHT 8</a>: We Need to Teach Computers To Understand Human Information** |
|:----------------------------------------------------------------------|
| In order to move towards standardised ways to store and unify personal data from multiple sources, computer systems must be taught to understand the information within the data, and how it relates to an individual and the world. This moves beyond just capturing data provenance: put simply, **computers need to understand human information**. They need to move beyond files [@bowyer2011filesdie] and databases, and begin to perform operations on human informational concepts, and to associate those concepts according to what they mean - i.e. **_semantically_**. This is a preliminary step that will enable the building of systems and interfaces that are able to deal in human concepts and represent the elements of everyday life.|
| We need to store **semantic context and semantic associations**, i.e. the meaning of things, not just raw bundles of data. This is advocated by the Web's inventor Tim Berners-Lee in his vision of a _Semantic Web_ [@bernersLee2001] and by other proponents of _networked_ and _semantic_ PIM systems [[2.2.2](#2.2.2)]. There is a need to develop standard ways to digitally model facts and assertions about users' lives, so that those disparate pieces of data can be unified, connected, correlated and compared. Some standards are emerging, such as _data shapes_ [@shapeRepo]. The extraction of meaning from data has a business domain all of its own. Sizable industries have built up around Content Analytics and Enterprise Content Management. But to consider the problem at its simplest level, I offer this insight: Through **the capture of metadata** at the point of data recording, and through **subsequent programmatic analysis** of stored data, as illustrated in [Figure 8.11](#figure-8.11), we can begin to teach computers what the data we store represents.|

<span class="editnote">renumber figure</span>

![Figure 8.11: Annotating Data with Semantic Context](./src/figs/fig8.11-semantic-annotation.png){#figure-8.11}

|Machine learning technologies and Artificial Intelligence have pushed machine understanding of human words, images and content to impressive levels in recent years and such technologies can certainly be helpful, but in fact at the core what we are talking about here is something much simpler than AI; It is simply about automatically labelling datapoints in as many different ways as possible (using a similar principle to _lifelogging_) so that those datapoints can be associatively retrieved from many different angles, and providing humans with ways to amend incorrect labels and to reclassify data or apply new semantic associations. Such approaches are in their infancy, and have not yet been adopted extensively in commercial settings. Issues of interoperability for PDS systems are being actively explored and developed in the _Solid_ community [@bernersLee2022inruptSolid; @bansal2018] in pursuit of a decentralised web [@verborgh2017]. |

### Design Insight 9: Individual GDPR requests can compel companies to change data practices.

<span class="editnote">Position that this is designing at sociotechnical level</span>

| **<a name="insight-9">INSIGHT 9</a>: Individual GDPR requests can compel companies to change data practices.** |
| :--------------------------------------------------------------------- |
| In this inset box, I will explain how one person can apply the discovery-driven activist approach to **compel** a multi-billion-dollar international data-centric organisation to improve their HDR. |
| As an avid user for several years of the music streaming service Spotify, I have built up a large library of playlists. I was interest to build an app using my listening data, so made a GDPR request to get a copy of my personal data. When I received that data, I was disappointed to find it was not suitable for programmatic use, because the tracks in my listening history were identified not by any unique identifiers such as `spotify:track:4cOdK2wGLETKBW3PvgPWqT` which I could use to construct clickable song links, just by freeform text strings. Through a long and complicated saga, explained in detail in [ARI9.1](#ari-9.1), which involved much persistence and sending over 30 e-mails in an eight-month period, I was ultimately successful in getting Spotify to improve the format of their GDPR data returns, **not just for me but for all customers who make GDPR requests in future**. I had proven that one individual can use their GDPR rights to exert power over a corporation, with persistence. |
| A larger scale example of individuals forcing giant corporations to change is seen in the case of Facebook. In the early 2010s, Austrian lawyer Max Schrems began to pressure Facebook to disclose more personal data to their users. He created a tool to enable people to make their own data access requests, which over 40,000 people used. Faced with an overwhelming volume of work and massive liability of future data access requests, Facebook was forced to launch the self-service _Download Your Information (DYI)_ download tool, increasing transparency for all Facebook users worldwide [@solon2012]. Facebook was forced to increase its transparency further when Paul-Olivier Dehaye (now CEO of Hestia.ai) made a GDPR request (later backed by legal action) to force Facebook to disclose more information about which advertisers Facebook had enabled to target him using the _Facebook Custom Audiences_ feature. Apparently in order to avoid being embarrassed in court, Facebook updated _DYI_ so that every user's downloaded information includes a list of advertisers who have added you to a _Custom Audience_ [@dehaye2017]. Dehaye and Schrems both continue to act as HDR reformers and civic hackers following the discovery-driven activism approach, through their organisations _Hestia.ai_ [[ARI7.2OLD](#ari-digipower-OLD)] and privacy rights organisation _noyb.eu_ ('none of your business') [@schrems2017] respectively. |


### Design Insight 10: Collectives can compare and unify their data and use their pooled knowledge to demand change.

<span class="editnote">Position that this is designing at sociotechnical level</span>

| **<a name="insight-10">INSIGHT 10</a>: Collectives can compare and unify their data and use their pooled knowledge to demand change.** |
|:---------------------------------------------------------------------|
| Increasingly, the Internet that each individual experiences is not the same as that experienced by anyone else. Thanks to recommendations, targeted ads and social media feeds personalised to your interests, no two people will see the same digital reality. This makes it much more difficult for regulators or individuals to hold digital service providers to account than their analogue counterparts. In recent years, many activists have embraced **the power of collectives** to try and fill this regulatory gap, realising that together, they can discover far more than they can alone, and that through such collaboration there is an opportunity to improve awareness of digital providers' practices. |
| An example of this is the _WhoTargetsMe_ project, launched in 2017 [@jeffers2017]. The objective of this project was to monitor political advertising in the UK. Recognising (as larger studies have shown [@bakshy2015]) that everyone was seeing different advertisements, the goal was to have each individual report what adverts they see on Facebook, so that these can be pooled and compared with others. Over 50,000 people participated, building up an otherwise unavailable picture of the ways in which different political demographics were being targeted. This is a powerful mechanism available to collectives in this space: the ability to have **individuals obtain their own datapoints and then compare them**.
| Another example is seen in the Worker Info Exchange [@wie2022], a collective that helps gig economy workers such as _Uber_ drivers and _Deliveroo_ riders to make data requests. Using the pooled data, they conduct investigations to understand algorithmic inequalities and identify unfair treatment of worker by employers. They then help those workers to fight for better working conditions, much like a traditional trade union, but powered by collectively-sourced data. This resulted in Uber being taken to court, and some gains being made for drivers [@lomas2021; @dumas2021]. |
| As the aforementioned case with Max Schrems showed [[Insight 9](#insight-9)], collectives can be particularly powerful when exerting their data access rights _en masse_, and this can improve HDR and force greater transparency. René Mahieu and Jef Ausloos have published an exhaustive list of collective actions taken using GDPR rights, addressing issues such as discrimination by US colleges, corporate surveillance of climate activists, identifying gaps in data disclosures, and manipulation of users on dating apps [@mahieu2020a]. The authors identify that the GDPR provides an _architecture of empowerment_ and have called for better enforcement and for European authorities to provide better support for the ability for collectives to make data access requests together [@mahieu2020b]. Hestia.ai's _digipower_ investigation [[ARI7.2OLD](#ari-digipower-OLD)] concluded that data-discovery driven collectives are a vital step on the road to a more digitally empowered society [@pidoux2022, 70]. It is clear that organised collectives exploiting data access rights represent a powerful vector for impactful discovery-driven activism. |

### Design Insight 11: Automating the Identification of Entities can enhance Machine Understanding and Unburden Life Interface Users.

| **<a name="insight-11">INSIGHT 11</a>: Automating the Identification of Entities can enhance Machine Understanding and Unburden Life Interface Users.** |
| :------------------------------------------------------------------ |
| Having identified the need to assign every piece of a user's life information to a particular partition (or multiple partitions) of their life, it quickly becomes apparent that this would be _too much work_ for the user to do alone. Systems that use manual categorisation and tagging to classify information work best with a large userbase to contribute effort to the classification operation [@golder2006]. As part of the explorations of PDS approaches at BBC R&D, I therefore also examined how this challenge might be addressed (considering also that effort could be a deterrent to adoption [Objective 5 [[8.5](#8.5)]]). I identified an approach that could help with this problem: If the _entities_ (for example, a person, a place, an event or a topic) associated with a piece of data can be programmatically identified, then a lot of the **assignment of data to life partitions can be handled automatically**. For example, association with your office location would indicate that any data associated to that location is likely to relate to the 'work' part of your life, and this could be done automatically, reducing the effort for the PDS user. The process of **identifying entities within data**, known as _entity extraction_ or _named entity recognition (NER)_ is a well-established technique, which relies on the trained recognition of proper nouns and keywords combined with the statistical analysis of sentence grammar [@marshall2019]. This technique is used extensively in text-mining products within the Content Analytics industry such as those produced by my former employer, OpenText (formerly nStein) [@opentext2022]. However, in the context of a PDS, I propose that new techniques can be applied, making use of the data touchpoints into different parts of an individual's life to identify entities relevant to them personally (including, for example, names of friends or private projects that a standard NER solution would not detect). Data is full of references to entities that have personal relevance in your life. Finding these allows meaningful metadata to be attached to each datapoint. [Figure 9.11](#figure-9.11) shows how a large number of entities could be detected from different parts of an individual's data once it has been imported into a PDS environment: |

<span class="editnote">renumber figure</span>

![Figure 9.11: Identifying Entity Associations in Data](./src/figs/fig9.11-finding-entities-in-data.jpg){#figure-9.11}

|(continues…)|
|:--|
| This sort of approach could be quite powerful in reducing the effort for life interface users. By scanning the data, the most prevalent entities could be identified, and the user need only assign the entities to different parts of their life, as illustrated in the first two frames of [Figure 9.10](#figure-9.10). This would then allow hundreds of associated data points which had been programmatically associated to that entity, to be assigned to the correct 'bucket' or life partition. I was able to prototype this technique successfully to prove the concept [[ARI7.1OLD](#ari-bbc-OLD)]. |
| While such an approach would not be perfect, and there would need to be some corrections made by the user, this is far preferable to them having to provide all the classifications and is likely to motivate greater engagement. I have observed in user experience design and consideration of productivity systems that users are more motivated to correct errors, than to fill in a blank page. |
| Philosophically, we are moving here towards a _learning system_, a system that can be told when it is right and when it is wrong, and get better at classifying things correctly, analogous to the way an executive might train an assistant to anticipate his/her needs better, a sort of _digital life assistant_ [@bowyer2018grandvision]. Bayesian classification techniques could also be used to help with the learning here [@geeks2022]. This approach is also useful for _ecosystem detection_–as outlined in [Insight 4](#insight-4)–as identification of relationships with external entities is a key first step to mapping a user's ecosystem. |

### Design Insight 12: The 'Seams' of Digital Services need to be Identified, Exploited and Protected.

<span class="editnote">Position that this is designing at sociotechnical level</span>

| **<a name="insight-12">INSIGHT 12</a>: The 'Seams' of Digital Services need to be Identified, Exploited and Protected.** |
| :------------------------------------------------------------------------ |
| As identified in [8.4.1](#8.4.1), product design (be it hardware or software) is political. Designers pass some power to the user through their design, but also, users should be able to take some power on their own terms. This is the case made by Cristiano Storni in his 2014 paper on _the politics of seams_, Cristiano Storni identified the idea of _empowerment-in-use_ which advocates the idea that people need to **appropriate** their technologies to different uses that the designers may not have foreseen [@storni2014]. This is blocked by current black box, limit-what-the-user-can-do thinking. Central to this capability is the concept of _seams_ - those **exposed areas which the user is free to change**. This concept was proposed by Mark Weiser and developed by Chalmers and others [@weiser1994; @weiser1997; @chalmers2003]. Changes such as closures of APIs or removal of ports [[8.4.2](#8.4.2)] can be seem as the removal of seams. As Storni highlights, the availability of design seams is a critical determiner of user power. Companies gain power and reduce agency when they remove or restrict activity at seams. It follows that by identifying, exploiting and protecting the seams of digital services and devices, user autonomy and the viability of data-unification efforts can be protected.|
| **An unseen battle is for the free flow of information is underway** at the seams of today's digital products. |
| Hackers, civic activists and makers seek to repurpose and exploit the edges of products for their own means, while digital service providers and platforms try to block such activity. For example: |
|  - A successful tool called Findings allowed people to clip and share their favourite quotes from Kindle books. Amazon blocked and banned this tool, and the company shut down [@hazardOwen2012; @maldre2012].
|  - Louis Barclay created a tool called Unfollow Everything, which allowed Facebook users to automatically unfollow all friends and pages, in order to give them greater control of their News Feed reading experience and avoid being manipulated into reading more than they want to. He was banned for life from Facebook and threatened with legal action should he ever build any tools that manipulated the Facebook experience [@barclay2021]. |
| - Various activist groups have for several years been fighting to give individuals the legal _**right to repair**_ their own products [@miller2021], which has often been blocked through planned obsolence, inaccessible seams or restricting access to parts. The problem has been described as _**device tenancy**_, the idea that our relationship with our technology products is more like a tenant, where a landlord retains overall control and permits us to perform certain activities [@tufecki2019]. New laws have been introduced in the EU [@tett2022], forcing companies to support individuals to repair their devices. Apple has subsequently released self-service repair kits, though these themselves force parts to be paired with particular phones, limiting the utility of self-repair [@mooreColyer2022]. |
| - As detailed in my co-authored paper with Louis Goffe and colleagues [@goffe2021; @goffe2022], _**web extensions**_ and _**web augmentation**_ offer a powerful technique for modifying web experiences and repurposing user interfaces. This is because once a website is loaded into your browser, it is no longer under the control of the remote site, and by creating a _web extension_ to run code within your local web browser that loaded website can be edited, _scraped_ [@p2021], or otherwise repurposed. This has been successfully used to stop clickbait, dispute fake news, combat addiction, filter explicit words and more. However, in order to re-assert control over these customisations, Google has announced changes to the way Chrome extensions will work, which could 'stifle innovation' and limit what developers can do within the web extension [@miagkov2019]. |
| - An example from 2016 shows how seams can be exploited to obtain information and increase transparency. By brute force querying of a Facebook API, researchers were able to identify a complete list of 282,000 interests on Facebook and identify the relative popularity of each interest. [@havlak2016]. |
| - A number of HDR reformers, myself included, had identified a new seam for subverting some of Facebook's control over how its content is consumed [[8.4](#8.4.2)]: _accessibility tags_ or _ARIA tags_ [@aria2022]. These are specially marked-up tags in HTML web pages used by screenreaders to display or read content in a more accessible way for partially-sighted or blind people. Because these show page content in a standard format (whereas the HTML of most web pages varies widely and often changes), they present a reliable way to more easily _scrape_ content from the loaded web page within a web extension. In experiments at Open Lab, posts were successfully scraped from friends' feeds (which Facebook do not make available anywhere except the News Feed) so that they could be consumed separately in a more human-focused user experience. This technique has been used successfully to monitor Facebook ads by NYU's _Ad Observatory_ [@watzman2021], and was used by _WhoTargetsMe_ [[Insight 10](#insight-10)]. In 2021, Facebook was found to have deliberately obfuscated content within ARIA tags to prevent such investigations, resulting in visually impaired users being _unable to differentiate_ ads from posts, and _hearing junk characters_ read aloud. This can be taken as an adversarial stance against researchers, activists and HDR reformers, and shows that companies like Facebook will go to extraordinary lengths to assert their dominance and reduce user agency [@faife2021].
| - One reason why many companies and services have produced apps is because these are much more locked-down and controllable than the web browser environment; there are fewer seams. However, adopting the same philosophy as using web extensions to modify web-based experiences, and drawing on data flow auditing technologies like TrackerControl [[9.3](#9.3)] researchers at Oxford University have now developed techniques by which mobile apps can be reverse-engineered and modified to change user experiences to better meet users' needs, offering the promise of a _right to fair programs_ [@kollnig2021appThatWay].
| These examples make it quite clear that Storni was right: **product seams are the place where control can be asserted or regained**. They are the setting for an ongoing battle for the freedom and integrity of today's information landscape, and it is important for HDR reform that this space is specifically targeted. The role of the HDR reformer here is twofold: |
|   1) To **surface information injustices**, especially the closures of seams. |
|   2) To **push or 'hack' the seams to gain transparency and re-assert control**, including gaining access to otherwise inaccessible data and to acquire new functionality. |
| In this context, the work of whistleblowers such as Frances Haugen [@horwitz2021] and Edward Snowden [@macaskill2013] is particularly validated and important. Whistleblowers can expose internal practices that harm the information landscape's integrity that are not otherwise visible. In order to hold online platforms to account, the public must be **aware** and **able to attribute** any restriction in freedom or information access to the correct source. They need to know that the information or functionality is being modified or restricted. These ideas are explored further in [@bowyer2017]. Seams should be much more in the public consciousness than they are. |

### Design Insight 13: It is Possible (and Necessary) to Demonstrate Business Benefits of Transparency and Human-centricity

| **<a name="insight-13">INSIGHT 13</a>: It is Possible (and Necessary) to Demonstrate Business Benefits of Transparency and Human-centricity** |
|  :------------------------------------------------------------------------ |
| As outlined in [8.5](#8.5) and in this section, it is essential that work is done to persuade data-holding organisations of the benefits of moving towards the new paradigms outlined in this thesis. The following avenues for possible future research and advocacy toward data holding organisations have been identified:|
| - **Trust & Reputation**: In line with the third _public relations_-like aspect of HDR [[7.3](#7.3)]  as well as the recommendations in [4.3.4](#4.3.4), [4.4.1](#4.4.1), [5.5.2](#5.5.2) and [6.2.1](#6.2.1), displaying a more inclusive, open and supportive attitude to data handling could strengthen the service relationship and increase customer loyalty and trust. Organisations that are seen to have good Human Data Relations are preferred. |
| - **Consent**: In the wake of the GDPR, ensuring consent is becoming an increasing concern to organisations, and the risks of legal consequences for mistakes are high. It makes sense that a more dynamic [@bowyer2018family; [4.4.1](#4.4.1); [5.5.2](#5.5.2); [6.2.2](#6.2.2)] consent approach that involves individuals [[6.2.3](#6.2.3)] and keeps them in the loop would enable them to speak up much earlier and express consent wishes that might otherwise go undetected. |
| - **Accuracy**: The best-placed person to spot errors in data's accuracy or fairness is the individual about whom the data is concerned. Therefore, increasing their involvement is likely to improve the quality of the data, especially if additional data is contributed or curated by the service user [[4.3.3](#4.3.3.4), [6.2.3](#6.2.3)] |
| - **Liability**: In an increasingly litigious society, storage of personal data, especially health or financial data, is a significant liability for businesses, especially if something goes wrong. Investment in human-centred personal ecosystems would outsource the storage of sensitive data to data trusts or PDS providers, reducing liability for the service business. By ensuring that data is accessed only in ways that are centralised outside of the business and remaining in the user's control—such as PDS company digi.me's Private Sharing model [@digimePrivateSharing; @bowyer2020bbcreport]—organisations can ensure that have negligible risk of mishandling customer data. |
| - **Better Customer Targeting** The most radical, but perhaps the most persuasive, business model relating to better HDR, is the VRM approach [[2.3.4](#2.3.4)], where individuals express their own service or product desires explicitly, which vendors then respond to. This turns traditional models inside out, and would empower users more, but due to the inherently improved accuracy of a self-declared interest, might also give businesses a greater confidence that their investment in converting those customers to a sale would be worthwhile. It is important to remember that the current drive towards collecting more data that drives the platformisation trend is in order to improve ad targeting, so that businesses can get a better return on their investment. A VRM approach, or any other approach where the individual contributes improved data to their data self, is in line with that current business objective. |

<span class="editnote">Add wrap up to this section here</span>

Pragmatic Reflections on Pursuing Better HDR{#10.2}
--------------------------------------------

<span class="editnote">ADD NEW SECTION ON PRAGMATIC REFLECTIONS. starting by saying what C8 did and didn't do in terms of obstacles etc.</span>
<span class="editnote">add some words highlighting that there are very difficult questions, but that by operationalising HDR i show some of what is possible, not an answer to these questions but a direction of travel. talk about viability and the need for these practical endeavours to acknowledge the challenges i identified. notes: Resolving this tension between what is wanted, what is possible (technically) and what barriers are organisationally/legally is interesting. The contribution here is showing what is possible and how to get there. Whilst I also like the optimism about how to leverage law and design to support and help citizens, still need for more criticality about viability of these routes in practice? How do we balance the paternalism with law, and values defined as societally beneficial e.g., transparency, accountability, privacy, the local desire for these to be realised, as shown in your data, and the reality of surveillance capitalism and ‘if you’re not paying, you’re the product’? </span>
<span class="editnote">write more about HDR literacy and *whose responsibility it is* (ref recursive public, policy, designers - all designers should consider this - etc). I need to more explicitly talk about the burden/impact on the citizen (as Dave said, use the accountant analogy, etc, or environmental impact advise, or mechanic, etc)). Notes: HDR literacy - again, how much of this should be pushed to individuals, e.g. to rely on their legal rights and seek portability/erasure etc? How much is this failure of system/service design where this should be done by default and implemented to prevent putting burden on users in first place? <br/> More notes from examiners: <br/> Usability point - what support for ‘what next’ does HDR provide – once individuals have oversight, what then? Is that enough, or is this also about challenging current business models? Whilst choice is good – it does push debate to what are they choosing in relation to? And do they have capacity, time, energy, means to really choose (like with consent?) Wary of pushing too much back to the citizen to deal with, when these are structural design decisions around service delivery or business model, and regulatory failings (often as a result of lobbying during legislative process).</span>
<span class="editnote">Section about Feasibility / Practicality? A Challenging Road Ahead / Designing the Future.</span>
<span class="editnote">more specific discussion on the challenges of unification and liabilities. make clearer the relationship between law and desired change, and how to balance needs of different parties.notes: Given the focus on GDPR, how much do you see law as enabling or inhibiting changes in design practice and balancing value conflict? e.g., process transparency around data processing vs use of IP rights to limit AI transparency? or individual oversight (which may be limited in its utility) vs collective oversight or enforcement authority ? . notes: The idea of unifying data is interesting as whilst it could add value from a usability perspective, giving an understanding of data insights (p243)– it prompts questions though around DP realities of linking data, and roles of different controllers/processors around managing their various obligations if it is unified e.g. risks of new identification harms/connections being made that otherwise were partitioned. </span>
<span class="editnote">legal vs reality difference: How do we align what people want with governance and socio-technical structures that shape what they can have? For example, many of the requirements elicited from fieldwork broadly reflect what we would hope would be best practice from many legal frameworks (GDPR, ePrivacy Directive, Consumer Rights Act, DSA etc), yet power structures around services are such they are not realisable in practice? I am not sure what is actionable for me here in this c1 feedback point. Ask the examiners?</span>
<span class="editnote">highlight the design problem. The future work section should frame some of what i have offered in C6 as a design problem (informed by the insights). notes: What mechanisms are there to support individuals navigating their data in an everyday way and how can design respond to that complex problem? HDR seems well placed to contribute here not just defaulting to XAI (explainable AI) type approaches which may have little value for individuals?</span>
<span class="editnote">Notes on how we can apply HDR to design practice: There can be a clear disconnect between what law may frame as being protected vs what is possible in practice... How do we reconcile expectations/wants with reality of what is feasible/aspirational/implementable? What role can designers play – i.e., how can we apply HDR to design practice? This involves considering the different roles of HDR from activist adversarial orientated through to establishing areas where greater translation between design and law is needed to supporting compliance with GDPR. Good point from discussion around inadequacy of what GDPR seeks at times too e.g. data changing all the time – copy is not working – data access should be around person understanding of data... if bundle of files this is static and loses nature of data being interpretable and relational.</span>
<span class="editnote">consideration of e.g. pseudonymous data, CCTV, AI emotion identification, etc and how that relates to PD (I would argue, still needs to be made understandable, however hard). Notes: Attending to importance of specificity of law in defining the problem space for HDR. 2 examples. Personal data (PD) is a term of legal art - if there is not identification/singling out of individuals then it might not be PD, and therefore no rights under GDPR. This occurs with data driven systems where intent is not identification or unclear if PD being processed and therefore scope of protection limited... e.g. emotion sensing AI systems. How does your work deal with that tension in limits of the law, and also of what people may want or feel is there data may not in fact have the legal protections they desire around it?</span>
<span class="editnote">risk of people having to sacrifice data, no choice. (ref to C5?)</span>
<span class="editnote">individual data being lost in a big data whole, and how that doesn't absolve the company of responsibility, or the individual of having an interest (maybe use an example like car traffic data... or CCTV.. how could it be accountable / providence?). Notes: Related to this, with the uncertainty, opacity etc around how data is consumed/used in organisations (training data for models etc) - how does this implicate the model of human data relations? how do we have relations when the data may be a mere weighted variable in a larger decision making process? Does this lead to apathy for direct relations and concern around indirect relations and what does HDR offer in dealing with this?</span>


Limitations and Future Work{#10.3}
----------------------------------

<span class="editnote">ADD NEW SECTION ON LIMITATIONS AND FUTURE WORK. Notes: Need for a Future Work Section which reflects awareness of topics that are pertinent for the PhD but have not been explored and will not be in depth e.g. awareness of value sensitive design for notion of publics; awareness of limitations of individualist nature of DP law/PIMs and recognising need to consider role of HDR in addressing collective/group interests; recognition of relationality of data vs individual framings in law. </span>

<span class="editnote">community engagement/reflection.  (but can say, work like this is happening e.g by others with Hestia) (in fact this could be a really good next step for future researchers - workshops to validate and build on my findings ACROSS participatory and industrial. Also consider individualist stance of author vs what is lost by not appealing to grassroots communities and closing loop. Constanza Chock ref.</span>
<span class="editnote">focus on GDPR is limiting. Notes: How do you balance interests of an individual around their data and the collective nature of data? Particularly as law is not very good at protecting group data currently (GDPR has very individualistic rights). This is an opportunity for design and HDR to play a greater role, where there is currently a gap due to law.</span>
<span class="editnote">talk about limitations of indiv. approach. explicitly say somewhere that focus on GDPR is limiting, data is inherently collective (and given meaning by e.g. how people are grouped/compared against others, relationships and interactions that are arguably data of multiple people, etc). (or is this more case study two). Group rights. Examiner comment:<br/>Notion of empowerment does align with many liberal democratic ideals around individualised human rights and enabling rights (e.g. DP / Privacy). Given data is often social and interpersonal, pertaining to multiple individuals, it is not just their own data. The individualised nature of data protection rights in particular are increasingly stretched to resolve collective harms (e.g., around categorisations/sorting from algorithmic systems) not currently not dealt with well under individual rights framings – due to limited scope for collective action. How does this map onto your framing of ‘a desire for empowerment’, to help group rights and responses to undesirable ways of interacting with data? this is part of supporting empowered digital citizen(s). (you recognise this point on p182). With individualism – empowerment aligned to individual (acknowledge that others exist – collective rights etc) – point to future work – limitations of individual to empowerment – harm to collective (e.g. Group Privacy – Taylor et al book) link (also I have emailed the library)</span>
<span class="editnote">Further work, acknowledge limitations of Human Centric Futures – what about ‘more than human design’ here? Going beyond the individual, human centric approach – what about groups, environment and data in its ecosystem of processing/collection/storage/management and wider social context? Flag for further work section literature from Paul Coulton; Elisa Giacardi; Ron Wakkary.</span>
<span class="editnote">Acknowledging the limitations of feedback loop not closed with PD done in Part A with Part B. Flagging that Part B is derived from industry/internships, has different value to if this was just another study as part of more conventional structure that may have followed from Part A.</span>
<span class="editnote">add additional text about 'data processor'. Appreciate desire in thesis to avoid terms of legal art such as data subject, processor and controller for individuals and data holders – worth reflecting on what is lost in not using these? For example, specific obligations faced by controller’s vs processors in GDPR? Limits in the use of terminology like personal data/controllers which highlight gaps in protection cf domestic data controllers and impacts for individuals who may be subject to GDPR responsibilities running IOT in their homes link </span>


Personal Reflection{#10.OLD1}
-------------------

<span class="editnote">UPDATE TO REMOVE PART ONE AND TWO REFS</span>

As an experienced software engineer, power user and technology blogger, who had considered the loss of digital agency for many years [[1.1](#1.1)], my journey into this research space was an unusual one; I arrived with already-formed ideas about the nature of the problem. This was not an ideal match for the traditionally participant-led approach of HCI, where ideas and insights normally arise solely from one's participants. However, through the discipline of the _Digital Civics_ programme, the process of publishing peer-reviewed papers. Recognising that HDR issues would be unlikely to surface organically, I was able to use careful sensitisation [[3.5.1](#3.5.1)], balanced and open questioning and neutrally-designed stimuli [[3.5.2](#3.5.2)] in a way that elevated participant experience to be the primary source of data, to produce findings and discursive conclusions that are as much the participants as my own.

Along the way I discovered vital areas of literature and existing work, most notably the foundational work of Weiser, Abowd, Crabtree and others [[2.3.1](#2.3.1); [2.3.3](#2.3.3)], the sub-discipline of _Human Data Interaction_ [[2.3.2](#2.3.2)] and the emergent innovation around _Personal Data Ecosystems_ and _MyData_ [[2.3.4](#2.3.4)]. Collectively through these discoveries, I solidified my existing understandings and was able to contextualise my evolving learning against the established research landscape.

As my understanding from the Case Studies coalesced into a clear, cross-validated understanding of what people want from data and from data holders [[Chapter 6](#chapter-6)], this gave me the confidence to grow and evolve as a researcher; moving from investigatory or theoretical research towards activist exploration of how to work towards delivering these new capabilities in practice, enabled by the models and ideas I developed. This ultimately gave me the confidence to recognise that, in this body of work, I have identified something newly emergent, that deserved to be named, scoped, and explored—**the research agenda for better Human Data Relations**.

I was especially lucky to find peripheral activities, especially with the BBC and Hestia.ai, that fitted so well alongside my research agenda. These activities slotted perfectly into the action research cycle [[3.2.2](#3.2.2); [Figure 3.14](#figure-3.14)] of my thesis, producing a powerful feedback loop where findings from the academic inquiry became immediately applicable in practical settings, while experiences of the real-life barriers to pursuit of the HDR goals helped to challenge and evolve the theoretical models (such as shared data interaction) emerging from the Case Studies. The real-world contexts provided a place where emerging qualitiative findings and design ideas could be tested and iteratively improved through attempts to operationalise them, producing exceptionally grounded and actionable learnings.

This dual research-and-practice approach has allowed me to push this thesis further than a traditional HCI study would allow, and underpins the two-part structure of this thesis, where in Part Two I leave behind the traditional researcher-as-observer stance and step forward into taking an active role as an expert in user-centred design (UCD) [[3.2.1](#3.2.1)] and practical software interface and process design and innovation.

It has been a tremendous privilege to spend six years understanding in great detail the nature of the problems facing our data-centric society, to translate those impacts into tangible needs, and to be able to map out the landscape and possibilities for improving the way we relate to data. Through this research, I have discovered rich evidence to quantify and qualify the losses of agency I had observed, in a far greater level of detail than existing research. The programme has also given me space to experiment with using both GDPR and web-scraping to access data and push boundaries, to really embrace my role as an HDR activist and adversarial designer [[3.2.1](#3.2.1); [Figure ARI7.1](#figure-ari7.1)]. It has allowed me design and prototype new models and views of data and of information which have transformed the way I look at digital information and how we relate to it, in particular:

  - the five types of held data [[Table 5.2](#table-5.2)],
  - the two purposes of HDR [[Figure 7.1](#figure-7.1)], and
  - the approaches to effecting change in the HDR landscape [Figures [9.1](#figure-9.1), [9.2](#figure-9.2), [9.19](#figure-9.19), and [9.21](#figure-9.21)].

I hope these models, as well as the other contributions [[1.2](#1.2)], can help others to develop their thinking in the same way, to become HDR-literate and contribute to the crusade for HDR reform that the world so desperately needs.

The collaborative opportunities have been significant. Without this PhD, I would never have had the opportunities to discuss and develop models for personal data interaction and improved ecosystem negotiability with experts at the BBC, Hestia.ai and the wider _MyData_ community. Alongside these formal collaborations, I have disseminated ideas through blogs, tweets, workshop papers and lectures, which has helped to refine and clarify ideas but also to stimulate valuable discussions with interested people to gain feedback that helped develop the models and my own learning further.

This opportunity has opened doors that have allowed me to pivot my career towards putting these learnings into action, working on important projects [[7.2](#7.2)] to explore how data interaction reforms can be realised in practice, and how we can become not just innovators but social data activists. Thanks to this research, I am now a Senior UX Designer with BBC Newcastle, where I will be able to bring the benefits of this research to the general public through the design of services and interfaces that aim to inform, educate and entertain people in their everyday lives. I now know how to begin to have an impact, how to work on building that better HDR future I and my participants have imagined. It is the journey of a lifetime, and also one that is in many ways just beginning. I hope that my work and this thesis can contribute to a better, more human-centric digital world, and I can't wait to see where this leads.

Legacy of This Thesis to The Future of Human Data Relations{#10.OLD2}
-----------------------------------------------------------

<span class="movenote">MOVE SOME DETAILS OF CONTRIBUTIONS ETC HERE FROM C1</span>
<span class="editnote">UPDATE THIS SECTION TO INCLUDE SOME DETAIL AS WELL AS HIGH LEVEL</span>
<span class="editnote">REMOVE REF TO PAR - REFERENCE my hybrid method instead</span>
<span class="editnote">refer back to the research gap in 2.2.5, make sure i have a clear story on how I addressed it. notes: Need to consider how insights are being balanced when there are tensions? For example, making data united/unified could be quite controversial when linking data may present new risks of identification that may have not been there before. Or knowing the data’s provenance (particularly if implicating personal data of others, which can often be the case as it is often interpersonal and collected across multiple persons, in multioccupancy homes for example). This nature of data implicating others is recognised as a research gap (s2.2.5 – data beyond the individual), but wondered how you deal with that gap?</span>
<span class="editnote">weave in observation that mdata should not be an owned commodity; instead, it is reflective of something real, which is an aspect of the human, and hence not anyone else's to separate/extricate them from without their involvement/consent. inadequacies not just of regulation but of law. (and the possible insolubility of that - e.g. a photo of someone else). notes: Also, how to manage balance of data not being seen as something that can be ‘owned’, but instead as part of a fundamental human right to private and family life. Risk in PIMS systems of seeing data as something once it is controlled that may then be commodity to be used as people want. Yet, paternalism of HR law says everyone has inalienable rights in such data, and can’t get to point where some can afford to keep privacy whilst others need to ‘transact’ with their data. </span>
<span class="editnote">Make impacts clearer: methodology adopted, informing industrial research and policy, key pubs & dissemination, five types data model</span>

This thesis offers a detailed understanding of individual needs around data interaction and data-centric service relationships [[Chapter 6](#chapter-6)], backed by participatory action research in both public sector and private sector Case Studies [[Chapter 4](#chapter-4); [Chapter 5](#chapter-5)], providing a clear answer to the two primary research questions RQ1 [[3.3.1](#RQ1)] and RQ2 [[3.3.2](#RQ2)]: People want visible, understandable and useable<sup>[10](#fn10)</sup> data, process transparency, individual oversight capabilities and involvement in decision making.

Furthermore, based on a solid grounding in existing literature, policy and innovation around Data Access, Personal Information Management, Human Data Interaction and Human-centric Innovation [[Chapter 2](#chapter-2)], these needs are synthesised into a clearly-defined new field for future research and innovation, _Human Data Relations (HDR)_ [[7.3](#7.3)], encompassing four clear objectives [[Chapter 8](#chapter-8)] for improving individual agency and societal power imbalances around data:

  (i) data awareness & understanding, <br/>
  (ii) data useability<sup>[10](#fn10)</sup>, <br/>
  (iii) data ecosystem awareness & understanding, and <br/>
  (iv) data ecosystem negotiability.

The inclusion of Chapters [7](#chapter-7), [8](#chapter-8) and [9](#chapter-9) took the thesis much further than a traditional HCI PhD, drawing on the author's experiences with the practical pursuit of better Human Data Relations in four different real-world academic and industrial project settings [[7.2](#7.2)]. Through additional insights, designs and implementation strategies [[Chapter 9](#chapter-9)], the thesis offers not just a theoretical frame for this area of research, but clear and actionable insights that could be immediately explored by researchers and innovators - **an anthology of reference material, designs and strategies for HDR reform**. This practical contribution of the thesis is delivered in four distinct parts:

- first, a **map of the landscape for improving HDR** [[7.7](#7.7)], outlining the key **obstacles** that are likely be faced in pursuing HDR objectives [[Chapter 8](#chapter-8)], including illegible, immobile, scattered and unmalleable data; a complex ecosystem lacking metadata; exploitations of power by data holders, introspective practices, insufficient machine understanding of human information, and gaps in interoperability, investment and demand;
- second, **four detailed approaches** for making progress in the pursuit of better HDR, illustrated with reference to real-world projects situated in the HDR space: (i) discovery-driven activism (ii) life interface design, (iii) protection of, and progressive action within, the information landscape and (iv) motivational efforts to make better HDR viable, investable and well-understood across society [[Chapter 9](#chapter-9)];
- third, through **a series of specific insights** that can aid the pursuit of better HDR, including conceptualisations around **life information** and **ecosystem information**, deep understandings of the ways in which service providers exert power over the data economy and at the seams of their products; practical trajectories for change including entity identification, individual and collective data activism; and methods for acquiring additional metadata, provenance and context so that systems can better understand and represent human information [[Insights](#inset-boxes)]; and
- fourth, **an HDR index**, located [after the Appendices](#hdr-index),  making the novel findings, insights, obstacles, approaches and strategies of this thesis easy to locate, accompanied by a glossary explaining existing terms and nomenclature this thesis makes use of.

Through its Case Studies, this thesis has made additional contributions to the fields of Early Help and GDPR Data Access, detailed in [[1.2.3](#1.2.3)] and [[1.2.4](#1.2.4)]. Nine publications, workshops and presentations of the work in this thesis have been delivered [[1.3](#1.3)], and this body of research has already contributed value to real-world industrial projects at BBC R&D in the UK, Hestia.ai in Switzerland and their client Sitra in Finland.

Through the grounded and detailed references and examples in Part Two, this work moves beyond conducting research to understand human personal data wants, and **sets the scene for an progressive and activist agenda** to take action in service of those wants, with the objective to reconfigure society to one where those human-centric needs are better met. It constitutes **a call to arms** for future research, innovation and activism in Human Data Relations, combined with a detailed guide to understand the data economy landscape, what needs to change, and an arsenal of design and implementation strategies for how HDR reformers might fulfil their role as a recursive public [[7.8](#7.8)]. Armed with these insights, practitioners of this new field of HDR can **drive us towards a better future** to deliver increased agency for individuals, greater data use capabilities, and a more balanced landscape around the use of personal data by service providers across society—in short, a better world for us all.

---
