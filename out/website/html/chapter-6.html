<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang xml:lang>
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Alex Bowyer" />
  <title>Understanding and Improving Human Data Relations</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <style type="text/css">

html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{-webkit-box-sizing:content-box;box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{-webkit-box-sizing:border-box;box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{-webkit-box-sizing:border-box;box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}html{font-family:sans-serif}.hidden,[hidden]{display:none!important}.pure-img{max-width:100%;height:auto;display:block}.pure-g{letter-spacing:-.31em;text-rendering:optimizespeed;font-family:FreeSans,Arimo,"Droid Sans",Helvetica,Arial,sans-serif;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-flow:row wrap;flex-flow:row wrap;-ms-flex-line-pack:start;align-content:flex-start}@media all and (-ms-high-contrast:none),(-ms-high-contrast:active){table .pure-g{display:block}}.opera-only :-o-prefocus,.pure-g{word-spacing:-.43em}.pure-u{display:inline-block;letter-spacing:normal;word-spacing:normal;vertical-align:top;text-rendering:auto}.pure-g [class*=pure-u]{font-family:sans-serif}.pure-u-1,.pure-u-1-1,.pure-u-1-12,.pure-u-1-2,.pure-u-1-24,.pure-u-1-3,.pure-u-1-4,.pure-u-1-5,.pure-u-1-6,.pure-u-1-8,.pure-u-10-24,.pure-u-11-12,.pure-u-11-24,.pure-u-12-24,.pure-u-13-24,.pure-u-14-24,.pure-u-15-24,.pure-u-16-24,.pure-u-17-24,.pure-u-18-24,.pure-u-19-24,.pure-u-2-24,.pure-u-2-3,.pure-u-2-5,.pure-u-20-24,.pure-u-21-24,.pure-u-22-24,.pure-u-23-24,.pure-u-24-24,.pure-u-3-24,.pure-u-3-4,.pure-u-3-5,.pure-u-3-8,.pure-u-4-24,.pure-u-4-5,.pure-u-5-12,.pure-u-5-24,.pure-u-5-5,.pure-u-5-6,.pure-u-5-8,.pure-u-6-24,.pure-u-7-12,.pure-u-7-24,.pure-u-7-8,.pure-u-8-24,.pure-u-9-24{display:inline-block;letter-spacing:normal;word-spacing:normal;vertical-align:top;text-rendering:auto}.pure-u-1-24{width:4.1667%}.pure-u-1-12,.pure-u-2-24{width:8.3333%}.pure-u-1-8,.pure-u-3-24{width:12.5%}.pure-u-1-6,.pure-u-4-24{width:16.6667%}.pure-u-1-5{width:20%}.pure-u-5-24{width:20.8333%}.pure-u-1-4,.pure-u-6-24{width:25%}.pure-u-7-24{width:29.1667%}.pure-u-1-3,.pure-u-8-24{width:33.3333%}.pure-u-3-8,.pure-u-9-24{width:37.5%}.pure-u-2-5{width:40%}.pure-u-10-24,.pure-u-5-12{width:41.6667%}.pure-u-11-24{width:45.8333%}.pure-u-1-2,.pure-u-12-24{width:50%}.pure-u-13-24{width:54.1667%}.pure-u-14-24,.pure-u-7-12{width:58.3333%}.pure-u-3-5{width:60%}.pure-u-15-24,.pure-u-5-8{width:62.5%}.pure-u-16-24,.pure-u-2-3{width:66.6667%}.pure-u-17-24{width:70.8333%}.pure-u-18-24,.pure-u-3-4{width:75%}.pure-u-19-24{width:79.1667%}.pure-u-4-5{width:80%}.pure-u-20-24,.pure-u-5-6{width:83.3333%}.pure-u-21-24,.pure-u-7-8{width:87.5%}.pure-u-11-12,.pure-u-22-24{width:91.6667%}.pure-u-23-24{width:95.8333%}.pure-u-1,.pure-u-1-1,.pure-u-24-24,.pure-u-5-5{width:100%}.pure-button{display:inline-block;line-height:normal;white-space:nowrap;vertical-align:middle;text-align:center;cursor:pointer;-webkit-user-drag:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-box-sizing:border-box;box-sizing:border-box}.pure-button::-moz-focus-inner{padding:0;border:0}.pure-button-group{letter-spacing:-.31em;text-rendering:optimizespeed}.opera-only :-o-prefocus,.pure-button-group{word-spacing:-.43em}.pure-button-group .pure-button{letter-spacing:normal;word-spacing:normal;vertical-align:top;text-rendering:auto}.pure-button{font-family:inherit;font-size:100%;padding:.5em 1em;color:rgba(0,0,0,.8);border:none transparent;background-color:#e6e6e6;text-decoration:none;border-radius:2px}.pure-button-hover,.pure-button:focus,.pure-button:hover{background-image:-webkit-gradient(linear,left top,left bottom,from(transparent),color-stop(40%,rgba(0,0,0,.05)),to(rgba(0,0,0,.1)));background-image:linear-gradient(transparent,rgba(0,0,0,.05) 40%,rgba(0,0,0,.1))}.pure-button:focus{outline:0}.pure-button-active,.pure-button:active{-webkit-box-shadow:0 0 0 1px rgba(0,0,0,.15) inset,0 0 6px rgba(0,0,0,.2) inset;box-shadow:0 0 0 1px rgba(0,0,0,.15) inset,0 0 6px rgba(0,0,0,.2) inset;border-color:#000}.pure-button-disabled,.pure-button-disabled:active,.pure-button-disabled:focus,.pure-button-disabled:hover,.pure-button[disabled]{border:none;background-image:none;opacity:.4;cursor:not-allowed;-webkit-box-shadow:none;box-shadow:none;pointer-events:none}.pure-button-hidden{display:none}.pure-button-primary,.pure-button-selected,a.pure-button-primary,a.pure-button-selected{background-color:#0078e7;color:#fff}.pure-button-group .pure-button{margin:0;border-radius:0;border-right:1px solid rgba(0,0,0,.2)}.pure-button-group .pure-button:first-child{border-top-left-radius:2px;border-bottom-left-radius:2px}.pure-button-group .pure-button:last-child{border-top-right-radius:2px;border-bottom-right-radius:2px;border-right:none}.pure-form input[type=color],.pure-form input[type=date],.pure-form input[type=datetime-local],.pure-form input[type=datetime],.pure-form input[type=email],.pure-form input[type=month],.pure-form input[type=number],.pure-form input[type=password],.pure-form input[type=search],.pure-form input[type=tel],.pure-form input[type=text],.pure-form input[type=time],.pure-form input[type=url],.pure-form input[type=week],.pure-form select,.pure-form textarea{padding:.5em .6em;display:inline-block;border:1px solid #ccc;-webkit-box-shadow:inset 0 1px 3px #ddd;box-shadow:inset 0 1px 3px #ddd;border-radius:4px;vertical-align:middle;-webkit-box-sizing:border-box;box-sizing:border-box}.pure-form input:not([type]){padding:.5em .6em;display:inline-block;border:1px solid #ccc;-webkit-box-shadow:inset 0 1px 3px #ddd;box-shadow:inset 0 1px 3px #ddd;border-radius:4px;-webkit-box-sizing:border-box;box-sizing:border-box}.pure-form input[type=color]{padding:.2em .5em}.pure-form input[type=color]:focus,.pure-form input[type=date]:focus,.pure-form input[type=datetime-local]:focus,.pure-form input[type=datetime]:focus,.pure-form input[type=email]:focus,.pure-form input[type=month]:focus,.pure-form input[type=number]:focus,.pure-form input[type=password]:focus,.pure-form input[type=search]:focus,.pure-form input[type=tel]:focus,.pure-form input[type=text]:focus,.pure-form input[type=time]:focus,.pure-form input[type=url]:focus,.pure-form input[type=week]:focus,.pure-form select:focus,.pure-form textarea:focus{outline:0;border-color:#129fea}.pure-form input:not([type]):focus{outline:0;border-color:#129fea}.pure-form input[type=checkbox]:focus,.pure-form input[type=file]:focus,.pure-form input[type=radio]:focus{outline:thin solid #129fea;outline:1px auto #129fea}.pure-form .pure-checkbox,.pure-form .pure-radio{margin:.5em 0;display:block}.pure-form input[type=color][disabled],.pure-form input[type=date][disabled],.pure-form input[type=datetime-local][disabled],.pure-form input[type=datetime][disabled],.pure-form input[type=email][disabled],.pure-form input[type=month][disabled],.pure-form input[type=number][disabled],.pure-form input[type=password][disabled],.pure-form input[type=search][disabled],.pure-form input[type=tel][disabled],.pure-form input[type=text][disabled],.pure-form input[type=time][disabled],.pure-form input[type=url][disabled],.pure-form input[type=week][disabled],.pure-form select[disabled],.pure-form textarea[disabled]{cursor:not-allowed;background-color:#eaeded;color:#cad2d3}.pure-form input:not([type])[disabled]{cursor:not-allowed;background-color:#eaeded;color:#cad2d3}.pure-form input[readonly],.pure-form select[readonly],.pure-form textarea[readonly]{background-color:#eee;color:#777;border-color:#ccc}.pure-form input:focus:invalid,.pure-form select:focus:invalid,.pure-form textarea:focus:invalid{color:#b94a48;border-color:#e9322d}.pure-form input[type=checkbox]:focus:invalid:focus,.pure-form input[type=file]:focus:invalid:focus,.pure-form input[type=radio]:focus:invalid:focus{outline-color:#e9322d}.pure-form select{height:2.25em;border:1px solid #ccc;background-color:#fff}.pure-form select[multiple]{height:auto}.pure-form label{margin:.5em 0 .2em}.pure-form fieldset{margin:0;padding:.35em 0 .75em;border:0}.pure-form legend{display:block;width:100%;padding:.3em 0;margin-bottom:.3em;color:#333;border-bottom:1px solid #e5e5e5}.pure-form-stacked input[type=color],.pure-form-stacked input[type=date],.pure-form-stacked input[type=datetime-local],.pure-form-stacked input[type=datetime],.pure-form-stacked input[type=email],.pure-form-stacked input[type=file],.pure-form-stacked input[type=month],.pure-form-stacked input[type=number],.pure-form-stacked input[type=password],.pure-form-stacked input[type=search],.pure-form-stacked input[type=tel],.pure-form-stacked input[type=text],.pure-form-stacked input[type=time],.pure-form-stacked input[type=url],.pure-form-stacked input[type=week],.pure-form-stacked label,.pure-form-stacked select,.pure-form-stacked textarea{display:block;margin:.25em 0}.pure-form-stacked input:not([type]){display:block;margin:.25em 0}.pure-form-aligned input,.pure-form-aligned select,.pure-form-aligned textarea,.pure-form-message-inline{display:inline-block;vertical-align:middle}.pure-form-aligned textarea{vertical-align:top}.pure-form-aligned .pure-control-group{margin-bottom:.5em}.pure-form-aligned .pure-control-group label{text-align:right;display:inline-block;vertical-align:middle;width:10em;margin:0 1em 0 0}.pure-form-aligned .pure-controls{margin:1.5em 0 0 11em}.pure-form .pure-input-rounded,.pure-form input.pure-input-rounded{border-radius:2em;padding:.5em 1em}.pure-form .pure-group fieldset{margin-bottom:10px}.pure-form .pure-group input,.pure-form .pure-group textarea{display:block;padding:10px;margin:0 0 -1px;border-radius:0;position:relative;top:-1px}.pure-form .pure-group input:focus,.pure-form .pure-group textarea:focus{z-index:3}.pure-form .pure-group input:first-child,.pure-form .pure-group textarea:first-child{top:1px;border-radius:4px 4px 0 0;margin:0}.pure-form .pure-group input:first-child:last-child,.pure-form .pure-group textarea:first-child:last-child{top:1px;border-radius:4px;margin:0}.pure-form .pure-group input:last-child,.pure-form .pure-group textarea:last-child{top:-2px;border-radius:0 0 4px 4px;margin:0}.pure-form .pure-group button{margin:.35em 0}.pure-form .pure-input-1{width:100%}.pure-form .pure-input-3-4{width:75%}.pure-form .pure-input-2-3{width:66%}.pure-form .pure-input-1-2{width:50%}.pure-form .pure-input-1-3{width:33%}.pure-form .pure-input-1-4{width:25%}.pure-form-message-inline{display:inline-block;padding-left:.3em;color:#666;vertical-align:middle;font-size:.875em}.pure-form-message{display:block;color:#666;font-size:.875em}@media only screen and (max-width :480px){.pure-form button[type=submit]{margin:.7em 0 0}.pure-form input:not([type]),.pure-form input[type=color],.pure-form input[type=date],.pure-form input[type=datetime-local],.pure-form input[type=datetime],.pure-form input[type=email],.pure-form input[type=month],.pure-form input[type=number],.pure-form input[type=password],.pure-form input[type=search],.pure-form input[type=tel],.pure-form input[type=text],.pure-form input[type=time],.pure-form input[type=url],.pure-form input[type=week],.pure-form label{margin-bottom:.3em;display:block}.pure-group input:not([type]),.pure-group input[type=color],.pure-group input[type=date],.pure-group input[type=datetime-local],.pure-group input[type=datetime],.pure-group input[type=email],.pure-group input[type=month],.pure-group input[type=number],.pure-group input[type=password],.pure-group input[type=search],.pure-group input[type=tel],.pure-group input[type=text],.pure-group input[type=time],.pure-group input[type=url],.pure-group input[type=week]{margin-bottom:0}.pure-form-aligned .pure-control-group label{margin-bottom:.3em;text-align:left;display:block;width:100%}.pure-form-aligned .pure-controls{margin:1.5em 0 0 0}.pure-form-message,.pure-form-message-inline{display:block;font-size:.75em;padding:.2em 0 .8em}}.pure-menu{-webkit-box-sizing:border-box;box-sizing:border-box}.pure-menu-fixed{position:fixed;left:0;top:0;z-index:3}.pure-menu-item,.pure-menu-list{position:relative}.pure-menu-list{list-style:none;margin:0;padding:0}.pure-menu-item{padding:0;margin:0;height:100%}.pure-menu-heading,.pure-menu-link{display:block;text-decoration:none;white-space:nowrap}.pure-menu-horizontal{width:100%;white-space:nowrap}.pure-menu-horizontal .pure-menu-list{display:inline-block}.pure-menu-horizontal .pure-menu-heading,.pure-menu-horizontal .pure-menu-item,.pure-menu-horizontal .pure-menu-separator{display:inline-block;vertical-align:middle}.pure-menu-item .pure-menu-item{display:block}.pure-menu-children{display:none;position:absolute;left:100%;top:0;margin:0;padding:0;z-index:3}.pure-menu-horizontal .pure-menu-children{left:0;top:auto;width:inherit}.pure-menu-active>.pure-menu-children,.pure-menu-allow-hover:hover>.pure-menu-children{display:block;position:absolute}.pure-menu-has-children>.pure-menu-link:after{padding-left:.5em;content:"\25B8";font-size:small}.pure-menu-horizontal .pure-menu-has-children>.pure-menu-link:after{content:"\25BE"}.pure-menu-scrollable{overflow-y:scroll;overflow-x:hidden}.pure-menu-scrollable .pure-menu-list{display:block}.pure-menu-horizontal.pure-menu-scrollable .pure-menu-list{display:inline-block}.pure-menu-horizontal.pure-menu-scrollable{white-space:nowrap;overflow-y:hidden;overflow-x:auto;padding:.5em 0}.pure-menu-horizontal .pure-menu-children .pure-menu-separator,.pure-menu-separator{background-color:#ccc;height:1px;margin:.3em 0}.pure-menu-horizontal .pure-menu-separator{width:1px;height:1.3em;margin:0 .3em}.pure-menu-horizontal .pure-menu-children .pure-menu-separator{display:block;width:auto}.pure-menu-heading{text-transform:uppercase;color:#565d64}.pure-menu-link{color:#777}.pure-menu-children{background-color:#fff}.pure-menu-disabled,.pure-menu-heading,.pure-menu-link{padding:.5em 1em}.pure-menu-disabled{opacity:.5}.pure-menu-disabled .pure-menu-link:hover{background-color:transparent}.pure-menu-active>.pure-menu-link,.pure-menu-link:focus,.pure-menu-link:hover{background-color:#eee}.pure-menu-selected>.pure-menu-link,.pure-menu-selected>.pure-menu-link:visited{color:#000}.pure-table{border-collapse:collapse;border-spacing:0;empty-cells:show;border:1px solid #cbcbcb}.pure-table caption{color:#000;font:italic 85%/1 arial,sans-serif;padding:1em 0;text-align:center}.pure-table td,.pure-table th{border-left:1px solid #cbcbcb;border-width:0 0 0 1px;font-size:inherit;margin:0;overflow:visible;padding:.5em 1em}.pure-table thead{background-color:#e0e0e0;color:#000;text-align:left;vertical-align:bottom}.pure-table td{background-color:transparent}.pure-table-odd td{background-color:#f2f2f2}.pure-table-striped tr:nth-child(2n-1) td{background-color:#f2f2f2}.pure-table-bordered td{border-bottom:1px solid #cbcbcb}.pure-table-bordered tbody>tr:last-child>td{border-bottom-width:0}.pure-table-horizontal td,.pure-table-horizontal th{border-width:0 0 1px 0;border-bottom:1px solid #cbcbcb}.pure-table-horizontal tbody>tr:last-child>td{border-bottom-width:0}</style>
  <style type="text/css">body {
margin: 2.5em;
font-size: 16pt;
font-family: sans-serif;
}
p, li{
line-height: 1.65;
}
.centre {
text-align: center;
}
.margins-top {
margin-top: 5em;
}
.margins-bottom {
margin-bottom: 5em;
}
.author{
text-align: center;
font-size: 24pt;
}
#header {
text-align: center;
}
#header h1 {
margin-bottom: 1em;
}
h1 {
text-align: center;
margin-top: 3em;
margin-bottom: 3em;
}
table {
margin-left: auto;
margin-right: auto;
margin-top: 2em;
margin-bottom: 2em;
border-style: solid;
border-color: white;
}
td, th {
padding: 1em;
border: 1px solid;
border-color: white;
}
th {
background-color: #d1dbbc;
}
td {
background-color: #ecf0f1;
}

blockquote {
background: #f9f9f9;
border-left: 10px solid #ccc;
margin: 1.5em 10px;
padding: 0.5em 10px;
quotes: "\201C""\201D""\2018""\2019";
}
blockquote:before {
color: #ccc;
content: open-quote;
font-size: 4em;
line-height: 0.1em;
margin-right: 0.25em;
vertical-align: -0.4em;
}
blockquote p {
display: inline;
}
code {
background: #ECECEC;
color: #D24D27;
padding: 0.1em;
}
img {
display: block;
margin-left: auto;
margin-right: auto;
width: 80%;
}
figcaption, p.caption {
display: block;
margin-left: auto;
margin-right: auto;
text-align: center;
font-style: italic;
}

.container {
padding-right: 15px;
padding-left: 15px;
margin-right: auto;
margin-left: auto;
}
@media (min-width: 768px) {
.container {
width: 750px;
}
}
@media (min-width: 992px) {
.container {
width: 970px;
}
}
@media (min-width: 1200px) {
.container {
width: 1170px;
}
}
@media print {
@page {
size: A4;
@bottom-right {
content: counter(page)
}
}
body {
margin: 2cm;
font-size: 12pt;
}
h1 {
text-align: center;
margin-top: 3em;
margin-bottom: 3em;
font-size: 14pt;
page-break-before: always;
}
h2,h3,h4,h5{
text-align: left;
font-size: 12pt;
}
h2, h3 {
font-weight: bold;
}
h3 {
font-style: italic;
}
}
</style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Understanding and Improving Human Data Relations</h1>
<p class="author">Alex Bowyer</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#chapter-6"><span class="toc-section-number">6</span> Discussion Part 1: An Understanding of Human Data Relations</a>
<ul>
<li><a href="#answering-rq1-what-do-people-want-in-direct-data-relations"><span class="toc-section-number">6.1</span> Answering RQ1: What do people want in <em>direct</em> data relations?</a>
<ul>
<li><a href="#visible"><span class="toc-section-number">6.1.1</span> Visible</a></li>
<li><a href="#understandable"><span class="toc-section-number">6.1.2</span> Understandable</a></li>
<li><a href="#useable"><span class="toc-section-number">6.1.3</span> Useable</a></li>
</ul></li>
<li><a href="#answering-rq2-what-do-people-want-in-indirect-data-relations"><span class="toc-section-number">6.2</span> Answering RQ2: What do people want in <em>indirect</em> data relations?</a>
<ul>
<li><a href="#transparency"><span class="toc-section-number">6.2.1</span> Transparency</a></li>
<li><a href="#individual-oversight"><span class="toc-section-number">6.2.2</span> Individual Oversight</a></li>
<li><a href="#involvement"><span class="toc-section-number">6.2.3</span> Involvement</a></li>
</ul></li>
<li><a href="#achieving-individual-empowerment"><span class="toc-section-number">6.3</span> Achieving Individual Empowerment</a></li>
</ul></li>
<li><a href="#bibliography">Bibliography</a></li>
</ul>
</nav>
<section id="chapter-6" data-number="1">
<h1 data-number="6"><span class="header-section-number">6</span> Discussion Part 1: An Understanding of Human Data Relations</h1>
<p>It will be already evident to the reader that there are significant overlaps and parallels to be drawn across the findings and discursive insights in Case Study One and Two. In this first discussion chapter, I will draw on both Chapter 4 and Chapter 5 to produce a unified summary of findings and insights in terms of the first two research subquestions RQ1 and RQ2. To recap on the research objectives expressed in 3.3, these two RQs are:</p>
<ul>
<li>RQ1: “What is the human experience of personal data, and what do people want from their data?”</li>
<li>RQ2: “What role does data play in people’s service relationships and how could relationships involving data be improved?”</li>
</ul>
<p>The answers to these research questions are best expressed as an understanding of individual <em>wants</em> relating to data. The word ‘want’ is used here in a broader sense than its everyday meaning, referring to the <em>lack</em> of something that would be beneficial (which may or may not be accompanied by conscious desire). By framing our accumulated understandings from the Case Studies in this way, we are exposing both the problem - the things that individuals do not have or cannot do, while also identifying the goals that any imagined solutions or improvements to the status quo would need to address. It logically follows that any solution that better delivers on individual <em>data wants</em> will lead to improved relations between individuals and their data. This is how we can conceptualise “Human Data Relations” as alluded to in the title of this thesis, and indeed this gives us a yardstick against which to understand what “better” means, which will be explored in Chapter 8. <em>“Human Data Relations”</em> is a term that I introduce here to expand upon the established theory of Human Data Interaction <span class="citation" data-cites="mortier2013 mortier2014">(Mortier <em>et al.</em>, <a href="#ref-mortier2013" role="doc-biblioref">2013</a>, <a href="#ref-mortier2014" role="doc-biblioref">2014</a>)</span> in light of the Case Studies’ findings from a more sociotechnical, interpersonal point of view. Humans have two kinds of relationships with data: <em>direct</em> interaction (such as through an interface in an app or website) and <em>indirect</em> interaction (through interacting with services, providers or individual representatives who themselves have access to personal data about the individual). Thus, Human Data Relations is a term that can encompass both the relationship humans have with their data, but also the relationships they have in which data plays an indirect role. In this context, RQ1 and RQ2 map quite cleanly onto these two types of Human Data Relations, and in answering RQ1 we can identify what people want from direct data relations, while RQ2 helps provide an answer as to what people want from indirect data relations.</p>
<section id="answering-rq1-what-do-people-want-in-direct-data-relations" data-number="1.1">
<h2 data-number="6.1"><span class="header-section-number">6.1</span> Answering RQ1: What do people want in <em>direct</em> data relations?</h2>
<p>By comparing and grouping elements of the findings from Case Study One (see 4.3) and from Case Study Two (see 5.4), three distinct data wants are evident when considering <em>direct</em> data relations. All data about them needs to be:</p>
<ol type="1">
<li><em>Visible</em>: People need to have knowledge of data about them and an ability to see it and effectively access it;</li>
<li><em>Understandable</em>: People need to be able to interpret this data to extract meaningful information from it (and about it), including through visualisations and summaries; and</li>
<li><em>Useable</em>: People need to be able to take action upon this data, including exploring it, asking questions of it, using it to serve their own goals, and gaining personal value from it.</li>
</ol>
<p>These wants are detailed in the following sections:</p>
<section id="visible" data-number="1.1.1">
<h3 data-number="6.1.1"><span class="header-section-number">6.1.1</span> Visible</h3>
<p><strong>Data matters to every individual now, in a way that previously it did not.</strong> As described in 2.1.2, the role of data in our everyday lives has changed; data has become a material used by businesses to shape our world. In 2.2.2 and 2.2.4 I outlined how this change has practically manifested itself in people’s lives; where once data was viewed as <em>ours</em> for our personal reference and use, the emergence of complex multi-party data ecosystems has meant that personal data management has become a sociotechnical &amp; societal problem, not a practical individual one. In the past when businesses were more local, more personal and less data-centric, the data that businesses held about us was minimal and much less significant to our lives than the human relationships we had with those businesses. Businesses grew and data began to be considered as a resource to be processed at scale for customer insight and marketing exploitation, and though we didn’t realise it, our need to understand those processes to protect one’s own interests, began to grow. In the past, you didn’t need to become aware of data storage and use, because it had little effect. Now, data has become a substitute for direct communication with the individual being served, as my research in both public sector (<span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> and 4.3.3) and the private sector (5.4.3.3) has shown. In both domains, people do not have awareness, let alone access, to the extent of data that exists about them. In 5.4.4.1 we saw individuals feeling that companies forced them to hand over data in exchange for service access, and then subsequently maintaining power over them through holding that data, using it to make decisions, and denying them access to that data or even be clear about what data is held.</p>
<p><strong>Data sacrifice is now required for many services, putting individuals at risk.</strong> Be it the personal financial, health and lifestyle data collected on an Early Help assessment form when a family signs up for Early Help support (4.1.2), or the contact details, payment information and preferences provided when individuals register with commercial service providers such as insurance providers or streaming media platforms (5.4.4.1), supplying your personal data is required to access services. Consent to hold and use this data is enforced upon signup, through waiver forms or Terms &amp; Conditions agreements. Service providers in both sectors see the acquisition of more personal data as beneficial to their operations, be it support workers wanting to gain more data about families’ lives (4.2.3, 4.2.6), or commercial providers using trackers to gain more insight about users that they can exploit for advertising <span class="citation" data-cites="binns2022">(Binns, <a href="#ref-binns2022" role="doc-biblioref">2022</a>)</span>. In both domains, this sacrifice is seen to have an emotional effect on people, ranging from curiosity to fear and distrust (<span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> and 5.4.4). Such fears are well-founded, with mistreatment through incorrect data known in both settings (4.2.2, 5.4.4.1). While data holders almost certainly do not <em>intend</em> to cause harm, data <em>can</em> be ‘used against you’ (P2’s quote in 5.4.4.1) <span class="citation" data-cites="kroger2021 strohmayer2021">(Kröger, Miceli and Müller, <a href="#ref-kroger2021" role="doc-biblioref">2021</a>; Strohmayer <em>et al.</em>, <a href="#ref-strohmayer2021" role="doc-biblioref">2021</a>)</span>. In providers’ eyes, people are now represented through data. Despite the fact that data is never truly objective <span class="citation" data-cites="gitelman2013 taylor2015">(Gitelman, <a href="#ref-gitelman2013" role="doc-biblioref">2013</a>; Taylor <em>et al.</em>, <a href="#ref-taylor2015" role="doc-biblioref">2015</a>)</span> and a recognition (at least on the public sector side) that a data record can never tell the full story (4.2.6 and <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>), the data record becomes the object to be administered, rather than the individual <span class="citation" data-cites="cornford2013 zuboff2019">(Cornford, Baines and Wilson, <a href="#ref-cornford2013" role="doc-biblioref">2013</a>; Zuboff, <a href="#ref-zuboff2019" role="doc-biblioref">2019</a>)</span>, and this in itself creates risk - through mishandling or inaccuracy. Given the data record is seen as a source of truth (4.1.2, 5.5.3), it is vital that such information remains <em>fair</em>, and <em>accurate</em>; this is especially important in the commercial sector, where people are only just beginning to become aware of data misuses and data exploitations that are actually happening <span class="citation" data-cites="avast2022databrokers chang2018 mcnamee2019 zuckerman2021">(Chang, <a href="#ref-chang2018" role="doc-biblioref">2018</a>; McNamee, <a href="#ref-mcnamee2019" role="doc-biblioref">2019</a>; Zuckerman, <a href="#ref-zuckerman2021" role="doc-biblioref">2021</a>; ‘Data Brokers: Everything You Need to Know’, <a href="#ref-avast2022databrokers" role="doc-biblioref">2022</a>)</span>. Ensuring fairness and accuracy of held data cannot be verified without individuals’ awareness of data held about them.</p>
<p><strong>Once data has been sacrificed, it enters a closed and opaque ecosystem, where the individual loses access and becomes unaware</strong> of that data’s storage and use (Luger and Rodden’s ‘point of severance’ <span class="citation" data-cites="luger2013">(Luger and Rodden, <a href="#ref-luger2013" role="doc-biblioref">2013</a>)</span>). What was previously available for individuals to see becomes inaccessible and invisible. In the Early Help context, this manifested as families having a lack of awareness or direct access to data held about them and having to rely on support workers as gatekeepers to choose to inform or show them aspects of their data (4.1.1,4.5). In the commercial context, the situation is perhaps even worse, as not only is there rarely any kind of data viewing interface, there is not even a gatekeeper who might make people aware of their data and its use; and even if someone becomes motivated to gain awareness, the GDPR leaves them in the dark; in 62% of cases, the data that companies own privacy policies stated they collect, was not returned, and data that was returned was complete in only 22% of cases (5.3.2). In both context, no awareness is gained unless the information is actively sought. This means that the vast majority of people, busy and unaware, remain so. This is problematic because people cannot judge data accuracy or protect themselves from risk, because they may not even be aware of certain data’s existence, or be able to access it even when they are.</p>
<p>Across both contexts, we saw that <strong>people want to see data which is hidden from them</strong>. In the SILVER project (3.4.1.1, 4.2.2), and my prior work with families (<span class="citation" data-cites="bowyer2018b">Bowyer <em>et al.</em> (<a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>), and in Case Study One (4.2.6, 4.3.2, 4.4.2), families wanted to see what data was held about them (“what they’ve got on me”). They wanted to be actively kept informed and to have the ability to see if data was fair and accurate. In the commercial context, the same feelings were found; participants expressed a great desire to see and know what companies are storing about them, especially data collected or inferred about them without their involvement. This is not just a desire, but a need, given that data can have impact on their daily lives as it is used to inform decisions on how content is presented and recommended to them, and what services they are advertised, offered or can access (5.5.3). We also see from Case Study Two that awareness is not just a binary; awareness includes having an appreciation of why the existence and use of certain data is significant and what its implications might be. Article 13.2.f of the GDPR <span class="citation" data-cites="gdpr2018art13">(‘Article 13: Information to be provided where personal data are collected from the data subject’, <a href="#ref-gdpr2018art13" role="doc-biblioref">2020</a>)</span> states that, at least in the case of automated decision-making, people are entitled to meaningful information about the significance of the processing of their data, yet such explanations were not given to participants of Case Study Two.</p>
<p><strong>Effective access to held data is required for visibility</strong>. Having gained awareness of data held and of the significance of it, people want that to be accompanied by meaningful access to the data itself. In Case Study One (4.3.2.1, 4.4.2), we saw families and support workers recognise the need to accommodate the differences in families’ digital literacy, mental and physical handicaps, and technology skills while providing them access to the data held about them. This mirrors Gurstein’s call for ‘effective access for everyone’ <span class="citation" data-cites="gurstein2011">(Gurstein, <a href="#ref-gurstein2011" role="doc-biblioref">2011</a>)</span>, which was detailed in 2.1.4. Four aspects in particular are relevant here: the content and formatting of the data (which should support different levels of linguistic and computer literacy), the capabililities made available in terms of software, hardware and Internet access (sufficiently powerful, sufficiently available and affordable), and skills (ensuring that individuals are able to interpret the data). In Case Study Two, we saw several participants feeling that data was delivered in too-technical formats (5.4.3.2), or that they lacked the skill to properly interpret the data (5.4.3.1). Effective access and interpreting data goes beyond visibility of data and includes understandability, which is explored in the next section.</p>
<p><strong>Visibility of and access to data must be timely, and ongoing</strong>. Given the ever-changing nature of data (and indeed of the lives of the people it represents), occasional or one-off access is not sufficient. In Human-Data Interaction theory, this concept is described as having <em>negotiability</em> <span class="citation" data-cites="mortier2013 mortier2014">(Mortier <em>et al.</em>, <a href="#ref-mortier2013" role="doc-biblioref">2013</a>, <a href="#ref-mortier2014" role="doc-biblioref">2014</a>)</span>: the ability to re-evaluate data and associated decisions as contexts change externally. It is also mentioned by Gurstein, who points out that time-limited access to data would not be effective <span class="citation" data-cites="gurstein2011">(Gurstein, <a href="#ref-gurstein2011" role="doc-biblioref">2011</a>)</span>. In the Early Help context, families wanted access to their data outside of support meetings; this implies some sort of self-service interfaces being available, that you can use in your own time rather than being reliant on the support worker as gatekeeper. People wanted to see all data about them directly, through a personal interface, as reflected in their workshop designs (4.3.2.3). This echoed findings of my earlier work with families, which had identified a need for continuing rights and visibility of data over time, in order enable vigilance over keeping data accurate and meaningful as life changes (<span class="citation" data-cites="bowyer2018b">Bowyer <em>et al.</em> (<a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>). Timeliness also implies that access to an up-to-date view of the data does not require special and ongoing effort by the individual, it is always available. Both support workers and supported families saw value in notification feeds about changes to data records (4.3.3.3), so that changes are discovered and can be acted upon without having to wait for the next support meeting. In the commercial context we can see that GDPR provides a form of access that is not at all timely. The 30 day delay on request processing guarantees that data will be out of date by the time it is viewed, and individuals must repeatedly make GDPR requests to maintain an up-to-date view (and in doing so, they the imposition of charges as GDPR states that requests should not be excessive and that fees can be levied for additional copies). This lack of timeliness in the design of GDPR data access motivates my third suggestion to policymakers in 5.5.1, that they should offer ongoing access rather than the one-off delivery of data packages.</p>
<p><strong>For held data to become visible, systemic support is needed, including governance, advocacy and assistance</strong>. Offering access to data is not solvable at a purely technical level. Even a well-built data interface with 24/7 access would not provide the depth and breadth of visibility people want. As observed in Case Study Two, even those companies that provide instant data access portals such as Google and Facebook did not provide participants with all the data they desired, nor all the answers they sought (5.4.2.3), and most companies offered neglible follow-up support after data had been delivered (5.3.3). Further investigations into data access conducted as part of the #digipower investigation (3.4.3.4) confirmed that SAR requests and data portals rarely provide insight into some of the most desired types of data including derived and acquired data and data transfers. Effective access and visibility also requires advocacy <span class="citation" data-cites="gurstein2011">(Gurstein, <a href="#ref-gurstein2011" role="doc-biblioref">2011</a>)</span>: people require support and training to make use of their data. Furthermore, given the insufficient breadth of returned data from companies (5.3.3,5.4.2.2) and near-total lack of access to data on the public sector side (4.3.2.2, 4.3.2.3), it is clear that external governance <span class="citation" data-cites="gurstein2011">(Gurstein, <a href="#ref-gurstein2011" role="doc-biblioref">2011</a>)</span> to ensure effective access is needed. Without the sort of pressure on data-holders that only policymakers can exert, organisations will not be compelled to provide richer responses or better information-access support (5.4.2.2, 5.5.1), and while small improvements can be achieved through individual action, people generally lack the means to effectively demand the increased visibility required (5.5.3). The impact of this lack of governance is most keenly felt in the PDE/MyData space (2.3.4), where emergent actors seek to encourage data-holding organisations to enable greater information access so that they might build better data access tools for individuals, but are hampered by a lack of top-down governance supporting their requests as well as a lack of funding and investment by data-holders in data advocacy.</p>
<p><strong>If data is not visible, this can lead to subjection, alienation and exclusion</strong>. Throughout both Case Studies, we have seen the negative psychological effects of people not being able to see their data. Families in both my earlier work with families <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> and Case Study One were caused significant worries by not being able to see their data. People do not want to be treated like <em>subjects</em> (in either sense of on being subjugated <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> , or a topic being discussed) and reducing people to a set of assertions in data causes them to become, in effect ‘objects to be administed’, which is harmful and disempering (4.2.3, 4.3.4.2, <span class="citation" data-cites="cornford2013">(Cornford, Baines and Wilson, <a href="#ref-cornford2013" role="doc-biblioref">2013</a>)</span>). Supported families felt helpless and resigned to being judged through data and sometimes suspicious of those holding or using that data (4.3.4.1). This led in some cases to withholding of information or distrust of support workers, harming the effectiveness of a relationship that is designed to empower (4.4.1). In that same section (and in <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> Page 7) I outline how ongoing individual access to data has the potential to transform attitudes, remove dependence and a feeling of being a subject, and could empower families to help themselves. Such fears and worries about unseen data were echoed in Case Study Two, with participants exhibiting great unawareness of held data (Table 12, 5.3.3), and concerns over data being held out of their sight for long periods of time (5.4.3.3) as well as similar feelings of resignation or lack of choice (5.4.4.1, 5.6). Denying access to held data was seen as a key source of holding power over individuals (5.4.4.1), and visibility of data is a key part of assessing ‘to what extent the bargain’ (of data sacrifice for value as described above) ‘is fair’ (2.1.4, 5.5.3 and <span class="citation" data-cites="larsson2018">(Larsson, <a href="#ref-larsson2018" role="doc-biblioref">2018</a>)</span>). It is an inherent consequence of representing people through data and then using that data to make decisions (2.1.2, <span class="citation" data-cites="cornford2013 bowyer2018b">(Cornford, Baines and Wilson, <a href="#ref-cornford2013" role="doc-biblioref">2013</a>; Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>) that individuals become sidelined and excluded (2.3.3 and <span class="citation" data-cites="crabtree2016">(Crabtree and Mortier, <a href="#ref-crabtree2016" role="doc-biblioref">2016</a>)</span>). Without visibility of data, consent is not meaningful, and individual needs are more easily ignored or overlooked.</p>
</section>
<section id="understandable" data-number="1.1.2">
<h3 data-number="6.1.2"><span class="header-section-number">6.1.2</span> Understandable</h3>
<p><strong>Visibility and access to see data is not enough, people need to be able to interpret it</strong>. Data is only valuable in so much as it enables us to access the information which it encodes (2.1.1). People need to be able to make sense of it. When humans look at data, we inevitably attempt to interpret it to see what it can tell them; in Early Help, support workers try to learn more about people’s lives by examining data about them (4.2.3, 4.3.3.1). In doing so they apply their own knowledge and expectations in an attempt to extract facts. Similarly in the context of everyday digital life data, individuals search for value and meaning in that data, they reflect upon it and try to relate it to their own lives (5.4.3.1). While Early Help staff receive training on how to understand families’ data, individuals struggle to understand their data without sufficient support, as discussed above. Returned data from GDPR requests is often dry and technical. It may contain codes, internal notations or abbreviations that a layperson cannot understand (5.4.3.1). Raw data is rarely sufficient to provide clear, unambiguous and unbiased information to the reader <span class="citation" data-cites="gitelman2013 neff2013">(Gitelman, <a href="#ref-gitelman2013" role="doc-biblioref">2013</a>; Neff, <a href="#ref-neff2013" role="doc-biblioref">2013</a>)</span>. In line with one of the three core principles of HDI, <em>legibility</em>, data should be understandable by those it concerns <span class="citation" data-cites="mortier2014">(Mortier <em>et al.</em>, <a href="#ref-mortier2014" role="doc-biblioref">2014</a>)</span>. In both Case Studies (and my prior work), individuals shared a desire to not just be aware of, but to <strong>understand</strong> what data was held about them and how it was used (<span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>, 4.3.2.4, 5.4.2.1). People are only just beginning to understand the significance of a data-centric world that uses data to make decisions that affect their lives (2.1.2, 2.1.4, 5.5.3).</p>
<p><strong>People need understandable summaries of information content and context.</strong> It was very clear from the findings of both Case Studies that all humans looking at data need <em>summaries</em> to help them digest and locate key information. In Case Study Two participants were often overwhelmed or “<em>drowning&quot;</em> (P1) at the volume or technical complexity of the data returned from access requests, <em>&quot;so much of it that’s impossible to know what it all means&quot;</em> (P4) (5.4.3.1). These feelings were mirrored in Case Study One, by support workers who feared the liability of having to <em>&quot;trawl through&quot;</em> large volumes of data and know all the relevant and important facts about a family so that they do not make mistakes (4.3.2.1). Participants on both sides talked of needing help to see the whole picture, something that is hard to achieve from individual datapoints or sets of files. In both cases, summaries of data would help comprehension. However, the task of creating a summary is not straightforward and places power in the hands of the summary-maker, who can decide what is relevant, how the data is framed and what is omitted from the summary. People look at information for different reasons, to answer different questions, so the question of who decides what is relevant or most important within a body of data is a critical one. Different summaries would be needed for different audiences. As Mortier reminds us, effective legibility requires a recognition that individuals’ viewpoints of data can and should differ <span class="citation" data-cites="mortier2014">(Mortier <em>et al.</em>, <a href="#ref-mortier2014" role="doc-biblioref">2014</a>)</span>. There is a question about who decides what the viewer of a summary ‘needs to know’ (4.3.3.1, 4.3.4.3). This is further complicated by the fact that the data itself is not neutral <span class="citation" data-cites="gitelman2013">(Gitelman, <a href="#ref-gitelman2013" role="doc-biblioref">2013</a>)</span>; in the Early Help context it was clear that opinions as well as facts are recorded (<span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>, p. p6)</span> and from SILVER project), and a focus on the recording of data most helpful to the support worker. Commercial data holders record data in ways that are optimised for their existing systems and processes, as seen through the presence of internal codes, system screenshots and filenames in returned data (5.4.3.2). In Case Study Two most participants’ comments on returned data indicated that it had not been not presented in a way optimised for understanding (5.4.3.1), failing to support <em>sensemaking</em>;”Information presentation should be as clear as possible so that people can interpret their data and extract meaningful information from it.&quot; <span class="citation" data-cites="gurstein2011">(Gurstein, <a href="#ref-gurstein2011" role="doc-biblioref">2011</a>)</span></p>
<p><strong>Rather than raw data, people need information and visualisations, arranged and optimised for understanding.</strong> Data, by itself, is not meaningful. In order to be able to answer questions and acquire knowledge, people need information (2.1.1). Access to raw data files or database records or spreadsheets does not satisfy this, and prior research in the civic data context states that this would be inadequate and limiting <span class="citation" data-cites="cornford2013">(Cornford, Baines and Wilson, <a href="#ref-cornford2013" role="doc-biblioref">2013</a>)</span>. To comprehend the meaning of data, visualisations and explanations can help (4.4.2); as one support worker in Case Study One observed, some families might find data tables too technical, <em>“I think sometimes it’s easier to do it in pictures”</em> (4.3.2.1). Participant-designed interfaces in Case Study One included pie charts, graphs, spider diagrams and timelines, all designed to convey information more intuitively (4.3.2.1). In Case Study Two and prior GDPR requests, it was often the case that companies often returned data not in understandable forms that were less useful than the apps or websites those service providers offer. For example, run tracking apps such as Nike+ and Strava return route log information in XML-based TCX files which are meaningless without some analysis tool or visualisation. JSON files, a commonly returned data format, often use a timestamp format that is just a long number, not understandable by humans without extra work. Data was often returned in formats that were more a reflection of internal systems (e.g. screenshots, table dumps or exports) than being optimised for understanding (5.4.3.1), which some participants found useless. As P5 observed, <em>“It’s like being given the bricks to a house… It doesn’t really mean anything when it’s just bricks, if you don’t know how to put it together”</em> (5.4.3.2). It is clear that visualisations are key to accelerating understanding (and are also subject to the same challenges of selection and bias as summaries). Furthermore, visualisations of data can functional as powerful boundary objects and “things to think with” (<span class="citation" data-cites="bowyer2018b brandt2004">(Brandt and Messeter, <a href="#ref-brandt2004" role="doc-biblioref">2004</a>; Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> and 3.5.2, 4.4.2) and in the care context the use of data representations as a focal point or evidence for was thought to be more productive and empowering (4.3.2.2, 4.4.1).</p>
<p><strong>Information becomes most meaningful when it is recognisable and relatable and can be mapped back to life experiences.</strong> Across both case studies, there was a clear search for meaning in data, which manifested as a desire to use that data to build a fuller picture of the individual (or family)‘s life. In Case Study One and in SILVER, it was evident that support workers seek a broader view into supported families’ lives by reviewing data about them (4.3.2, 4.3.3.1). Both supported families and staff saw value in seeing all the data about each individual in a common place - in other words, structuring the information around the individual’s life, rather than the information silos of different agencies (4.3.2.3). In Case Study Two, where participants were asked about the value they saw in the data companies held about them (5.3.3), it was clear that data was most valuable to participants when it was recognisable and relatable to events in their lives. This is particularly important for data that participants have never seen before such as derived, acquired or metadata - without a way to connect it to one’s own life, it is impossible to relate to (5.3.3). Echoing goals surfaces in personal informatics literature <span class="citation" data-cites="li2010">(Li, Dey and Forlizzi, <a href="#ref-li2010" role="doc-biblioref">2010</a>)</span>, participants sought insights about themselves in data, and so valued data that spanned a longer time period such that they might use it to spot patterns in relation to events in their lives (5.4.3.1). They valued the opportunity to use data as <em>“a window into the past”</em> (P11, 5.4.3.1). Long term data was seen as a liability (5.4.3.3), and when it came to considering attitudes to providers, participants were most concerned about data collection by the larger data companies like Google and Facebook who, through their myriad apps, websites, devices and other means, had many touchpoints into their lives and thus had a broader picture of their life activity (5.4.3.3. 5.4.4.2). It is clear that to transform dry, technical data into meaningful information, it should be contextualised in relation to events in the life of the individual it describes.</p>
<p><strong>In practice, ongoing human support is needed to facilitate the understanding of data.</strong> In both case studies, participants felt that they had questions to ask of data holders, especially when the data was difficult to understand but also more generally when the answer to a given question could not be found in the data. In my earlier work <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> and in Case Study One, participants emphasised the ability to talk to someone about their data (4.3.2.4), and included such features in their designs - both to understand and receive help in understanding, but also to feedback and provide additional information, explanation or context so that they might be better understood (4.3.3.4). In some cases families needed additional support for reasons of accessibility or technical literacy. Human communication channels for data support need to be available at convenient times too; in Case Study One individuals felt constrained by needing to wait until their next meeting with a support worker, and wanted a communication channel they could use in their own time. In Case Study Two, participants were regularly frustrated by data they could not fully understand and could not ask about: sometimes literally, when internal codes were not explained or technical formats were used, and sometimes when they could not understand how the information had been derived, such as insurer’s driving scores (5.4.3.1) or Instagram’s inferred interests. The general pattern of GDPR handling by organisations was to deliver data, often handled by a back-end team with no customer face or means to ask follow-up questions. Where questions were asked they were typically hindered by delays and middlemen preventing an effective conversation (5.3.3). Considering the systemic changes toward data-centricity that the world has undergone, as described in 2.1.2 and 2.2.4, it is no surprise that human support has reduced. Across both studies we see the cost of that shift toward dealing with data instead of dealing with people; individuals get left behind, without the means to understand or ask about their data.</p>
<p><strong>If data is not understandable, distrust can arise.</strong> In both Case Studies, the costs of individuals not being able to understand their data and being left in an unsatisfactory position of being unable to resolve concerns or ask questions is evident: Without understanding, comes distrust. In Case Study One, participants were concerned when they saw assertions on their records that they disputed or could not identify the source of. In Case Study Two, privacy policies that were too vague in their explanations of data (such as Google’s) caused participant distrust because they seemed broad and lacked tangible examples, and large volumes of technical data caused suspicion. It is clear that understandable information about what is represented in data, and about the context and use of that data, can help individuals to trust the data holder. In the minority of cases in Case Study Two where the GDPR had a positive impact, the reasons given included understandable data and helpful human responses, for example P10 cited Niantic’s detailed data and positive attitude, while P6 described Sunderland AFC as upfront, and said that their data <em>‘just made sense’</em>. P7 specifically distrusted LinkedIn because she felt they had not bothered to adequately engage with her (5.4.4.3). The importance of trust will be discussed in more detail in 6.2.1 below.</p>
</section>
<section id="useable" data-number="1.1.3">
<h3 data-number="6.1.3"><span class="header-section-number">6.1.3</span> Useable</h3>
<p><strong>People need to be able to explore and interrogate data to ask questions of it.</strong> In both case studies, many participants showed they are aware that their personal data contains insights and value they cannot access. In Case Study One and <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> this manifested as concern over what unseen incriminating judgements might be storied in their records, and an awareness that the only data supported families can actually see is whatever subset of data their support worker chooses to share with them (4.3.4.1). In Case Study Two, this manifested as feelings of not having the technical skills necessary to explore their returned data (5.6) and that without better tools individuals were not getting the same view of data that service provider staff have (P2, 5.4.3.1). What we can see from these observations is that even visible, understandable data is not enough to meet people’s needs. People need to be able to interact with their data, in order to explore it, gain insights or answer questions. There is a need for tools not only to access data, but to help people make sense of (often technically formatted) data (5.4.3.1), and explore it in different ways to answer questions - which implies the need for operations such as filtering, searching, comparing and orienteering (see 2.1.4 for others), in order to understand history, context and patterns in the data, as suggested in self informatics (SI) literature (2.2.3). Several participants in Case Study Two hoped to receive data in formats they could visualise, “mashup” and play with, but did not get this - not only was data not optimally formatted for such use, it lacked sufficient explanation to enable individuals to pursue such goals for themselves (5.4.3.2).</p>
<p><strong>Data needs to be useable - correctly formatted and explained in a portable and standardised form.</strong> As discussed in 5.6 and 5.4.3.2, people have multiple needs around data: For understanding, people need <em>understandable information</em>, both the facts and assertions encoded within the data, but also information about the data itself - its context, history, use, and significance. But there is a distinct need for <em>usable data</em>, which is somewhat orthogonal to this. A PDF containing a screenshot from an internal system might potentially be sufficient for understanding, but is useless for exploration or visualisation-building. Similarly a technical log file might contain rich data that can be queried and visualised given the right tools, but without those tools or an informational summary, is of no immediate value (5.4.3.2). This dilemma was alluded to by P4 in Case Study Two thus: <em>“If you want to view the data they have about you, it’s quite usable. If you want to do something [analytical], then it’s not”</em> (5.4.3.2). This dichotomy of needs is discussed in 5.5.1, where the introduction of standard formats is proposed as a means to catalyse the building of data insight interfaces. As P1 stated, <em>“it would be nice if these companies had a standardised model of how this information is presented to people”</em> (5.4.3.1).</p>
<p><strong>People need to be able to interact with data, which means interfaces are needed</strong> By themselves, even standardised files as described above are not practically usable. As discussed in 4.4.2 and consistent with effective access <span class="citation" data-cites="gurstein2011">(Gurstein, <a href="#ref-gurstein2011" role="doc-biblioref">2011</a>)</span> participant data designs in Case Study Two remind us that simply providing data is not sufficient: to be meaningfully able to act upon data requires some form of interface not only for visualisation and interrogation as mentioned above, but also so that any physical, cognitive or accessibility needs can be met. In Case Study Two, some participants wanted not just for data access, but for tools to help them find insights from their data (5.5.3, 5.6). While several companies are starting to create interfaces for data access, most of these are still focussed upon file delivery, with the notable exception of Google Timeline and Google My Activity, which provide a glimpse how an interface to explore data could be more useful than providing a bundle of files. Both of these examples also re-iterate the value of unifying data around an individual’s life, as discussed in 4.3.2.3 and above in 6.1.2 above.</p>
<p><strong>Data needs to be explorable from a temporal perspective</strong> Another aspect of usable data that goes beyond what a data file can offer is the ability to view it over time. The importance of this temporal capability, as identified in literature cited in 2.1.4 (practical information access) and 2.2.2 (temporal PIM systems), and my prior writing <span class="citation" data-cites="bowyer2011">(Bowyer, <a href="#ref-bowyer2011" role="doc-biblioref">2011</a>)</span>, was evident in both Case Studies. In SILVER and in Case Study One, being able to access historical data for a full picture regularly surfaced as a desire in discussions - even though the exact bounds and mechanisms for achieving this were contentious (4.2.6, 4.3.2.1, 4.3.3.1). In Case Study Two, as Table 12 shows, 26% of participant goals related to SI-type reflection (2.2.3) on one’s past to enable self-insights, nostalgia and creative uses of data. No participant was able to achieve this, and this was in large part due to the lack of temporal data exploration capability, meaning that significant potential value (the value of a long-term dataset as described above) remained locked away and inaccessible (5.3, 5.6). Case Study Two also suggested a lack of thought to this temporal perspective from data holders, who delivered data as a one-off snapshot that was already out-of-date when delivered. Indeed the GDPR explicitly discourages excessive data requests, rendering an ongoing view of data as proposed in 5.5.1 near impossible. Having better temporal data exploration capabilities would enable people to understand themselves and their data ecosystems better, informing both personal self-improvement goals and better decisions about personal data practices and provider choices (5.6). Other exploration perspectives that could be powerful include location-based views or person/company/relationship-based views.</p>
<p><strong>If holders do not make data unusable, this is a barrier to individual agency and power.</strong> In Human-Data Interaction terms, people need not just legibility, but <em>agency</em> - the ability to act upon one’s data <span class="citation" data-cites="mortier2014">(Mortier <em>et al.</em>, <a href="#ref-mortier2014" role="doc-biblioref">2014</a>)</span>. Personal data contains valuable and actionable information about individuals and their lives (5.5.3). The SI field has identified that there are already many practical barriers to working with one’s personal data effectively, including not just access but challenges in integration, sensemaking and goal-tracking – the ‘barriers cascade’ <span class="citation" data-cites="li2010">(Li, Dey and Forlizzi, <a href="#ref-li2010" role="doc-biblioref">2010</a>)</span> – which hinder the ability to use one’s data for personal benefit. As observed in Case Study Two, an inability to access the value in your own data can lead to feelings of resignation, concern, suspicion or distrust (5.6). Even if one can see and understand one’s data, an inability to act upon it can reinforce feelings of being passive and uninvolved; without this, any opportunity to feel engaged and motivated is lost <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>, p. p8)</span>. Being able to use data for one’s own purposes is a critical ingredient of empowerment and rebalancing power <span class="citation" data-cites="wef2014lens">(Hoffman, <a href="#ref-wef2014lens" role="doc-biblioref">2014</a><a href="#ref-wef2014lens" role="doc-biblioref">a</a>)</span>. Without data usability, individuals are in effect digitally impaired, leading a less functional society where innovation and growth is limited <span class="citation" data-cites="abiteboul2015">(Abiteboul, André and Kaplan, <a href="#ref-abiteboul2015" role="doc-biblioref">2015</a>, p. 2.1.4)</span>.</p>
</section>
</section>
<section id="answering-rq2-what-do-people-want-in-indirect-data-relations" data-number="1.2">
<h2 data-number="6.2"><span class="header-section-number">6.2</span> Answering RQ2: What do people want in <em>indirect</em> data relations?</h2>
<p>By comparing and grouping elements of the findings from Case Study One (see 4.3) and from Case Study Two (see 5.4), especially in the context of individual relationships with care providers and digital service providers respectively, three distinct data wants are evident when considering <em>indirect</em> data relations:</p>
<ol type="1">
<li><em>Transparency</em>: People need to know what data is being collected or held, and critically how it is being used, for accountability and safety and in order to have trust in data holders;</li>
<li><em>Individual Oversight</em>: People need the ability to affect what data is held and how it is used, including reacting to changing circumstances, deleting data or withdrawing consent for certain uses; and</li>
<li><em>Involvement</em>: People need to be invited and involved in decision-making based upon their data, so that they are not misrepresented and their needs are not overlooked. This can be aided by collaborative use of data, giving individuals a human point of contact, and consulting the person not just the record.</li>
</ol>
<p>These wants are detailed in the following sections:</p>
<section id="transparency" data-number="1.2.1">
<h3 data-number="6.2.1"><span class="header-section-number">6.2.1</span> Transparency</h3>
<p><strong>People need a window into how their data is used; this means transparency of processes not just of data</strong>. It is well established that there is currently extensive use of personal data by service providers and other parties that is beyond an individual’s view <span class="citation" data-cites="wef2011">(Hoffman, <a href="#ref-wef2011" role="doc-biblioref">2011</a>)</span>, forming an ecosystem of data use based upon one’s data, which is currently not centred on or visible to the individual concerned (2.3.4). Decisions made based upon personal data directly affect people’s lives through policy decisions (in the care context) or business/functionality decisions (in the commercial context). People need to understand the value created by the use of their data and how (if at all) they are compensated for this <span class="citation" data-cites="wef2011">(Hoffman, <a href="#ref-wef2011" role="doc-biblioref">2011</a>)</span>. Even with full data access, understanding and useability, individuals cannot see into this opaque world of data use; the data is just an artifact produced and shaped by unseen processes. Like an archaelogist trying to infer the customs of lost civilisations through ancient relics, observation of the data can only reveal so much. Andrew Cormack, writing before GDPR, observed that <em>“it is more important to know how information is processed than the actual values involved”</em> <span class="citation" data-cites="cormack2016">(Cormack, <a href="#ref-cormack2016" role="doc-biblioref">2016</a>)</span>. The SILVER project found that families had very little awareness or understanding how how their data was used, and that consent was therefore not meaningful because consent had been given without processual understanding [4.2.2]. In Case Study One participants agreed that people need rights to see how their data is used (4.2.6). Case Study Two revealed a clear desire for awareness of how data is used, how decisions are made, and how this might affect them (5.4.2.1), with over 74% of goals in pursuing GDPR requests relating to wanting greater insight into personal data use practices (5.3.2). 70% of participants wanted to understand what providers infer from their data and this was unmet in 73% of cases and fully met in only 7% of cases (5.3.2).</p>
<p><strong>Process transparency is required to enable accountability.</strong> In Case Study Two, participants recognised that organisations had collected data about them which could be exploited, and wanted to understand the extent of that capability (5.4.3.3). Data access can provide a window into collection capability, but only process transparency can reveal the extent of data use capability. Many participants expressed a desire to assess the trustworthiness of their service providers; they had curiosity, suspicion and unanswered questions that only transparency could address (5.3.2) and sought to judge whether data use practices were “appropriate” (5.2.4.1). In the Early Help context, all data processing is hidden from individual view and no access or questioning capability except through their support worker (functioning as a selective gatekeeper) (4.1.1, 4.2.1, 4.4.1). Returning to Case Study Two, there was evidently some transparency available in the form of the ability to make a GDPR request, but many participants found GDPR responses inadequate for holding providers accountable (5.2.4.3). Nonetheless, data access request handling is itself a data process, and so in this sense, the GDPR process did offer some ability to judge the trustworthiness and integrity of providers in data handling, in part informed by the breadth and quality of data returns (Table 11) but perhaps moreso by the experience of the GDPR process. Many participants formed or revise their perceptions of companies, with perceptions of providers having a lack of care and making access difficult, or of providers being helpful and open having a strong impact on participants’ attitudes toward them (5.4.4.3).</p>
<p><strong>There is no accountability, processes are not transparent, and thus power remains imbalanced.</strong> Across both case studies, the lack of process transparency is clear. Early Help services have no obligation to describe or share their data use practices with supported families, and apparently only even attempt to do so at the point of initial onboarding and consent collection (<span class="citation" data-cites="bowyer2018b">Bowyer <em>et al.</em> (<a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>, 4.2). This equates in practice to a complete lack of accountability over data practice (4.4.1, 4.5) Meanwhile in the commercial context, some companies failed to respond at all to GDPR, which is a barrier to accountability service providers. Many routinely failed to adequately meet the transparency rights stated by GDPR, without repercussion or consequence (5.4.2.2). In both sectors, data holders’ freedom to collect and use data without adequate transparency or ability to be held to account can be seen as an exertion of power over individuals. The power imbalance (<span class="citation" data-cites="wef2011">Hoffman (<a href="#ref-wef2011" role="doc-biblioref">2011</a>)</span>, <span class="citation" data-cites="wef2014lens">Hoffman (<a href="#ref-wef2014lens" role="doc-biblioref">2014</a><a href="#ref-wef2014lens" role="doc-biblioref">a</a>)</span>) and the dominance of data holders over the individuals about whom data is held, is reinforced by a lack of transparency.</p>
<p><strong>People need transparency not only for accountability, but to level the playing field in accessing value locked within data.</strong> People need to see the complete picture of their data and its use, not only for accountability, but in order that they might access at least as much value and insight from it as data holders do (5.4.3.1). For self improvement and improving one’s situation (a key goal of Early Help), access to metrics visible in data are extremely important, so that one might measure progress (4.3.2.4). While support workers do endeavour to provide this, this can never be as empowering as having full transparency over that data. In commercial service provider relationships, data interfaces present data in ways that are configured to reflect the profit motives of the organisation (explored further in my work with Goffe <em>et. al.</em> <span class="citation" data-cites="goffe2021">(Goffe <em>et al.</em>, <a href="#ref-goffe2021" role="doc-biblioref">2021</a>)</span>), and so accessing a relevant view of one’s own data and having the means to access the knowledge within it is similarly difficult. Participants in Case Study Two wanted visualisations that would allow them to discover patterns and insights, and tools to explore their data (5.4.3.1, 5.5.3). With transparency, individuals can learn about the valuable knowledge that data holders are currently extracting from their data, and hopefully how to access that knowledge for themselves.</p>
<p><strong>People face an incomplete picture of their data ecosystem, even after using all available means to achieve transparency.</strong> In SILVER and my prior work in the Early Help context, supported families expressed concern that data could not adequately represent the complexity of their lives (<span class="citation" data-cites="bowyer2018b">Bowyer <em>et al.</em> (<a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>), a view supported by literature (<span class="citation" data-cites="cornford2013">Cornford, Baines and Wilson (<a href="#ref-cornford2013" role="doc-biblioref">2013</a>)</span>; <span class="citation" data-cites="gitelman2013">Gitelman (<a href="#ref-gitelman2013" role="doc-biblioref">2013</a>)</span>) and sustained by support workers &amp; staff in Case Study One (4.2.6, 4.3.3.1). Therefore, transparency is vital in order to ensure data is fair and accurate to them, yet it is not available (4.3.4.1) so they have no means to ensure this. Similarly in Case Study Two, the most popular GDPR goals around understanding inferences made from data about people (5.3.3) remained unmet. Data was incomplete, delayed, or inaccessible (5.3.2) and the potentially most informative type of data when it comes to understanding processing – metadata, derived and acquired data – were typically absent. Apparently broad responses were discovered to be very limited when viewed through the lens of privacy policy commitments and GDPR transparency rights (5.3.4).</p>
<p><strong>Trust in data holders is needed, and gaps in transparency create distrust and a risk of broken expectations, harming relations.</strong> Individuals need a functional understanding of their data and its handling, and this is crucial to trust. Good explanations (as were often found lacking in Case Study Two (5.4.3.2)) can deliver some of this needed understanding and subsequently increase trust <span class="citation" data-cites="glavic2021">(Glavic <em>et al.</em>, <a href="#ref-glavic2021" role="doc-biblioref">2021</a>)</span>, as observed in a minority of cases (14%) where a good GDPR response led to the participant’s trust in their provider increasing. Conversely we found that incomplete data (or a general lack of transparency/difficulties of access (5.4.4, 5.6)) can harm trust, as in the majority of cases (52%) can harm trust (5.3.4), leading to thoughts such as ‘what are they hiding?’ (5.4.4.3). Privacy policies that contradicted expectations or lacked sufficient explanations also led to distrust (5.3.4). Trust in the independence and integrity of data holders is essential <span class="citation" data-cites="vandijck2014">(Dijck, <a href="#ref-vandijck2014" role="doc-biblioref">2014</a>)</span>, and this was often a concern in the Early Help context, where trust between support worker and supported family is especially critical in order for the support relationship to be effective. Earlier work found that families wanted to be confident that their data would be handled sensitively and fairly only by those with a need to know, and believed that greater visibility of data processing would allow them to trust that that was the case (4.2.2 and <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>). When families felt alienated from their data, trust was absent (4.4.1), and a lack of transparency and accountability makes it hard for families to maintain trust in the system (4.5). These issues of transparency and trust are inherent in a data-centric operating model, and the World Economic Forum have summarised this problem thus:</p>
<blockquote>
<p><em>“A crisis of trust is developing, stemming from the use of personal data in ways that are inconsistent with individuals’ preferences or expectations.”</em> <span class="citation" data-cites="wef2014context">(Hoffman, <a href="#ref-wef2014context" role="doc-biblioref">2014</a><a href="#ref-wef2014context" role="doc-biblioref">b</a>)</span></p>
</blockquote>
<p><strong>Information facilitates trust; transparency therefore offers an opportunity to earn trust &amp; improve relations.</strong> In both studies, the findings led us to conclude that increased transparency from data holders / service providers would improve trust; in Case Study One we concluded that support workers and organisations should be as open as possible about data handling and sharing (4.3.4.3), while in Case Study Two we highlighted the potential benefits of increased consumer loyalty that greater transparency might bring (5.5.2), as well as the need for policymakers to legislate in favour of increasing individuals’ understanding of data practices (5.5.1). In doing so, we are recommending a level of transparency that goes beyond current GDPR practice, and even beyond current GDPR policy; in order to redistribute power, GDPR needs to deliver meaningful transparency, not just the <em>“box ticking”</em> delivery of unhelpful files that our participants sometimes observed (5.5.1). Crabtree describes meaningful transparency by saying that it cannot be a <em>“one-way street”</em> that reduces individuals to <em>“being spectators”</em> on how their data is used; he says that it involves <em>“making the whole ecosystem transparent, not just the front end”</em> <span class="citation" data-cites="crabtree2016">(Crabtree and Mortier, <a href="#ref-crabtree2016" role="doc-biblioref">2016</a>)</span>. Access to good information about practices is the most effective way to earn trust (5.4.4.2), and both studies’ findings suggest that a proactive attitude can do just that. (4.4.1, 4.3.4.2, 5.5.2, 5.6).</p>
<p><strong>Initially, transparency may cause distrust, but only where practice is problematic; this is accountability becoming real and catalysing better data practices.</strong> It is important to note that in Case Study Two we saw the transparency of GDPR cause elevated distrust (5.3.4), however this does not mean it should be avoided. The reasons cited for distrust arising were invariably due to the discovery of practices that participants did not approve of. This is a clear illustration of the link between transparency and accountability; the transparency reveals the non-consensual or unsatisfactory practices that providers must change if they wish to maintain trust and loyalty, such as unclear data practices, data over-use or data sharing that the individual would not have consented to had they been asked. This shows that in some cases trust is fragile, where unfavourable practices are hidden and only the individual’s unawareness is keeping the relationship intact (5.4.4). Data holders should not only be transparent, but should follow this up by acting upon subsequent feedback, improving practices that individuals discover and challenge (5.4.4.3). By shining a light, accountability becomes real and change for the better can occur. Ultimately, increasing transparency can help providers uncover exactly what they need to do to earn greater trust (5.6).</p>
<p><strong>Transparency of data and processes enables individual action and facilitates the levelling of power balance.</strong> Across the two studies, a clear pattern emerges: transparency can increase trust, enable accountability, empower individuals, and (provided organisations respond favourably) actually tilt the power balance back toward an equitable and fair relationship where data is collected and used in clear sight of the individuals it concerns, where they might hold those organisations to account and immediately challenge any unsatisfactory practice, unauthorised processing/sharing or inaccurate data. Thanks to GDPR, individuals are now able to take direct action to educate themselves and pursue greater transparency, and utilise their rights to motivate incremental changes from data holders (5.5.3). Without transparency, data holders will continue to hold the balance of power, and individuals will lack agency and accountability.</p>
</section>
<section id="individual-oversight" data-number="1.2.2">
<h3 data-number="6.2.2"><span class="header-section-number">6.2.2</span> Individual Oversight</h3>
<p><strong>Data visibility and process transparency naturally leads to a desire for individual oversight.</strong> If you see something that is ‘not right’, you are motivated to want to fix it. And therefore, people want something more than data and process transparency, the natural next step is the ability to make decisions about what happens to their data. Participants’ goals in Case Study Two included curiosity, suspicion and a desire to shed light on specific incidents (5.3.3), mirroring the desires families in <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> exhibited to be able to know and see what data was held and used about them. In both cases, individuals wanted to have a say over what happens. Current models of informed consent have been found to be inadequate, with the initial handover of data acting as a <em>‘point of severance’</em> <span class="citation" data-cites="luger2013">(Luger and Rodden, <a href="#ref-luger2013" role="doc-biblioref">2013</a>)</span>. This was echoed in the experiences of families in the Early Help context, who gave consent at the point of initial onboarding, but lost all ability to influence what happens to their data thereafter [<span class="citation" data-cites="bowyer2018b">Bowyer <em>et al.</em> (<a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>; 4.2.2]. GDPR aims to adhere more to a <em>dynamic consent</em> model <span class="citation" data-cites="kaye2015 williams2015">(Kaye <em>et al.</em>, <a href="#ref-kaye2015" role="doc-biblioref">2015</a>; Williams <em>et al.</em>, <a href="#ref-williams2015" role="doc-biblioref">2015</a>)</span> by giving people an ongoing set of rights, including the right to be informed about the use of your data, the right to object to certain data uses, and the right to get your data corrected or deleted <span class="citation" data-cites="ico2018">(Information Commissioner’s Office, <a href="#ref-ico2018" role="doc-biblioref">2018</a>)</span>. In line with the <em>accountability principle</em> [ADD REF TO EU ACCOUNTABILITY PRINCIPLE Article 29 Data Protection Working Party (2010) Opinion 3/2010 on the Principle of Accountability, 00062/10/EN WP 173. AND Article 29 Data Protection Working Party (2014) Opinion 8/2014 on Recent Developments on the Internet of Things, 14/EN WP233], this in effect would allow people to act as overseers or regulators over their own data: watching how it is used, and demanding action or change to practice when they see data use that goes against their wishes.</p>
<p><strong>People need agency and negotiability over held data about them, in order to ensure fairness and accuracy and reduce risk.</strong> As my earlier work in the Early Help context <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> showed, there is a strong desire to ensure data is <em>fair</em> and <em>accurate</em>, because that data is used to inform judgements and make decisions that can directly affect the individuals concerned. Data in Case Study Two showed a clear problem with the accuracy of unseen data: while in 92% of cases volunteered data (which by definition, has been seen by the individual) was found accurate, derived and acquired data (previously unseen by the individual) was found inaccurate in 50% and 80% of cases respectively (5.3.2). Being able to ensure fair and accurate data goes beyond being able to see and understand the data, but requires also <em>agency</em> (the ability to act within a data system, such as to delete or correct data, or withdraw consent) and <em>negotiability</em> (the ability to continue to have a voice and make changes as circumstances change) <span class="citation" data-cites="mortier2014">(Mortier <em>et al.</em>, <a href="#ref-mortier2014" role="doc-biblioref">2014</a>)</span>. People need a relationship with their data (2.1.5). In both Case Studies and in earlier work, individuals perceived tangible risks both of data being held beyond their reach, but also of potentially inaccurate data being used to make decisions. Risk factors identified in the Early Help context included facilitating or encouraging crime, causing social and psychological harm, and enabling medical mismanagement or welfare support failures <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>. In Case Study Two, participants felt that held data about them that is not visible or controllable was a liability that might lead to privacy violations, commercial exploitation, and an increased risk of data leaks (5.4.3.3). Clearly people feel that for their data to be safe, they must be able to see and verify its storage and use for themselves and enforce action when something is not right. As early as 1980, when the world was less data-centric, it was already recognised that individuals would need the ability to challenge data use, as the OECD observed in their guidelines:</p>
<blockquote>
<p><em>“The right of individuals to access and challenge personal data is generally regarded as perhaps the most important privacy protection safeguard.”</em> <span class="citation" data-cites="OECD1980">(Organisation for Economic Co-operation and Development, <a href="#ref-OECD1980" role="doc-biblioref">1980</a>)</span></p>
</blockquote>
<p><strong>Individual oversight capabilities must be supported by governance, so that they can effect desired changes.</strong> As Gurstein notes, a key element of effective data access is governance, that is, mandating data holders to support individuals in accessing their data and respecting their wishes over what should happen to that data <span class="citation" data-cites="gurstein2011">(Gurstein, <a href="#ref-gurstein2011" role="doc-biblioref">2011</a>)</span>. Individuals need be be able to give instructions, make changes and express permissions that have weight; they need to be listened to, so that they can meaningfully effect change (4.4.2). Bakardjieva, examining the use of data about others in a different context (research), identified that individuals whose data is used need the ability to influence not only the data about them, but the actual decisionmaking that occurs based on that data: both the data <em>and</em> the decisionmaking should become objects that the individual subject can manipulate <span class="citation" data-cites="bakardjieva2001">(Bakardjieva and Feenberg, <a href="#ref-bakardjieva2001" role="doc-biblioref">2001</a>)</span>. At the time of writing, much of the focus on GDPR has been about access to data, perhaps because this is more tangible, and very little about GDPR’s other rights that can influence decision-making (5.1.2). This was backed up by participant experiences in Case Study Two, where desires to influence or change practices or delete data were either not actionable or ineffective (5.4.3.3). Governance over individual data rights has two elements. First, to support individuals in complaints or challenges, which are currently unevenly enforced (5.5.1). But more importantly than this, given the extensive use of data by organisations and the great potential for misuse or harm, individuals need to be able to trust that systems are in place that mandate the behaviour of data holders to be trustworthy; to compel organisations to maintain good data practices such as data security and dynamic consent in the first place (5.4.4.1). In the GDPR context the bodies that can do this already exist - the Data Protection Authorities. In the public sector/care context, the picture is less clear. Participants identified a need for oversight bodies to compel good practice, identify appropriate access rules, and to provide independent oversight in contentious cases (4.3.4.3); this is particularly difficult given that no organisation can see the full picture of an individual’s civic data.</p>
<p><strong>Individual oversight would bring individuals back to the centre of their personal data ecosystem as an active participant.</strong> As outlined in 2.3.4, the ideal has been established that individuals need to be at the centre of their own personal data ecosystem, overseeing and controlling their data selves as easily as their physical selves. Currently, as seen in both contexts, data functions as a proxy for their direct involvement [<span class="citation" data-cites="bowyer2018b">Bowyer <em>et al.</em> (<a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>; 5.4.4.1]. Decisionmakers consult data first, as the primary source of truth (4.1.2, 2.1.2), and the individual second (if at all). For transparency to be meaningful, data flows need to open up to include individuals as part of the loop, changing them from passive spectators to active participants <span class="citation" data-cites="wef2014lens crabtree2016">(Hoffman, <a href="#ref-wef2014lens" role="doc-biblioref">2014</a><a href="#ref-wef2014lens" role="doc-biblioref">a</a>; Crabtree and Mortier, <a href="#ref-crabtree2016" role="doc-biblioref">2016</a>)</span> in the processing of their data. Examples of specific oversight abilities desired in Case Study One were the ability to explain or annotate datapoints (4.3.3.4), to be able to check data together with support workers, with the record of that check becoming part of the data (4.3.3.2), or to have granular access controls over precisely which data could be seen by whom (4.3.3.5). In Case Study Two, a clear picture emerged that what participants want is the ability to make choices. They want control over the data they are forced to sacrifice to companies (5.4.4.1); to avoid the <em>‘point of severance’</em> Luger describes, data sacrifice should be a loan or sublicense, not a taking-possession-of.</p>
<p><strong>Given the changing and complex nature of human life, data is inadequate and consent is never complete, so longitudinal participation and oversight is needed.</strong> Too often, data is treated as a static source of truth (see above). Attempting to represent people as data in order to require less human contact is a reasonable goal from an organisational efficiency or cost-saving perspective, but any representation will never be complete or adequate <span class="citation" data-cites="cornford2013 bowyer2018b">(Cornford, Baines and Wilson, <a href="#ref-cornford2013" role="doc-biblioref">2013</a>; Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>. In Case Study One, the findings showed the need for numerous efforts to augment data in order to combat its inherent inadequacy, such as support workers seeking to understand the people behind the records (4.3.3.1) and maintaining a constant attitude of seeking to understand more deeply than the data record can allow (4.3.4.2). Even if a data record can be corrected or completed, it will still be inadequate, because human lives change continuously: people move, start and end relationships and jobs, marry, divorce, have children, pursue new interests, become incapacitated, or die. The passage of time can radically change the context or relevance of data <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span>. A one-time informed consent upon data collection is inadequate in this ever-changing context (4.2.2, 4.2.6, 4.3.3.3). And of course, if consent needs to be ongoing (and in order for it to be meaningful) this means that engagement with the individual concerned, and that individual having a view of their data and its use, need to be ongoing too. In order to avoid storing or using data beyond its need, ongoing data access is needed, in order to enable ongoing individual oversight (4.2.2, 4.3.2.4). Systems and processes must treat data as dynamic (4.3.3.3), as something that will become inaccurate without sustained engagement. In Case Study Two, we note that GDPR data access is currently based around viewing a one-time snapshot of your data, and does not take this need for negotiability <span class="citation" data-cites="mortier2014">(Mortier <em>et al.</em>, <a href="#ref-mortier2014" role="doc-biblioref">2014</a>)</span> into account at all (5.5.1) (though some companies now offer download dashboards that come closer to providing ongoing access). Ongoing access, consent and participation do carry cost implications for providers, and effort implications for individuals - but these can be improved over time: the former through automation, standards and education, and the latter through holistic approaches to personal data ecosystems; these mitigations will be explored further in Chapter 7.</p>
<p><strong>There is very little oversight available today. Governance is lacking. If people cannot make choices about their data, they will remain powerless.</strong> Participants in both contexts faced an inability to see the full picture of how their data is processed and used. Despite families in Case Study One workshops spending time designing interfaces for seeing and correcting their data and changing permissions (3.5.3, 4.3.2.1, 4.3.2.3), no such interfaces exist. The entirety of their data access and influence is limited to what can be achieved verbally with their support workers (4.2.4, 4.4.3). Without transparency and dynamic consent mechanisms, those families lack accountability. They are excluded with no ability to oversee or participate in the life of their data. In Case Study Two, of the 41% of participant goals that concerned gaining insight into and control over the use of their data, 66% were unmet. Participants reported seeing no clear pathway on how to access rights to control their data and only 1 of the 10 cases where a participant wanted to delete their data was successful (5.3.3). At the time of writing only one company, Apple, has a privacy hub that offers clear routes to access data rights other than access. Participants also reported in some cases being unable to check the accuracy of their data, or to investigate specific incidents where they had concerns (5.3.3). The general view was one of widespread disappointment, that despite the promise of GDPR it did not confer any power to the individual to influence data use. (5.2.4.3), leading in some cases to a reluctance to submit GDPR requests in future. Access requests were also rarely seen as useful in the care context, and our understanding is they typically only occur in the case of complaints. In the GDPR context, the inability to restrict data use or delete data was seen as a lack of control, and the retaining of data against their wishes as a liability (5.4.3.3). Ultimately oversight means having choices, which is essential in the data-centric world. The case studies’ findings show that, in general, participants felt they had been forced to sacrifice data to access services, and offered <em>no</em> practical choices or control over that data. Without individual oversight, there is no choice and people remain powerless.</p>
</section>
<section id="involvement" data-number="1.2.3">
<h3 data-number="6.2.3"><span class="header-section-number">6.2.3</span> Involvement</h3>
<p><strong>Data represents people. But people are not records. There is a need to engage the human behind the data, as people can never be fully represented in data.</strong> Intrinsic in the move towards data-centricity has been a move away from human involvement. In the commercial sector this is due to cost-saving (call centres and web portals being cheaper than individual customer interactions) (2.1.2). In the care context it is similar but there is also a desire to create a society that functions at large without individuals requiring special handling and support (3.4.1). Both case studies’ findings, consistent with literature <span class="citation" data-cites="abiteboul2015 crabtree2016">(Abiteboul, André and Kaplan, <a href="#ref-abiteboul2015" role="doc-biblioref">2015</a>; Crabtree and Mortier, <a href="#ref-crabtree2016" role="doc-biblioref">2016</a>)</span>, reveal myriad problems created by the exclusion <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> of people from matters that affect them - from feelings of alienation or disengagement (5.4.4.1) to actual harms caused by erroneous or unfair judgements (4.2.2). Service providers holding data need to contextualise data as an incomplete view into the complex human world, and seek greater understanding (4.3.4.2) while looking for positives in data (4.3.4.1). It is interesting to note that the Troubled Families programme was created help find the human situations of people slipping through the cracks of the system, which highlights the inadequacy of purely data-based decision-making (3.4.1).</p>
<p><strong>Consent to access and use data needs to be dynamic and meaningful, which can only happen through ongoing involvement.</strong> As established in 4.4.1 and above in 6.2.2, ongoing data consent is essential, and this is especially important where that data is used to make decisions (4.4.3). One-time consent is ineffective and meaningless (4.5). Asking individuals for consent and subsequently less involved in decision-making reinforces a hierarchical, rather than an equitable, power relationship, as Bakardjieva and Feenberg found in their work looking at how to involve virtual subjects in research <span class="citation" data-cites="bakardjieva2001">(Bakardjieva and Feenberg, <a href="#ref-bakardjieva2001" role="doc-biblioref">2001</a>)</span>. Without ongoing consent, the power imbalance is amplified (4.5). In the commercial context, companies view data as their asset to exploit <span class="citation" data-cites="wef2011 toonders2014">(Hoffman, <a href="#ref-wef2011" role="doc-biblioref">2011</a>; Toonders, <a href="#ref-toonders2014" role="doc-biblioref">2014</a>)</span>, and the simple fact of having the ability to collect or access to data about people has proved in practice, sufficient to enable a variety of practices which would be likely to be refused consent if made visible to users <span class="citation" data-cites="evans2021 claburn2021 melendez2019">(Melendez and Pasternack, <a href="#ref-melendez2019" role="doc-biblioref">2019</a>; Evans, <a href="#ref-evans2021" role="doc-biblioref">2021</a>; Claburn, <a href="#ref-claburn2021" role="doc-biblioref">2021</a>)</span>. Individuals feel forced into a one-sided arrangement of sacrificing data in exchange for service benefits; with no choice upfront on signup, and minimal practical choices afterwards, their only choice is Hobson’s choice <span class="citation" data-cites="britannicaHobsonsChoice">(‘Hobson’s Choice’, <a href="#ref-britannicaHobsonsChoice" role="doc-biblioref">no date</a>)</span>. Consent has become commoditised, and from a corporate perspective the focus has become constructing a legal justification for using an individual’s data rather than practically engaging with them and verifying if they approve <span class="citation" data-cites="woods2022">(Woods and Böhme, <a href="#ref-woods2022" role="doc-biblioref">2022</a>)</span>. This can only happen when the individual about which data is held is excluded from data handling processes.</p>
<p><strong>A human channel for conversation is wanted, to enable explanations, questions, and consultation</strong>. In my earlier work <span class="citation" data-cites="bowyer2018b">(Bowyer <em>et al.</em>, <a href="#ref-bowyer2018b" role="doc-biblioref">2018</a>)</span> and in Case Study One, all participants viewed that individuals should be able to talk to someone about their data (4.2.6, 4.3.2.4), in order to ask questions or explain datapoints. In Case Study Two, participants had questions about their data that they wanted to answer (5.3.3), yet these questions remained unanswered (5.4.2.3). Participants regularly experienced painful and ineffective processes when trying to answer their questions, found that GDPR responses, often unhelpful, provided no backchannel for followup questions or further communication (5.2.4.3). They were left <em>‘in the dark’</em>. This highlights the need for a human support channel, which is not mandated by GDPR, not just to better understand the data itself (6.1.2), but to enable ongoing consent negotiation within the relationship with data holders.</p>
<p><strong>Individuals should be consulted in decision-making. This improves accuracy, consideration, and fairness.</strong></p>
<p>In doing so, it is important to give the human data subject a role; they need to be involved, to ensure a fairer and more complete view is obtained than the limited view presented by the data record (4.3.3.1). Data is not neutral <span class="citation" data-cites="gitelman2013 neff2013">(Gitelman, <a href="#ref-gitelman2013" role="doc-biblioref">2013</a>; Neff, <a href="#ref-neff2013" role="doc-biblioref">2013</a>)</span>, and this means all stakeholders should be given a role <span class="citation" data-cites="bowker2005">(Bowker, <a href="#ref-bowker2005" role="doc-biblioref">2005</a>)</span> in order to avoid errors, harm or disempowerment (4.4.1).</p>
<ol start="5" type="1">
<li>Effective collaboration can be achieved by bringing data subject and data holder together around the data, using it as evidence (of facts or opinions) and as a boundary object.</li>
</ol>
<p>[reference the fact that individuals’ viewpoints of data may differ but be valid (6.1.2)]</p>
<ol start="6" type="1">
<li>Being involved means being able to learn and act at any time, including on one’s own and away from official contact or interactions with service representatives.</li>
<li>Data use enforces an uneasy trust; services need a human face or point of contact, in order to earn trust and improve relations.</li>
<li>Without involvement, people can never take a full and equitable role in processes that affect their life.</li>
</ol>
</section>
</section>
<section id="achieving-individual-empowerment" data-number="1.3">
<h2 data-number="6.3"><span class="header-section-number">6.3</span> Achieving Individual Empowerment</h2>
<ol type="1">
<li><p>Through these summarised insights, I have shown a multifacted set of needs and opportunities around data access and use. While all six of these data wants can produce improvements in their own right, the combination of all six is likely to produce more than the sum of its parts, an empowered form of digital citizen.</p></li>
<li><p>Giving people a role as co-stewards of their own data and involved in decision-making would be progressive and transformative, and this could be applied in different domains across society.</p></li>
<li><p>We can envision from this a new fully human-centred (or at least power-balanced) future - cooperative data stewardship and empowered, involved citizens.</p></li>
</ol>
</section>
</section>
<h1 class="unnumbered" id="bibliography">Bibliography</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-abiteboul2015">
<p>Abiteboul, S., André, B. and Kaplan, D. (2015) <em>Managing your digital life with a Personal information management system</em>. 5. ACM, pp. 32–35. doi: <a href="https://doi.org/10.1145/2670528">10.1145/2670528</a>.</p>
</div>
<div id="ref-gdpr2018art13">
<p>‘Article 13: Information to be provided where personal data are collected from the data subject’ (2020). doi: <a href="https://doi.org/10.1093/oso/9780198826491.003.0044">10.1093/oso/9780198826491.003.0044</a>.</p>
</div>
<div id="ref-bakardjieva2001">
<p>Bakardjieva, M. and Feenberg, A. (2001) ‘Involving the Virtual Subjects’, <em>Ethics and Information Technology</em>, 2, pp. 233–240. doi: <a href="https://doi.org/10.1023/A:1011454606534">10.1023/A:1011454606534</a>.</p>
</div>
<div id="ref-binns2022">
<p>Binns, R. (2022) ‘Tracking on the Web, Mobile and the Internet-of-Things’. Available at: <a href="http://arxiv.org/abs/2201.10831">http://arxiv.org/abs/2201.10831</a>.</p>
</div>
<div id="ref-bowker2005">
<p>Bowker, G. C. (2005) <em>Memory practices in the sciences</em>. MIT Press, p. 261.</p>
</div>
<div id="ref-bowyer2011">
<p>Bowyer, A. (2011) ‘Why files need to die’. Available at: <a href="http://radar.oreilly.com/2011/07/why-files-need-to-die.html">http://radar.oreilly.com/2011/07/why-files-need-to-die.html</a>.</p>
</div>
<div id="ref-bowyer2018b">
<p>Bowyer, A. <em>et al.</em> (2018) ‘Understanding the Family Perspective on the Storage, Sharing and Handling of Family Civic Data’, in <em>Conference on human factors in computing systems - proceedings</em>. New York, New York, USA: ACM Press, pp. 1–13. doi: <a href="https://doi.org/10.1145/3173574.3173710">10.1145/3173574.3173710</a>.</p>
</div>
<div id="ref-brandt2004">
<p>Brandt, E. and Messeter, J. (2004) ‘Facilitating collaboration through design games’, in <em>Proceedings of the eighth conference on participatory design artful integration: Interweaving media, materials and practices - pdc 04</em>. New York, New York, USA: ACM Press, p. 121. doi: <a href="https://doi.org/10.1145/1011870.1011885">10.1145/1011870.1011885</a>.</p>
</div>
<div id="ref-chang2018">
<p>Chang, A. (2018) ‘The Facebook and Cambridge Analytica scandal, explained with a simple diagram - Vox’. Available at: <a href="https://www.vox.com/policy-and-politics/2018/3/23/17151916/facebook-cambridge-analytica-trump-diagram">https://www.vox.com/policy-and-politics/2018/3/23/17151916/facebook-cambridge-analytica-trump-diagram</a>.</p>
</div>
<div id="ref-claburn2021">
<p>Claburn, T. (2021) ‘Android’s Messages, Dialer apps quietly sent text, call info to Google’. Available at: <a href="https://www.theregister.com/2022/03/21/google_messages_gdpr/">https://www.theregister.com/2022/03/21/google_messages_gdpr/</a>.</p>
</div>
<div id="ref-cormack2016">
<p>Cormack, A. (2016) ‘Is the Subject Access Right Now Too Great a Threat to Privacy?’, <em>European Data Protection Law Review</em>, 2(1), pp. 15–27. doi: <a href="https://doi.org/10.21552/edpl/2016/1/5">10.21552/edpl/2016/1/5</a>.</p>
</div>
<div id="ref-cornford2013">
<p>Cornford, J., Baines, S. and Wilson, R. (2013) ‘Representing the family: how does the state ’think family’?’, <em>Policy &amp; Politics</em>, 41(1), pp. 1–19. doi: <a href="https://doi.org/10.1332/030557312X645838">10.1332/030557312X645838</a>.</p>
</div>
<div id="ref-crabtree2016">
<p>Crabtree, A. and Mortier, R. (2016) ‘Personal Data, Privacy and the Internet of Things: The Shifting Locus of Agency and Control’, <em>SSRN Electronic Journal</em>, pp. 1–20. doi: <a href="https://doi.org/10.2139/ssrn.2874312">10.2139/ssrn.2874312</a>.</p>
</div>
<div id="ref-avast2022databrokers">
<p>‘Data Brokers: Everything You Need to Know’ (2022). Available at: <a href="https://www.avast.com/c-data-brokers">https://www.avast.com/c-data-brokers</a> (Accessed: 11 February 2022).</p>
</div>
<div id="ref-vandijck2014">
<p>Dijck, J. van (2014) ‘Datafication, dataism and dataveillance: Big data between scientific paradigm and ideology’, <em>Surveillance and Society</em>. Surveillance Studies Network, 12(2), pp. 197–208. doi: <a href="https://doi.org/10.24908/ss.v12i2.4776">10.24908/ss.v12i2.4776</a>.</p>
</div>
<div id="ref-evans2021">
<p>Evans, W. (2021) ‘Amazon’s dark secret: It has failed to protect your data’.</p>
</div>
<div id="ref-gitelman2013">
<p>Gitelman, L. (2013) <em>Raw data is an oxymoron</em>. Edited by Lisa Gitelman. MIT Press, p. 182. Available at: <a href="https://mitpress.mit.edu/books/raw-data-oxymoron">https://mitpress.mit.edu/books/raw-data-oxymoron</a>.</p>
</div>
<div id="ref-glavic2021">
<p>Glavic, B. <em>et al.</em> (2021) ‘Trends in Explanations: Understanding and Debugging Data-driven Systems’, <em>Foundations and Trendsin Databases</em>. Now Publishers, Inc., 11(3), pp. 226–318. doi: <a href="https://doi.org/10.1561/XXXXXXXXX.Boris">10.1561/XXXXXXXXX.Boris</a>.</p>
</div>
<div id="ref-goffe2021">
<p>Goffe, L. <em>et al.</em> (2021) ‘Appetite for Disruption: Designing Human-Centred Augmentations to an Online Food Ordering Platform’, <em>34th British Human Computer Interaction Conference Interaction Conference, BCS HCI 2021</em>, pp. 155–167. doi: <a href="https://doi.org/10.14236/ewic/HCI2021.16">10.14236/ewic/HCI2021.16</a>.</p>
</div>
<div id="ref-gurstein2011">
<p>Gurstein, M. B. (2011) ‘Open data: Empowering the empowered or effective data use for everyone?’, <em>First Monday</em>. First Monday, 16(2). doi: <a href="https://doi.org/10.5210/fm.v16i2.3316">10.5210/fm.v16i2.3316</a>.</p>
</div>
<div id="ref-britannicaHobsonsChoice">
<p>‘Hobson’s Choice’ (no date). Available at: <a href="https://www.britannica.com/dictionary/Hobson%27s-choice">https://www.britannica.com/dictionary/Hobson%27s-choice</a>.</p>
</div>
<div id="ref-wef2011">
<p>Hoffman, W. (2011) <em>Personal data : The emergence of a new asset class</em>. World Economic Forum, pp. 1–40. Available at: <a href="http://www.weforum.org/reports/personal-data-emergence-new-asset-class">http://www.weforum.org/reports/personal-data-emergence-new-asset-class</a>.</p>
</div>
<div id="ref-wef2014lens">
<p>Hoffman, W. (2014a) <em>Rethinking Personal Data : A New Lens for Strengthening Trust</em>. May. World Economic Forum, p. 35. Available at: <a href="http://www3.weforum.org/docs/WEF_RethinkingPersonalData_ANewLens_Report_2014.pdf">http://www3.weforum.org/docs/WEF_RethinkingPersonalData_ANewLens_Report_2014.pdf</a>.</p>
</div>
<div id="ref-wef2014context">
<p>Hoffman, W. (2014b) <em>Rethinking personal data: Trust and context in user-centred data ecosystems</em>. May. World Economic Forum, p. 35. Available at: <a href="http://www3.weforum.org/docs/WEF_RethinkingPersonalData_TrustandContext_Report_2014.pdf">http://www3.weforum.org/docs/WEF_RethinkingPersonalData_TrustandContext_Report_2014.pdf</a>.</p>
</div>
<div id="ref-ico2018">
<p>Information Commissioner’s Office (2018) ‘Your data matters - Your rights’. Available at: <a href="https://ico.org.uk/your-data-matters/">https://ico.org.uk/your-data-matters/</a>.</p>
</div>
<div id="ref-kaye2015">
<p>Kaye, J. <em>et al.</em> (2015) ‘Dynamic consent: a patient interface for twenty-first century research networks’, <em>European Journal of Human Genetics</em>. Nature Publishing Group, 23(2), pp. 141–146. doi: <a href="https://doi.org/10.1038/ejhg.2014.71">10.1038/ejhg.2014.71</a>.</p>
</div>
<div id="ref-kroger2021">
<p>Kröger, J. L., Miceli, M. and Müller, F. (2021) ‘How Data Can Be Used Against People: A Classification of Personal Data Misuses’, <em>SSRN Electronic Journal</em>, (December). doi: <a href="https://doi.org/10.2139/ssrn.3887097">10.2139/ssrn.3887097</a>.</p>
</div>
<div id="ref-larsson2018">
<p>Larsson, S. (2018) ‘Algorithmic governance and the need for consumer empowerment in data-driven markets’, <em>Internet Policy Review</em>, 7(2). doi: <a href="https://doi.org/10.14763/2018.2.791">10.14763/2018.2.791</a>.</p>
</div>
<div id="ref-li2010">
<p>Li, I., Dey, A. and Forlizzi, J. (2010) ‘A stage-based model of personal informatics systems’, <em>Proceedings of the 28th international conference on Human factors in computing systems CHI 10</em>. New York, New York, USA: ACM Press, p. 557. doi: <a href="https://doi.org/10.1145/1753326.1753409">10.1145/1753326.1753409</a>.</p>
</div>
<div id="ref-luger2013">
<p>Luger, E. and Rodden, T. (2013) ‘An informed view on consent for ubicomp’, in <em>UbiComp 2013 - proceedings of the 2013 acm international joint conference on pervasive and ubiquitous computing</em>. New York, New York, USA: ACM Press, pp. 529–538. doi: <a href="https://doi.org/10.1145/2493432.2493446">10.1145/2493432.2493446</a>.</p>
</div>
<div id="ref-mcnamee2019">
<p>McNamee, R. (2019) <em>Zucked: Waking up to the Facebook Catasrophe</em>, p. 336.</p>
</div>
<div id="ref-melendez2019">
<p>Melendez, S. and Pasternack, A. (2019) ‘The data brokers quietly buying and selling your personal information’. Available at: <a href="https://www.fastcompany.com/90310803/here-are-the-data-brokers-quietly-buying-and-selling-your-personal-information">https://www.fastcompany.com/90310803/here-are-the-data-brokers-quietly-buying-and-selling-your-personal-information</a>.</p>
</div>
<div id="ref-mortier2013">
<p>Mortier, R. <em>et al.</em> (2013) ‘Challenges &amp; opportunities in human-data interaction’, <em>University of Cambridge, Computer Laboratory</em>. Citeseer. doi: <a href="https://doi.org/10.5210/fm.v17i5.4013">10.5210/fm.v17i5.4013</a>.</p>
</div>
<div id="ref-mortier2014">
<p>Mortier, R. <em>et al.</em> (2014) ‘Human-data interaction: The human face of the data-driven society’, <em>Available at SSRN 2508051</em>. doi: <a href="https://doi.org/10.2139/ssrn.2508051">10.2139/ssrn.2508051</a>.</p>
</div>
<div id="ref-neff2013">
<p>Neff, G. (2013) ‘Why Big Data Won’t Cure Us’, <em>Big Data</em>, 1(3), pp. 117–123. doi: <a href="https://doi.org/10.1089/big.2013.0029">10.1089/big.2013.0029</a>.</p>
</div>
<div id="ref-OECD1980">
<p>Organisation for Economic Co-operation and Development (1980) <em>OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data</em>. Available at: <a href="https://www.oecd.org/digital/ieconomy/oecdguidelinesontheprotectionofprivacyandtransborderflowsofpersonaldata.htm">https://www.oecd.org/digital/ieconomy/oecdguidelinesontheprotectionofprivacyandtransborderflowsofpersonaldata.htm</a>.</p>
</div>
<div id="ref-strohmayer2021">
<p>Strohmayer, A. <em>et al.</em> (2021) <em>Trust and Abusability Toolkit: Centering Safety in Human-Data Interactions</em>.</p>
</div>
<div id="ref-taylor2015">
<p>Taylor, A. S. <em>et al.</em> (2015) ‘Data-in-place: Thinking through the relations between data and community’, in <em>Conference on human factors in computing systems - proceedings</em>, pp. 2863–2872. doi: <a href="https://doi.org/10.1145/2702123.2702558">10.1145/2702123.2702558</a>.</p>
</div>
<div id="ref-toonders2014">
<p>Toonders, J. (2014) ‘Data Is the New Oil of the Digital Economy’. Available at: <a href="https://www.wired.com/insights/2014/07/data-new-oil-digital-economy/">https://www.wired.com/insights/2014/07/data-new-oil-digital-economy/</a>.</p>
</div>
<div id="ref-williams2015">
<p>Williams, H. <em>et al.</em> (2015) ‘Dynamic consent: a possible solution to improve patient confidence and trust in how electronic patient records are used in medical research.’, <em>JMIR medical informatics</em>. JMIR Publications Inc., 3(1), p. e3. doi: <a href="https://doi.org/10.2196/medinform.3525">10.2196/medinform.3525</a>.</p>
</div>
<div id="ref-woods2022">
<p>Woods, D. W. and Böhme, R. (2022) ‘The commodification of consent’, <em>Computers &amp; Security</em>. Elsevier Ltd, 115, p. 102605. doi: <a href="https://doi.org/10.1016/j.cose.2022.102605">10.1016/j.cose.2022.102605</a>.</p>
</div>
<div id="ref-zuboff2019">
<p>Zuboff, S. (2019) <em>The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power</em>. Profile. Available at: <a href="https://books.google.co.uk/books?id=W7ZEDgAAQBAJ">https://books.google.co.uk/books?id=W7ZEDgAAQBAJ</a>.</p>
</div>
<div id="ref-zuckerman2021">
<p>Zuckerman, E. (2021) <em>Mistrust: Why Losing Faith In Institutions Provides The Tools To Transform Them</em>. New York, NY, USA: W. W. Norton &amp; Company, pp. 1–3. doi: <a href="https://doi.org/10.1017/ipo.2021.30">10.1017/ipo.2021.30</a>.</p>
</div>
</div>
</body>
</html>
